{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from core.web_discovery import WebDiscovery\n",
    "from features.research_agent import ResearchAgent\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize components\n",
    "discovery = WebDiscovery()\n",
    "research_agent = ResearchAgent()\n",
    "sources_dir = Path('../data/sources')\n",
    "sources_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úì Research workflow initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f9e25",
   "metadata": {},
   "source": [
    "## Step 1: Define Research Question\n",
    "\n",
    "What question are you trying to answer with this research?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82856486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your research question\n",
    "research_question = \"How do knowledge graphs improve data integration in cloud environments?\"\n",
    "\n",
    "print(f\"Research Question: {research_question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac0585",
   "metadata": {},
   "source": [
    "## Step 2: Batch URL Input\n",
    "\n",
    "Paste all your source URLs here (one per line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da537b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste all URLs here\n",
    "urls_text = \"\"\"\n",
    "https://example.com/source1\n",
    "https://example.com/source2\n",
    "https://example.com/source3\n",
    "https://example.com/source4\n",
    "https://example.com/source5\n",
    "\"\"\"\n",
    "\n",
    "# Parse URLs\n",
    "urls = [url.strip() for url in urls_text.strip().split('\\n') if url.strip() and url.startswith('http')]\n",
    "\n",
    "print(f\"\\nüìã Processing {len(urls)} URLs\")\n",
    "for i, url in enumerate(urls, 1):\n",
    "    print(f\"  {i}. {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5da98b",
   "metadata": {},
   "source": [
    "## Step 3: Scrape and Assess Quality\n",
    "\n",
    "Extract content and assess quality for each source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff7be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape URLs using ResearchAgent\n",
    "print(\"\\nüîç Scraping sources...\\n\")\n",
    "\n",
    "scraped_sources = research_agent.scrape_urls(urls)\n",
    "\n",
    "print(f\"\\n‚úì Successfully scraped {len(scraped_sources)} sources\")\n",
    "print(f\"‚úó Failed to scrape {len(urls) - len(scraped_sources)} sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d8f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess quality of each source\n",
    "print(\"\\nüìä Assessing source quality...\\n\")\n",
    "\n",
    "assessed_sources = []\n",
    "\n",
    "for source in scraped_sources:\n",
    "    print(f\"Assessing: {source['title'][:60]}...\")\n",
    "    \n",
    "    assessment = research_agent.assess_quality(source, research_question)\n",
    "    source['assessment'] = assessment\n",
    "    \n",
    "    # Parse quality score from assessment\n",
    "    score_match = re.search(r'Quality Score:\\s*(\\d+)/10', assessment.get('assessment', ''))\n",
    "    source['quality_score'] = int(score_match.group(1)) if score_match else 0\n",
    "    \n",
    "    assessed_sources.append(source)\n",
    "    print(f\"  Score: {source['quality_score']}/10\")\n",
    "    print()\n",
    "\n",
    "print(f\"‚úì Assessed {len(assessed_sources)} sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e6d77",
   "metadata": {},
   "source": [
    "## Step 4: Filter by Quality\n",
    "\n",
    "Keep only high-quality sources (score >= 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by quality threshold\n",
    "quality_threshold = 7\n",
    "\n",
    "high_quality_sources = [s for s in assessed_sources if s['quality_score'] >= quality_threshold]\n",
    "\n",
    "print(f\"\\nüìà Quality Analysis:\")\n",
    "print(f\"  Total sources: {len(assessed_sources)}\")\n",
    "print(f\"  High quality (>= {quality_threshold}): {len(high_quality_sources)}\")\n",
    "print(f\"  Low quality (< {quality_threshold}): {len(assessed_sources) - len(high_quality_sources)}\")\n",
    "\n",
    "print(\"\\nüåü High Quality Sources:\")\n",
    "for source in high_quality_sources:\n",
    "    print(f\"  [{source['quality_score']}/10] {source['title']}\")\n",
    "    print(f\"           {source['url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac872940",
   "metadata": {},
   "source": [
    "## Step 5: Synthesize Sources\n",
    "\n",
    "Create a synthesis of all high-quality sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ca427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesize sources\n",
    "print(\"\\nüß† Synthesizing sources...\\n\")\n",
    "\n",
    "synthesis = research_agent.synthesize_sources(\n",
    "    sources=high_quality_sources,\n",
    "    research_question=research_question\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RESEARCH SYNTHESIS\")\n",
    "print(\"=\"*80)\n",
    "print(synthesis)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da39dbd",
   "metadata": {},
   "source": [
    "## Step 6: Save Individual Sources\n",
    "\n",
    "Save each high-quality source as a markdown file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ed788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save individual sources\n",
    "print(\"\\nüíæ Saving sources...\\n\")\n",
    "\n",
    "saved_files = []\n",
    "\n",
    "for source in high_quality_sources:\n",
    "    # Create safe filename\n",
    "    safe_title = re.sub(r'[^\\w\\s-]', '', source['title'])\n",
    "    safe_title = re.sub(r'[-\\s]+', '-', safe_title)[:100]\n",
    "    filename = f\"{safe_title}.md\"\n",
    "    filepath = sources_dir / filename\n",
    "    \n",
    "    # Extract key topics from research question\n",
    "    topics = research_question.lower().split()\n",
    "    tags = [t for t in topics if len(t) > 3][:3]  # Top 3 meaningful words\n",
    "    \n",
    "    # Create markdown content\n",
    "    content = f\"\"\"---\n",
    "title: {source['title']}\n",
    "author: {source.get('author', 'Unknown')}\n",
    "url: {source['url']}\n",
    "quality_score: {source['quality_score']}/10\n",
    "date_extracted: {datetime.now().strftime('%Y-%m-%d')}\n",
    "research_question: {research_question}\n",
    "tags: [research, high-quality, {', '.join(tags)}]\n",
    "---\n",
    "\n",
    "# {source['title']}\n",
    "\n",
    "**Author:** {source.get('author', 'Unknown')}  \n",
    "**Source:** {source['url']}  \n",
    "**Quality Score:** {source['quality_score']}/10  \n",
    "**Extracted:** {datetime.now().strftime('%Y-%m-%d')}\n",
    "\n",
    "## Quality Assessment\n",
    "\n",
    "{source['assessment'].get('assessment', 'No assessment available')}\n",
    "\n",
    "---\n",
    "\n",
    "## Content\n",
    "\n",
    "{source['content']}\n",
    "\"\"\"\n",
    "    \n",
    "    # Write file\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    saved_files.append(filepath)\n",
    "    print(f\"  ‚úì {filename}\")\n",
    "\n",
    "print(f\"\\n‚úì Saved {len(saved_files)} sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62044d7d",
   "metadata": {},
   "source": [
    "## Step 7: Create Literature Note\n",
    "\n",
    "Create a synthesis note linking all sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268526f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create literature note with synthesis\n",
    "lit_note_filename = f\"Literature-{datetime.now().strftime('%Y%m%d-%H%M%S')}.md\"\n",
    "lit_note_path = sources_dir / lit_note_filename\n",
    "\n",
    "# Build links to sources\n",
    "source_links = \"\\n\".join([\n",
    "    f\"- [[{source['title']}]] - Quality: {source['quality_score']}/10\"\n",
    "    for source in high_quality_sources\n",
    "])\n",
    "\n",
    "lit_note_content = f\"\"\"---\n",
    "title: Literature Review - {research_question}\n",
    "type: literature-note\n",
    "date_created: {datetime.now().strftime('%Y-%m-%d')}\n",
    "num_sources: {len(high_quality_sources)}\n",
    "tags: [literature-review, synthesis]\n",
    "---\n",
    "\n",
    "# Literature Review: {research_question}\n",
    "\n",
    "**Date:** {datetime.now().strftime('%Y-%m-%d')}  \n",
    "**Sources:** {len(high_quality_sources)} high-quality articles\n",
    "\n",
    "## Research Question\n",
    "\n",
    "{research_question}\n",
    "\n",
    "## Synthesis\n",
    "\n",
    "{synthesis}\n",
    "\n",
    "## Sources\n",
    "\n",
    "{source_links}\n",
    "\n",
    "## Methodology\n",
    "\n",
    "- Total URLs processed: {len(urls)}\n",
    "- Successfully scraped: {len(scraped_sources)}\n",
    "- Quality threshold: {quality_threshold}/10\n",
    "- High-quality sources: {len(high_quality_sources)}\n",
    "- Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "\"\"\"\n",
    "\n",
    "# Save literature note\n",
    "with open(lit_note_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(lit_note_content)\n",
    "\n",
    "print(f\"\\nüìù Created literature note: {lit_note_filename}\")\n",
    "print(f\"\\n‚úÖ Research workflow complete!\")\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"   - Processed: {len(urls)} URLs\")\n",
    "print(f\"   - Saved: {len(saved_files)} high-quality sources\")\n",
    "print(f\"   - Created: 1 literature note with synthesis\")\n",
    "print(f\"\\nüîÑ Next steps:\")\n",
    "print(f\"   1. Launch UI: python server.py\")\n",
    "print(f\"   2. Build knowledge graph: see test_graph.py\")\n",
    "print(f\"   3. Ask questions about your research!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
