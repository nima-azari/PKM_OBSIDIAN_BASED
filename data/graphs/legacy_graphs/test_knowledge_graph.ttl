# Knowledge Graph Export
# Generated: 2025-12-15 11:27:36
# 
# Graph Statistics:
#   - Documents: 14
#   - Chunks: 30
#   - Domain Concepts: 205
#   - Topic Nodes: 21
#   - Total Triples: 1236
# 
# Structure Guide:
#   1. Topic Nodes (onto:TopicNode) - Navigation layer organizing concepts
#   2. Documents (onto:Document) - Source files with metadata
#   3. Chunks (onto:Chunk) - Text segments from documents
#   4. Domain Concepts (onto:DomainConcept) - Knowledge entities
#   5. Tags (onto:Tag) - Document categorization
# 
# Relationships:
#   - onto:hasChunk: Document → Chunk (1-to-many)
#   - onto:mentionsConcept: Chunk → DomainConcept (many-to-many)
#   - onto:coversConcept: TopicNode → DomainConcept (many-to-many)
#   - onto:coversChunk: TopicNode → Chunk (many-to-many)
# 
# For more information, see: README.md
#

@prefix dct: <http://purl.org/dc/terms/> .
@prefix onto: <http://pkm.local/ontology/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix skos: <http://www.w3.org/2004/02/skos/core#> .
@prefix sources: <http://pkm.local/sources/> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

onto:topic_0 a onto:TopicNode ;
    onto:coversChunk sources:Cloud_switching_under_the_EU_Data_Actpdf_chunk_0,
        sources:Knowledge_Graphs__Redefining_Data_Management_for_the_Modern_Enterprisepdf_chunk_0,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_0,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_2,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_3,
        sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability_chunk_0,
        sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability_chunk_1,
        sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability_chunk_2,
        sources:The_EU_Data_Act_explained__rights_obligations_and_challenges_for_data_holders_and_manufacturerspdf_chunk_0,
        sources:node_12633_printable_pdfpdf_chunk_0,
        sources:node_12633_printable_pdfpdf_chunk_1,
        sources:tr_104410v010101ppdf_chunk_0 ;
    onto:coversConcept onto:Addressing_Vendor_Lock,
        onto:Breaking_Down_Barriers,
        onto:Critical_Challenge_Data,
        onto:Data_Act,
        onto:Data_Interoperability_The_Key_to_Breaking_Down_Barriers,
        onto:Data_Silos,
        onto:Data_Silos_A_Critical_Challenge,
        onto:Linked_Data,
        onto:Regulatory_Framework,
        onto:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability ;
    rdfs:comment "Clusters concepts: Data Silos: A Critical Challenge, Data Interoperability: The Key to Breaking Down Barriers, Critical Challenge Data" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Data Silos: A Critical Challenge, Data Interoperability: The Key to Br..." .

onto:topic_1 a onto:TopicNode ;
    onto:coversChunk sources:Knowledge_Graphs__Redefining_Data_Management_for_the_Modern_Enterprisepdf_chunk_0,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_0,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_2,
        sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability_chunk_1,
        sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability_chunk_2,
        sources:YouTube-8nbb6CwpPMA_chunk_1 ;
    onto:coversConcept onto:Conclusion_A_Call_for_Action,
        onto:Data_Lock,
        onto:Enhancing_Data_Interoperability,
        onto:Knowledge_Graphs,
        onto:Knowledge_Graphs_A_Tool_for_Enhancing_Data_Interoperability,
        onto:Linked_Data_Linked_Data,
        onto:The_EU_Data_Act_A_Regulatory_Framework_for_Data_Empowerment,
        onto:The_Interplay_Between_the_EU_Data_Act_and_Linked_Data,
        onto:The_Promise_of_Linked_Data,
        onto:Using_Template ;
    rdfs:comment "Clusters concepts: The Interplay Between the EU Data Act and Linked Data, The Promise of Linked Data, Enhancing Data Interoperability" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: The Interplay Between the EU Data Act and Linked Data, The Promise of ..." .

onto:topic_10 a onto:TopicNode ;
    onto:coversChunk sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf_chunk_1,
        sources:Cloud_switching_under_the_EU_Data_Actpdf_chunk_0 ;
    onto:coversConcept onto:Christopher_Eduard,
        onto:Cloud_Computing_Data,
        onto:Common_European_Dataspaces,
        onto:Digital_Europe,
        onto:Digital_Law,
        onto:European_Parliament,
        onto:Public_Procurement,
        onto:Research_Data,
        onto:Service_Level_Agreements,
        onto:Till_Contzen_Why ;
    rdfs:comment "Clusters concepts: Service Level Agreements, Cloud Computing Data, Digital Europe" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Service Level Agreements, Cloud Computing Data" .

onto:topic_11 a onto:TopicNode ;
    onto:coversChunk sources:Cloud_switching_under_the_EU_Data_Actpdf_chunk_0,
        sources:Knowledge_Graphs__Redefining_Data_Management_for_the_Modern_Enterprisepdf_chunk_0 ;
    onto:coversConcept onto:All_Blog,
        onto:Data_Act_Action,
        onto:Data_Security_Data,
        onto:Gergana_Petkova,
        onto:Graph_Center,
        onto:Knowledge_Graph,
        onto:Modern_Enterprise,
        onto:Reading_Time,
        onto:Service_Deloitte_Survey,
        onto:Technology_Digitalization ;
    rdfs:comment "Clusters concepts: Data Act Action, Data Security Data, Service Deloitte Survey" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Data Act Action, Data Security Data" .

onto:topic_12 a onto:TopicNode ;
    onto:coversChunk sources:Knowledge_Graphs__Redefining_Data_Management_for_the_Modern_Enterprisepdf_chunk_0,
        sources:node_12633_printable_pdfpdf_chunk_0,
        sources:node_12633_printable_pdfpdf_chunk_1 ;
    onto:coversConcept onto:Common_European_Data_Spaces,
        onto:Creative_Commons_Attribution,
        onto:Data_Act_Businesses,
        onto:Data_Governance_Act,
        onto:European_Data_Innovation_Board,
        onto:Member_States,
        onto:Previous_Next,
        onto:Redefining_Data_Management,
        onto:Scope_Chapter,
        onto:Under_Chapter ;
    rdfs:comment "Clusters concepts: Previous Next, Redefining Data Management, Data Governance Act" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Previous Next, Redefining Data Management" .

onto:topic_13 a onto:TopicNode ;
    onto:coversChunk sources:The_EU_Data_Act_explained__rights_obligations_and_challenges_for_data_holders_and_manufacturerspdf_chunk_0,
        sources:The_FAIR_Guiding_Principles_for_scientific_data_management_and_stewardshippdf_chunk_0,
        sources:node_12633_printable_pdfpdf_chunk_1 ;
    onto:coversConcept onto:Allianz_Insurance,
        onto:Career_Insights_Imprint_Code,
        onto:Creative_Commons,
        onto:Dutch_Techcenter,
        onto:General_Terms,
        onto:Insights_Blog,
        onto:Interoperability_Why,
        onto:Offering_Success,
        onto:Trade_Secrets_Directive,
        onto:Zohar_Efroni ;
    rdfs:comment "Clusters concepts: Interoperability Why, Allianz Insurance, Offering Success" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Interoperability Why, Allianz Insurance" .

onto:topic_14 a onto:TopicNode ;
    onto:coversChunk sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_2,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_7,
        sources:The_FAIR_Guiding_Principles_for_scientific_data_management_and_stewardshippdf_chunk_0,
        sources:tr_104410v010101ppdf_chunk_0 ;
    onto:coversConcept onto:Change_Requests,
        onto:Concept_Web_Alliance,
        onto:Data_Management,
        onto:European_Trusted_Data_Framework,
        onto:Informatics_Assoc,
        onto:Jointly_Designing,
        onto:Lib_Magazine,
        onto:Life_Sciences,
        onto:Lorentz_Workshop,
        onto:Trustworthiness_Requirements ;
    rdfs:comment "Clusters concepts: Informatics Assoc, Concept Web Alliance, Life Sciences" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Informatics Assoc, Concept Web Alliance" .

onto:topic_15 a onto:TopicNode ;
    onto:coversChunk sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_0,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_2,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_7,
        sources:tr_104410v010101ppdf_chunk_0 ;
    onto:coversConcept onto:Basic_Co,
        onto:Commission_Implementing_Decision,
        onto:Data_Space,
        onto:Electrotechnical_Standardization,
        onto:Life_Sciences_Accelerators_Menu,
        onto:Making_Sense,
        onto:Metadata_Studio,
        onto:Powered_Target_Discovery,
        onto:Semantic_Content_Hub,
        onto:Trusted_Data_Transactions ;
    rdfs:comment "Clusters concepts: Basic Co, Electrotechnical Standardization, Trusted Data Transactions" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Basic Co, Electrotechnical Standardization" .

onto:topic_16 a onto:TopicNode ;
    onto:coversChunk sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_0,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_1,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_2,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_3,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_7 ;
    onto:coversConcept onto:Contact_Us,
        onto:Content_Management,
        onto:Dimitar_Taskov,
        onto:Domain_Knowledge_Graph,
        onto:Graph_Analytics,
        onto:Knowledge_Graph_Applications,
        onto:Menu_Toggle,
        onto:Ontotext_Refine,
        onto:Products_Overview,
        onto:Public_Sector ;
    rdfs:comment "Clusters concepts: Graph Analytics, Products Overview, Domain Knowledge Graph" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Graph Analytics, Products Overview" .

onto:topic_17 a onto:TopicNode ;
    onto:coversChunk sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_1,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_2,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_3,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_4,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_5,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_7 ;
    onto:coversConcept onto:By_Application_Menu_Toggle,
        onto:Ivan_Koychev,
        onto:Keeps_Three_Key,
        onto:Managed_Services,
        onto:Ontotext_Semantic_Objects,
        onto:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability,
        onto:Semantic_Data_Modeling,
        onto:Social_Network_Benchmark,
        onto:SynthMedic_Utilizing_large_language_models_for_synthetic_discharge_summary_generation_correction_and_validationhttpswwwontotextcomknowledgehubpublicationsusing-llm-for-synthetic-discharge-summary-generation-correction-validation,
        onto:Vasil_Vasilev ;
    rdfs:comment "Clusters concepts: Managed Services, [SynthMedic: Utilizing large language models for synthetic discharge summary generation, correction and validation](https://www.ontotext.com/knowledgehub/publications/using-llm-for-synthetic-discharge-summary-generation-correction-validation/), By Application Menu Toggle" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Managed Services, [SynthMedic: Utilizing large language models for syn..." .

onto:topic_18 a onto:TopicNode ;
    onto:coversChunk sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_4,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_5 ;
    onto:coversConcept onto:Atanas_Kiryakov,
        onto:Knowledge_graphs_are_the_next_generation_tool_for_helping_businesses_make_critical_decisions_based_on_harmonized_knowledge_models_and_data_derived_from_siloed_source_systems_Due_to_the_huge_value_generated_by_their_data_standardization_and_semantic_modelling_capabilities_knowledge_graphs_are_most_often_associated_with_data_integration_linking_unification_and_information_reuse_As_more_and_more_organizations_are_turning_to_knowledge_graphs_for_better_data_and_content_analytics_search_and_graph_exploration_become_key_requirements_also,
        onto:Labeled_Property_Graphs,
        onto:Linked_Data_Benchmarking_Council,
        onto:Meet_the_speakers,
        onto:Ontotext_Atanas_Kiryakov,
        onto:Sirma_Group_Holding,
        onto:Sofia_Stock_Exchange,
        onto:Sofia_University,
        onto:The_recording_of_this_webinar_is_available_on__YouTubehttpsyoutube8nbb6CwpPMA_ ;
    rdfs:comment "Clusters concepts: The recording of this webinar is available on **_[YouTube](https://youtu.be/8nbb6CwpPMA)_**., Knowledge graphs are the next generation tool for helping businesses make critical decisions, based on harmonized knowledge models and data derived from siloed source systems. Due to the huge value generated by their data standardization and semantic modelling capabilities, knowledge graphs are most often associated with data integration, linking, unification and information reuse. As more and more organizations are turning to knowledge graphs for better data and content analytics, search and graph exploration become key requirements also., Ontotext Atanas Kiryakov" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: The recording of this webinar is available on **_[YouTube](https://you..." .

onto:topic_19 a onto:TopicNode ;
    onto:coversChunk sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_6 ;
    onto:coversConcept onto:Connected_Data_World,
        onto:Europe_Bulgaria,
        onto:Graphwise_Reconciliation,
        onto:Have_Someone,
        onto:Information_Extraction_Tool_How,
        onto:Key_Benefits,
        onto:My_Dear_Watson,
        onto:Ontotext_Metadata_Studio,
        onto:Want_more_like_this_learn_more_about_the_recommended_contentdataimagesvgxml3Csvg20xmlnshttpwwww3org2000svg20viewBox0200201620163E3Csvg3Elearn_more_about_the_recommended_contentwp-contentuploads202407icon-help-circlesvg_The_Ontotext_Recommendations_engine_combines_content_and_its_semantic_fingerprint_to_retrieve_knowledge_graph-driven_recommendations_It_is_integrated_with_the_Ontotext_Metadata_Studio_tagging_to_power_meaningful_recommendations_based_on_both_semantic_relevancy_and_recency,
        onto:Want_to_chat_more_with_us_Reach_out_and_lets_do_it ;
    rdfs:comment "Clusters concepts: Have Someone, Information Extraction Tool How, Key Benefits" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Have Someone, Information Extraction Tool How" .

onto:topic_2 a onto:TopicNode ;
    onto:coversChunk sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf_chunk_0,
        sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf_chunk_1,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_0,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_1,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_2,
        sources:node_12633_printable_pdfpdf_chunk_1 ;
    onto:coversConcept onto:Actionable_Insight,
        onto:Amazon_Web_Services,
        onto:Data_Ownership,
        onto:Data_Structure,
        onto:European_Commission,
        onto:Intro_Set,
        onto:Myth_Debunker,
        onto:Post_Draft,
        onto:Why_Linked_Data_Infrastructure,
        onto:Wistor_Alternative ;
    rdfs:comment "Clusters concepts: Data Structure, Post Draft, Intro Set" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Data Structure, Post Draft" .

onto:topic_20 a onto:TopicNode ;
    onto:coversChunk sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_7 ;
    onto:coversConcept onto:Corporate_Social_Responsibility_Policy,
        onto:How_GraphDB_11_111_Let_Organizations_Unlock_AI-powered_Knowledge_Graphs_GraphDB_latest_versions_power_enterprise_AI_with_knowledge-grounded_data_LLM_integration_scalable_graph_performance_Go_to_page_httpswwwontotextcomcompanynewshow-graphdb-11-enables-organizations-to-create-an-enterprise-wide-data-fabric-for-reliable-ai_CDW21_Talk_RDF_Leveled_the_Advantages_of_LPG_and_Keeps_3_Key_Benefits_Standards_Semantics_Interoperability_A_talk_by_Atanas_Kiryakov_CEO_at_Ontotext_presented_at_Connected_Data_World_2021_Go_to_page_httpswwwontotextcomknowledgehubvideoscdw21-rdf-leveled-the-advantages-of-lpg_Graphwise_Reconciliation_Build_Custom_Reconciliation_Services_Over_Your_Knowledge_Graphs_Read_about_how_Graphwise_Reconciliation_empowers_seamless_data_integration_and_enrichment_by_building_custom_reconciliation_services_over_knowledge_graphs_Go_to_page_httpswwwontotextcomcompanynewsgraphwise-reconciliation-build-custom-reconciliation-services-over-your-knowledge-graphs_Knowledge_Graphs_101_The_Story_and_Benefits_Behind_the_Hype_Ontotexts_Doug_Kimball_talks_about_data_management_challenges_data_fabric_knowledge_graphs_and_more_in_this_Dataversity_article_Go_to_page_httpswwwontotextcomblogknowledge-graphs-101-the-story-and-benefits-behind-the-hype_How_Far_We_Can_Go_with_GenAI_as_an_Information_Extraction_Tool_How_we_used_Ontotext_GraphDB_and_LLMs_to_improve_CV_selection_Go_to_page_httpswwwontotextcombloghow-far-we-can-go-with-genai-as-an-information-extraction-tool_Choosing_A_Graph_Data_Model_to_Best_Serve_Your_Use_Case_This_post_discusses_the_LPG-RDF_vis-a-vis_graph_models_and_why_enterprises_should_invest_in_knowledge_graphs_with_RDFs_for_their_data_management_practices_Go_to_page_httpswwwontotextcomblogchoosing-a-graph-data-model-to-best-serve-your-use-case_My_Dear_Watson_it_is_Great_to_Have_Someone_to_Talk_to_Join_us_to_learn_how_we_empower_users_to_sift_through_a_large_pool_of_data_with_the_help_of_a_trusted_assistant_the_GraphDB_108_Talk_To_Your_Graph_agent_Go_to_page_httpswwwontotextcombloggraphdb-talk-to-your-graph-customized-agent_View_More,
        onto:Privacy_Policy,
        onto:Semantic_Data_Modelling,
        onto:Share_Buttons ;
    rdfs:comment "Clusters concepts: Corporate Social Responsibility Policy, Share Buttons, Semantic Data Modelling" ;
    skos:definition "Auto-generated topic covering 5 domain concepts" ;
    skos:prefLabel "Topic: Corporate Social Responsibility Policy, Share Buttons" .

onto:topic_3 a onto:TopicNode ;
    onto:coversChunk sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_1,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_2 ;
    onto:coversConcept onto:Cloud_Middleware,
        onto:Cloud_Silos,
        onto:Economic_Complexity,
        onto:Introduction_Section,
        onto:Microsoft_Azure,
        onto:Native_Linked_Data,
        onto:Opaque_Cost,
        onto:Strategic_Migration,
        onto:Technical_Complexity,
        onto:Wistor_Blog_Post_Draft ;
    rdfs:comment "Clusters concepts: Cloud Silos, Native Linked Data, Introduction Section" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Cloud Silos, Native Linked Data" .

onto:topic_4 a onto:TopicNode ;
    onto:coversChunk sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_2,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_3,
        sources:YouTube-8nbb6CwpPMA_chunk_0 ;
    onto:coversConcept onto:Atanas_Kirakov,
        onto:Enhanced_Solutions,
        onto:Housekeeping_Details,
        onto:Intro,
        onto:Mandated_Interoperability,
        onto:Native_Standards,
        onto:Our_Journey_and_Current_Focus,
        onto:Suggested_Images,
        onto:Welcome_to_the_OntoText_Webinar,
        onto:YouTube-8nbb6CwpPMA ;
    rdfs:comment "Clusters concepts: Mandated Interoperability, Enhanced Solutions, Native Standards" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Mandated Interoperability, Enhanced Solutions" .

onto:topic_5 a onto:TopicNode ;
    onto:coversChunk sources:YouTube-8nbb6CwpPMA_chunk_0,
        sources:YouTube-8nbb6CwpPMA_chunk_1 ;
    onto:coversConcept onto:Advantages_of_RDF_Over_Labeled_Property_Graphs,
        onto:Atanas_Kirakov_Thank,
        onto:Current_Focus,
        onto:Graph_Traversal,
        onto:Jason_Stokov,
        onto:Knowledge_Graphs_and_Technology,
        onto:Presentation_by_Atanas_Kirakov,
        onto:RDF-Star_A_Game_Changer,
        onto:Sirima_Holding_Group,
        onto:The_Importance_of_RDF ;
    rdfs:comment "Clusters concepts: Presentation by Atanas Kirakov, Jason Stokov, Sirima Holding Group" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Presentation by Atanas Kirakov, Jason Stokov" .

onto:topic_6 a onto:TopicNode ;
    onto:coversChunk sources:YouTube-8nbb6CwpPMA_chunk_1,
        sources:YouTube-8nbb6CwpPMA_chunk_2,
        sources:YouTube_Links_to_Process_chunk_0 ;
    onto:coversConcept onto:Add_one_URL_per_line_lines_starting_with_are_ignored,
        onto:Conclusion_and_QA,
        onto:Game_Changer,
        onto:Graph_Traversal_and_Performance,
        onto:Knowledge_Graphs_Knowledge,
        onto:PROCESSED_httpswwwyoutubecomwatchv8nbb6CwpPMA,
        onto:Resource_Description_Framework,
        onto:Technology_At,
        onto:The_Value_of_Knowledge_Graphs,
        onto:YouTube_Links_to_Process ;
    rdfs:comment "Clusters concepts: Technology At, Resource Description Framework, Game Changer" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Technology At, Resource Description Framework" .

onto:topic_7 a onto:TopicNode ;
    onto:coversChunk sources:arxiv_13054054v1pdf_chunk_0,
        sources:arxiv_200502614v1pdf_chunk_0 ;
    onto:coversConcept onto:Aline_Senart,
        onto:Cleanness_Consistency_Comprehensibility_Completeness,
        onto:Data_Quality,
        onto:Information_Science,
        onto:International_Journal,
        onto:Open_Data,
        onto:Performance_Quality,
        onto:Renaud_Delbru,
        onto:Science_University,
        onto:Tim_Berners ;
    rdfs:comment "Clusters concepts: Performance Quality, Aline Senart, Open Data" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Performance Quality, Aline Senart" .

onto:topic_8 a onto:TopicNode ;
    onto:coversChunk sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf_chunk_0,
        sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf_chunk_1,
        sources:arxiv_200502614v1pdf_chunk_0,
        sources:node_12633_printable_pdfpdf_chunk_1 ;
    onto:coversConcept onto:Electronic_Government,
        onto:European_Data_Portal,
        onto:Feature_Comparison,
        onto:Interaction_Support,
        onto:Member_State,
        onto:Open_Data_Solution,
        onto:Sci_Data,
        onto:Semantic_Web_Activity_Homepage,
        onto:Semantic_Web_Technologies_Fabian,
        onto:Weizenbaum_Institute ;
    rdfs:comment "Clusters concepts: European Data Portal, Open Data Solution, Interaction Support" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: European Data Portal, Open Data Solution" .

onto:topic_9 a onto:TopicNode ;
    onto:coversChunk sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf_chunk_0,
        sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf_chunk_1,
        sources:The_EU_Data_Act_explained__rights_obligations_and_challenges_for_data_holders_and_manufacturerspdf_chunk_0 ;
    onto:coversConcept onto:Brochure_Find,
        onto:Cloud_Rulebook_To,
        onto:Data_Regulation,
        onto:Edge_Computing,
        onto:European_Union,
        onto:Free_Flow,
        onto:General_Data_Protection_Regulation,
        onto:Horizon_Europe,
        onto:Industrial_Data,
        onto:Shaping_Europe ;
    rdfs:comment "Clusters concepts: Industrial Data, Free Flow, Edge Computing" ;
    skos:definition "Auto-generated topic covering 10 domain concepts" ;
    skos:prefLabel "Topic: Industrial Data, Free Flow" .

sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf a onto:Document ;
    rdfs:label "Cloud and Edge Computing_ a different way of using IT — Brochure _ Shaping Europe’s digital future.pdf" ;
    onto:hasChunk sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf_chunk_0,
        sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf_chunk_1 ;
    onto:path "Cloud and Edge Computing_ a different way of using IT — Brochure _ Shaping Europe’s digital future.pdf" ;
    onto:sourceFormat "application/pdf" .

sources:Cloud_switching_under_the_EU_Data_Actpdf a onto:Document ;
    rdfs:label "Cloud switching under the EU Data Act.pdf" ;
    onto:hasChunk sources:Cloud_switching_under_the_EU_Data_Actpdf_chunk_0 ;
    onto:path "Cloud switching under the EU Data Act.pdf" ;
    onto:sourceFormat "application/pdf" .

sources:Knowledge_Graphs__Redefining_Data_Management_for_the_Modern_Enterprisepdf a onto:Document ;
    rdfs:label "Knowledge Graphs_ Redefining Data Management for the Modern Enterprise.pdf" ;
    onto:hasChunk sources:Knowledge_Graphs__Redefining_Data_Management_for_the_Modern_Enterprisepdf_chunk_0 ;
    onto:path "Knowledge Graphs_ Redefining Data Management for the Modern Enterprise.pdf" ;
    onto:sourceFormat "application/pdf" .

sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data a onto:Document ;
    rdfs:label "LinkedIn+Blog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data" ;
    onto:hasChunk sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_0,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_1,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_2,
        sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_3 ;
    onto:mentions onto:Intro ;
    onto:path "LinkedIn+Blog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data.md" ;
    onto:sourceFormat "text/markdown" .

sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability a onto:Document ;
    rdfs:label "RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits: Standards, Semantics & Interoperability" ;
    onto:hasChunk sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_0,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_1,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_2,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_3,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_4,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_5,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_6,
        sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_7 ;
    onto:mentions onto:How_GraphDB_11_111_Let_Organizations_Unlock_AI-powered_Knowledge_Graphs_GraphDB_latest_versions_power_enterprise_AI_with_knowledge-grounded_data_LLM_integration_scalable_graph_performance_Go_to_page_httpswwwontotextcomcompanynewshow-graphdb-11-enables-organizations-to-create-an-enterprise-wide-data-fabric-for-reliable-ai_CDW21_Talk_RDF_Leveled_the_Advantages_of_LPG_and_Keeps_3_Key_Benefits_Standards_Semantics_Interoperability_A_talk_by_Atanas_Kiryakov_CEO_at_Ontotext_presented_at_Connected_Data_World_2021_Go_to_page_httpswwwontotextcomknowledgehubvideoscdw21-rdf-leveled-the-advantages-of-lpg_Graphwise_Reconciliation_Build_Custom_Reconciliation_Services_Over_Your_Knowledge_Graphs_Read_about_how_Graphwise_Reconciliation_empowers_seamless_data_integration_and_enrichment_by_building_custom_reconciliation_services_over_knowledge_graphs_Go_to_page_httpswwwontotextcomcompanynewsgraphwise-reconciliation-build-custom-reconciliation-services-over-your-knowledge-graphs_Knowledge_Graphs_101_The_Story_and_Benefits_Behind_the_Hype_Ontotexts_Doug_Kimball_talks_about_data_management_challenges_data_fabric_knowledge_graphs_and_more_in_this_Dataversity_article_Go_to_page_httpswwwontotextcomblogknowledge-graphs-101-the-story-and-benefits-behind-the-hype_How_Far_We_Can_Go_with_GenAI_as_an_Information_Extraction_Tool_How_we_used_Ontotext_GraphDB_and_LLMs_to_improve_CV_selection_Go_to_page_httpswwwontotextcombloghow-far-we-can-go-with-genai-as-an-information-extraction-tool_Choosing_A_Graph_Data_Model_to_Best_Serve_Your_Use_Case_This_post_discusses_the_LPG-RDF_vis-a-vis_graph_models_and_why_enterprises_should_invest_in_knowledge_graphs_with_RDFs_for_their_data_management_practices_Go_to_page_httpswwwontotextcomblogchoosing-a-graph-data-model-to-best-serve-your-use-case_My_Dear_Watson_it_is_Great_to_Have_Someone_to_Talk_to_Join_us_to_learn_how_we_empower_users_to_sift_through_a_large_pool_of_data_with_the_help_of_a_trusted_assistant_the_GraphDB_108_Talk_To_Your_Graph_agent_Go_to_page_httpswwwontotextcombloggraphdb-talk-to-your-graph-customized-agent_View_More,
        onto:Meet_the_speakers,
        onto:SynthMedic_Utilizing_large_language_models_for_synthetic_discharge_summary_generation_correction_and_validationhttpswwwontotextcomknowledgehubpublicationsusing-llm-for-synthetic-discharge-summary-generation-correction-validation,
        onto:Want_more_like_this_learn_more_about_the_recommended_contentdataimagesvgxml3Csvg20xmlnshttpwwww3org2000svg20viewBox0200201620163E3Csvg3Elearn_more_about_the_recommended_contentwp-contentuploads202407icon-help-circlesvg_The_Ontotext_Recommendations_engine_combines_content_and_its_semantic_fingerprint_to_retrieve_knowledge_graph-driven_recommendations_It_is_integrated_with_the_Ontotext_Metadata_Studio_tagging_to_power_meaningful_recommendations_based_on_both_semantic_relevancy_and_recency,
        onto:Want_to_chat_more_with_us_Reach_out_and_lets_do_it ;
    onto:path "RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext.html" ;
    onto:sourceFormat "text/html" .

sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability a onto:Document ;
    rdfs:label "The EU Data Act and the Promise of Linked Data: Addressing Vendor Lock-in and Data Silos Through Interoperability" ;
    onto:hasChunk sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability_chunk_0,
        sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability_chunk_1,
        sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability_chunk_2 ;
    onto:hasTag onto:ai-generated,
        onto:knowledge-graph,
        onto:synthesis ;
    onto:mentions onto:Conclusion_A_Call_for_Action,
        onto:Data_Interoperability_The_Key_to_Breaking_Down_Barriers,
        onto:Data_Silos_A_Critical_Challenge,
        onto:The_EU_Data_Act_A_Regulatory_Framework_for_Data_Empowerment,
        onto:The_Interplay_Between_the_EU_Data_Act_and_Linked_Data ;
    onto:path "knowledge_graph_article.md" ;
    onto:sourceFormat "text/markdown" ;
    dct:title "Knowledge Graph Article" .

sources:The_EU_Data_Act_explained__rights_obligations_and_challenges_for_data_holders_and_manufacturerspdf a onto:Document ;
    rdfs:label "The EU Data Act explained_ rights, obligations and challenges for data holders and manufacturers.pdf" ;
    onto:hasChunk sources:The_EU_Data_Act_explained__rights_obligations_and_challenges_for_data_holders_and_manufacturerspdf_chunk_0 ;
    onto:path "The EU Data Act explained_ rights, obligations and challenges for data holders and manufacturers.pdf" ;
    onto:sourceFormat "application/pdf" .

sources:The_FAIR_Guiding_Principles_for_scientific_data_management_and_stewardshippdf a onto:Document ;
    rdfs:label "The FAIR Guiding Principles for scientific data management and stewardship.pdf" ;
    onto:hasChunk sources:The_FAIR_Guiding_Principles_for_scientific_data_management_and_stewardshippdf_chunk_0 ;
    onto:path "The FAIR Guiding Principles for scientific data management and stewardship.pdf" ;
    onto:sourceFormat "application/pdf" .

sources:YouTube-8nbb6CwpPMA a onto:Document ;
    rdfs:label "YouTube-8nbb6CwpPMA" ;
    onto:hasChunk sources:YouTube-8nbb6CwpPMA_chunk_0,
        sources:YouTube-8nbb6CwpPMA_chunk_1,
        sources:YouTube-8nbb6CwpPMA_chunk_2 ;
    onto:hasTag onto:transcript,
        onto:video,
        onto:youtube ;
    onto:mentions onto:Presentation_by_Atanas_Kirakov,
        onto:Welcome_to_the_OntoText_Webinar ;
    onto:path "YouTube-8nbb6CwpPMA.md" ;
    onto:sourceFormat "text/markdown" ;
    dct:created "2025-12-06T11:32:10.505712" ;
    dct:title "YouTube-8nbb6CwpPMA" .

sources:YouTube_Links_to_Process a onto:Document ;
    rdfs:label "YouTube Links to Process" ;
    onto:hasChunk sources:YouTube_Links_to_Process_chunk_0 ;
    onto:path "youtube_links.txt" ;
    onto:sourceFormat "text/plain" .

sources:arxiv_13054054v1pdf a onto:Document ;
    rdfs:label "arxiv_1305.4054v1.pdf" ;
    onto:hasChunk sources:arxiv_13054054v1pdf_chunk_0 ;
    onto:path "arxiv_1305.4054v1.pdf" ;
    onto:sourceFormat "application/pdf" .

sources:arxiv_200502614v1pdf a onto:Document ;
    rdfs:label "arxiv_2005.02614v1.pdf" ;
    onto:hasChunk sources:arxiv_200502614v1pdf_chunk_0 ;
    onto:path "arxiv_2005.02614v1.pdf" ;
    onto:sourceFormat "application/pdf" .

sources:node_12633_printable_pdfpdf a onto:Document ;
    rdfs:label "node_12633_printable_pdf.pdf" ;
    onto:hasChunk sources:node_12633_printable_pdfpdf_chunk_0,
        sources:node_12633_printable_pdfpdf_chunk_1 ;
    onto:path "node_12633_printable_pdf.pdf" ;
    onto:sourceFormat "application/pdf" .

sources:tr_104410v010101ppdf a onto:Document ;
    rdfs:label "tr_104410v010101p.pdf" ;
    onto:hasChunk sources:tr_104410v010101ppdf_chunk_0 ;
    onto:path "tr_104410v010101p.pdf" ;
    onto:sourceFormat "application/pdf" .

onto:ai-generated a onto:Tag ;
    rdfs:label "ai-generated" .

onto:knowledge-graph a onto:Tag ;
    rdfs:label "knowledge-graph" .

onto:synthesis a onto:Tag ;
    rdfs:label "synthesis" .

onto:transcript a onto:Tag ;
    rdfs:label "transcript" .

onto:video a onto:Tag ;
    rdfs:label "video" .

onto:youtube a onto:Tag ;
    rdfs:label "youtube" .

onto:Actionable_Insight a onto:DomainConcept ;
    skos:prefLabel "Actionable Insight" .

onto:Add_one_URL_per_line_lines_starting_with_are_ignored a onto:DomainConcept ;
    skos:prefLabel "Add one URL per line, lines starting with # are ignored" .

onto:Addressing_Vendor_Lock a onto:DomainConcept ;
    skos:prefLabel "Addressing Vendor Lock" .

onto:Advantages_of_RDF_Over_Labeled_Property_Graphs a onto:DomainConcept ;
    skos:prefLabel "Advantages of RDF Over Labeled Property Graphs" .

onto:Aline_Senart a onto:DomainConcept ;
    skos:prefLabel "Aline Senart" .

onto:All_Blog a onto:DomainConcept ;
    skos:prefLabel "All Blog" .

onto:Allianz_Insurance a onto:DomainConcept ;
    skos:prefLabel "Allianz Insurance" .

onto:Amazon_Web_Services a onto:DomainConcept ;
    skos:prefLabel "Amazon Web Services" .

onto:Atanas_Kirakov a onto:DomainConcept ;
    skos:prefLabel "Atanas Kirakov" .

onto:Atanas_Kirakov_Thank a onto:DomainConcept ;
    skos:prefLabel """Atanas Kirakov

Thank""" .

onto:Atanas_Kiryakov a onto:DomainConcept ;
    skos:prefLabel "Atanas Kiryakov" .

onto:Basic_Co a onto:DomainConcept ;
    skos:prefLabel "Basic Co" .

onto:Breaking_Down_Barriers a onto:DomainConcept ;
    skos:prefLabel "Breaking Down Barriers" .

onto:Brochure_Find a onto:DomainConcept ;
    skos:prefLabel """Brochure
Find""" .

onto:Career_Insights_Imprint_Code a onto:DomainConcept ;
    skos:prefLabel """Career
Insights
Imprint
Code""" .

onto:Change_Requests a onto:DomainConcept ;
    skos:prefLabel "Change Requests" .

onto:Christopher_Eduard a onto:DomainConcept ;
    skos:prefLabel "Christopher Eduard" .

onto:Cleanness_Consistency_Comprehensibility_Completeness a onto:DomainConcept ;
    skos:prefLabel """Cleanness 
Consistency 
Comprehensibility 
Completeness""" .

onto:Cloud_Computing_Data a onto:DomainConcept ;
    skos:prefLabel "Cloud Computing Data" .

onto:Cloud_Middleware a onto:DomainConcept ;
    skos:prefLabel "Cloud Middleware" .

onto:Cloud_Rulebook_To a onto:DomainConcept ;
    skos:prefLabel """Cloud Rulebook
To""" .

onto:Cloud_Silos a onto:DomainConcept ;
    skos:prefLabel "Cloud Silos" .

onto:Commission_Implementing_Decision a onto:DomainConcept ;
    skos:prefLabel "Commission Implementing Decision" .

onto:Common_European_Data_Spaces a onto:DomainConcept ;
    skos:prefLabel "Common European Data Spaces" .

onto:Common_European_Dataspaces a onto:DomainConcept ;
    skos:prefLabel "Common European Dataspaces" .

onto:Concept_Web_Alliance a onto:DomainConcept ;
    skos:prefLabel "Concept Web Alliance" .

onto:Conclusion_and_QA a onto:DomainConcept ;
    skos:prefLabel "Conclusion and Q&A" .

onto:Connected_Data_World a onto:DomainConcept ;
    skos:prefLabel "Connected Data World" .

onto:Corporate_Social_Responsibility_Policy a onto:DomainConcept ;
    skos:prefLabel "Corporate Social Responsibility Policy" .

onto:Creative_Commons a onto:DomainConcept ;
    skos:prefLabel "Creative Commons" .

onto:Creative_Commons_Attribution a onto:DomainConcept ;
    skos:prefLabel "Creative Commons Attribution" .

onto:Critical_Challenge_Data a onto:DomainConcept ;
    skos:prefLabel """Critical Challenge

Data""" .

onto:Current_Focus a onto:DomainConcept ;
    skos:prefLabel "Current Focus" .

onto:Data_Act_Action a onto:DomainConcept ;
    skos:prefLabel """Data
Act
Action""" .

onto:Data_Act_Businesses a onto:DomainConcept ;
    skos:prefLabel """Data Act
 Businesses""" .

onto:Data_Governance_Act a onto:DomainConcept ;
    skos:prefLabel """Data
Governance Act""" .

onto:Data_Lock a onto:DomainConcept ;
    skos:prefLabel "Data Lock" .

onto:Data_Management a onto:DomainConcept ;
    skos:prefLabel "Data Management" .

onto:Data_Ownership a onto:DomainConcept ;
    skos:prefLabel "Data Ownership" .

onto:Data_Quality a onto:DomainConcept ;
    skos:prefLabel "Data Quality" .

onto:Data_Regulation a onto:DomainConcept ;
    skos:prefLabel "Data Regulation" .

onto:Data_Security_Data a onto:DomainConcept ;
    skos:prefLabel """Data Security
Data""" .

onto:Data_Silos a onto:DomainConcept ;
    skos:prefLabel "Data Silos" .

onto:Data_Space a onto:DomainConcept ;
    skos:prefLabel "Data Space" .

onto:Digital_Europe a onto:DomainConcept ;
    skos:prefLabel "Digital Europe" .

onto:Digital_Law a onto:DomainConcept ;
    skos:prefLabel "Digital Law" .

onto:Domain_Knowledge_Graph a onto:DomainConcept ;
    skos:prefLabel "Domain Knowledge Graph" .

onto:Dutch_Techcenter a onto:DomainConcept ;
    skos:prefLabel "Dutch Techcenter" .

onto:Economic_Complexity a onto:DomainConcept ;
    skos:prefLabel "Economic Complexity" .

onto:Edge_Computing a onto:DomainConcept ;
    skos:prefLabel "Edge Computing" .

onto:Electronic_Government a onto:DomainConcept ;
    skos:prefLabel "Electronic Government" .

onto:Electrotechnical_Standardization a onto:DomainConcept ;
    skos:prefLabel "Electrotechnical Standardization" .

onto:Enhanced_Solutions a onto:DomainConcept ;
    skos:prefLabel "Enhanced Solutions" .

onto:Enhancing_Data_Interoperability a onto:DomainConcept ;
    skos:prefLabel "Enhancing Data Interoperability" .

onto:Europe_Bulgaria a onto:DomainConcept ;
    skos:prefLabel """Europe

Bulgaria""" .

onto:European_Data_Innovation_Board a onto:DomainConcept ;
    skos:prefLabel """European Data
Innovation Board""" .

onto:European_Data_Portal a onto:DomainConcept ;
    skos:prefLabel """European Data
Portal""" .

onto:European_Parliament a onto:DomainConcept ;
    skos:prefLabel "European Parliament" .

onto:European_Trusted_Data_Framework a onto:DomainConcept ;
    skos:prefLabel "European Trusted Data Framework" .

onto:Feature_Comparison a onto:DomainConcept ;
    skos:prefLabel "Feature Comparison" .

onto:Free_Flow a onto:DomainConcept ;
    skos:prefLabel "Free Flow" .

onto:Game_Changer a onto:DomainConcept ;
    skos:prefLabel "Game Changer" .

onto:General_Data_Protection_Regulation a onto:DomainConcept ;
    skos:prefLabel "General Data Protection Regulation" .

onto:General_Terms a onto:DomainConcept ;
    skos:prefLabel "General Terms" .

onto:Gergana_Petkova a onto:DomainConcept ;
    skos:prefLabel "Gergana Petkova" .

onto:Graph_Analytics a onto:DomainConcept ;
    skos:prefLabel "Graph Analytics" .

onto:Graph_Center a onto:DomainConcept ;
    skos:prefLabel "Graph Center" .

onto:Graph_Traversal a onto:DomainConcept ;
    skos:prefLabel "Graph Traversal" .

onto:Graph_Traversal_and_Performance a onto:DomainConcept ;
    skos:prefLabel "Graph Traversal and Performance" .

onto:Graphwise_Reconciliation a onto:DomainConcept ;
    skos:prefLabel "Graphwise Reconciliation" .

onto:Have_Someone a onto:DomainConcept ;
    skos:prefLabel "Have Someone" .

onto:Horizon_Europe a onto:DomainConcept ;
    skos:prefLabel "Horizon Europe" .

onto:Housekeeping_Details a onto:DomainConcept ;
    skos:prefLabel "Housekeeping Details" .

onto:How_GraphDB_11_111_Let_Organizations_Unlock_AI-powered_Knowledge_Graphs_GraphDB_latest_versions_power_enterprise_AI_with_knowledge-grounded_data_LLM_integration_scalable_graph_performance_Go_to_page_httpswwwontotextcomcompanynewshow-graphdb-11-enables-organizations-to-create-an-enterprise-wide-data-fabric-for-reliable-ai_CDW21_Talk_RDF_Leveled_the_Advantages_of_LPG_and_Keeps_3_Key_Benefits_Standards_Semantics_Interoperability_A_talk_by_Atanas_Kiryakov_CEO_at_Ontotext_presented_at_Connected_Data_World_2021_Go_to_page_httpswwwontotextcomknowledgehubvideoscdw21-rdf-leveled-the-advantages-of-lpg_Graphwise_Reconciliation_Build_Custom_Reconciliation_Services_Over_Your_Knowledge_Graphs_Read_about_how_Graphwise_Reconciliation_empowers_seamless_data_integration_and_enrichment_by_building_custom_reconciliation_services_over_knowledge_graphs_Go_to_page_httpswwwontotextcomcompanynewsgraphwise-reconciliation-build-custom-reconciliation-services-over-your-knowledge-graphs_Knowledge_Graphs_101_The_Story_and_Benefits_Behind_the_Hype_Ontotexts_Doug_Kimball_talks_about_data_management_challenges_data_fabric_knowledge_graphs_and_more_in_this_Dataversity_article_Go_to_page_httpswwwontotextcomblogknowledge-graphs-101-the-story-and-benefits-behind-the-hype_How_Far_We_Can_Go_with_GenAI_as_an_Information_Extraction_Tool_How_we_used_Ontotext_GraphDB_and_LLMs_to_improve_CV_selection_Go_to_page_httpswwwontotextcombloghow-far-we-can-go-with-genai-as-an-information-extraction-tool_Choosing_A_Graph_Data_Model_to_Best_Serve_Your_Use_Case_This_post_discusses_the_LPG-RDF_vis-a-vis_graph_models_and_why_enterprises_should_invest_in_knowledge_graphs_with_RDFs_for_their_data_management_practices_Go_to_page_httpswwwontotextcomblogchoosing-a-graph-data-model-to-best-serve-your-use-case_My_Dear_Watson_it_is_Great_to_Have_Someone_to_Talk_to_Join_us_to_learn_how_we_empower_users_to_sift_through_a_large_pool_of_data_with_the_help_of_a_trusted_assistant_the_GraphDB_108_Talk_To_Your_Graph_agent_Go_to_page_httpswwwontotextcombloggraphdb-talk-to-your-graph-customized-agent_View_More a onto:DomainConcept ;
    skos:prefLabel "[How GraphDB 11 11.1 Let Organizations Unlock AI-powered Knowledge Graphs GraphDB latest versions power enterprise AI with knowledge-grounded data, LLM integration & scalable graph performance Go to page  ](https://www.ontotext.com/company/news/how-graphdb-11-enables-organizations-to-create-an-enterprise-wide-data-fabric-for-reliable-ai) ## [CDW21 Talk: RDF Leveled the Advantages of LPG and Keeps 3 Key Benefits: Standards, Semantics & Interoperability A talk by Atanas Kiryakov, CEO at Ontotext, presented at Connected Data World 2021 Go to page  ](https://www.ontotext.com/knowledgehub/videos/cdw21-rdf-leveled-the-advantages-of-lpg/) ## [Graphwise Reconciliation: Build Custom Reconciliation Services Over Your Knowledge Graphs Read about how Graphwise Reconciliation empowers seamless data integration and enrichment by building custom reconciliation services over knowledge graphs. Go to page  ](https://www.ontotext.com/company/news/graphwise-reconciliation-build-custom-reconciliation-services-over-your-knowledge-graphs) ## [Knowledge Graphs 101: The Story (and Benefits) Behind the Hype Ontotext's Doug Kimball talks about data management challenges, data fabric, knowledge graphs and more in this Dataversity article Go to page  ](https://www.ontotext.com/blog/knowledge-graphs-101-the-story-and-benefits-behind-the-hype/) ## [How Far We Can Go with GenAI as an Information Extraction Tool How we used Ontotext GraphDB and LLMs to improve CV selection Go to page  ](https://www.ontotext.com/blog/how-far-we-can-go-with-genai-as-an-information-extraction-tool/) ## [Choosing A Graph Data Model to Best Serve Your Use Case This post discusses the LPG-RDF vis-a-vis graph models and why enterprises should invest in knowledge graphs with RDFs for their data management practices Go to page  ](https://www.ontotext.com/blog/choosing-a-graph-data-model-to-best-serve-your-use-case/) ## [My Dear Watson, it is Great to Have Someone to Talk to Join us to learn how we empower users to sift through a large pool of data with the help of a trusted assistant – the GraphDB 10.8 Talk To Your Graph agent. Go to page  ](https://www.ontotext.com/blog/graphdb-talk-to-your-graph-customized-agent/) View More" .

onto:Industrial_Data a onto:DomainConcept ;
    skos:prefLabel "Industrial Data" .

onto:Informatics_Assoc a onto:DomainConcept ;
    skos:prefLabel "Informatics Assoc" .

onto:Information_Extraction_Tool_How a onto:DomainConcept ;
    skos:prefLabel "Information Extraction Tool How" .

onto:Information_Science a onto:DomainConcept ;
    skos:prefLabel "Information Science" .

onto:Insights_Blog a onto:DomainConcept ;
    skos:prefLabel "Insights Blog" .

onto:Interaction_Support a onto:DomainConcept ;
    skos:prefLabel """Interaction
Support""" .

onto:International_Journal a onto:DomainConcept ;
    skos:prefLabel "International Journal" .

onto:Interoperability_Why a onto:DomainConcept ;
    skos:prefLabel """Interoperability
Why""" .

onto:Intro a onto:DomainConcept ;
    skos:prefLabel "Intro" .

onto:Intro_Set a onto:DomainConcept ;
    skos:prefLabel """Intro

Set""" .

onto:Introduction_Section a onto:DomainConcept ;
    skos:prefLabel "Introduction Section" .

onto:Ivan_Koychev a onto:DomainConcept ;
    skos:prefLabel "Ivan Koychev" .

onto:Jason_Stokov a onto:DomainConcept ;
    skos:prefLabel "Jason Stokov" .

onto:Jointly_Designing a onto:DomainConcept ;
    skos:prefLabel "Jointly Designing" .

onto:Key_Benefits a onto:DomainConcept ;
    skos:prefLabel "Key Benefits" .

onto:Knowledge_Graph a onto:DomainConcept ;
    skos:prefLabel "Knowledge Graph" .

onto:Knowledge_Graphs_A_Tool_for_Enhancing_Data_Interoperability a onto:DomainConcept ;
    skos:prefLabel "Knowledge Graphs: A Tool for Enhancing Data Interoperability" .

onto:Knowledge_Graphs_Knowledge a onto:DomainConcept ;
    skos:prefLabel """Knowledge Graphs

Knowledge""" .

onto:Knowledge_Graphs_and_Technology a onto:DomainConcept ;
    skos:prefLabel "Knowledge Graphs and Technology" .

onto:Knowledge_graphs_are_the_next_generation_tool_for_helping_businesses_make_critical_decisions_based_on_harmonized_knowledge_models_and_data_derived_from_siloed_source_systems_Due_to_the_huge_value_generated_by_their_data_standardization_and_semantic_modelling_capabilities_knowledge_graphs_are_most_often_associated_with_data_integration_linking_unification_and_information_reuse_As_more_and_more_organizations_are_turning_to_knowledge_graphs_for_better_data_and_content_analytics_search_and_graph_exploration_become_key_requirements_also a onto:DomainConcept ;
    skos:prefLabel "Knowledge graphs are the next generation tool for helping businesses make critical decisions, based on harmonized knowledge models and data derived from siloed source systems. Due to the huge value generated by their data standardization and semantic modelling capabilities, knowledge graphs are most often associated with data integration, linking, unification and information reuse. As more and more organizations are turning to knowledge graphs for better data and content analytics, search and graph exploration become key requirements also." .

onto:Labeled_Property_Graphs a onto:DomainConcept ;
    skos:prefLabel "Labeled Property Graphs" .

onto:Lib_Magazine a onto:DomainConcept ;
    skos:prefLabel "Lib Magazine" .

onto:Linked_Data_Benchmarking_Council a onto:DomainConcept ;
    skos:prefLabel "Linked Data Benchmarking Council" .

onto:Linked_Data_Linked_Data a onto:DomainConcept ;
    skos:prefLabel """Linked Data

Linked Data""" .

onto:Lorentz_Workshop a onto:DomainConcept ;
    skos:prefLabel "Lorentz Workshop" .

onto:Making_Sense a onto:DomainConcept ;
    skos:prefLabel "Making Sense" .

onto:Mandated_Interoperability a onto:DomainConcept ;
    skos:prefLabel "Mandated Interoperability" .

onto:Member_States a onto:DomainConcept ;
    skos:prefLabel "Member States" .

onto:Microsoft_Azure a onto:DomainConcept ;
    skos:prefLabel "Microsoft Azure" .

onto:Modern_Enterprise a onto:DomainConcept ;
    skos:prefLabel """Modern
Enterprise""" .

onto:My_Dear_Watson a onto:DomainConcept ;
    skos:prefLabel "My Dear Watson" .

onto:Myth_Debunker a onto:DomainConcept ;
    skos:prefLabel "Myth Debunker" .

onto:Native_Linked_Data a onto:DomainConcept ;
    skos:prefLabel "Native Linked Data" .

onto:Native_Standards a onto:DomainConcept ;
    skos:prefLabel "Native Standards" .

onto:Offering_Success a onto:DomainConcept ;
    skos:prefLabel """Offering
Success""" .

onto:Ontotext_Atanas_Kiryakov a onto:DomainConcept ;
    skos:prefLabel """Ontotext

Atanas Kiryakov""" .

onto:Ontotext_Metadata_Studio a onto:DomainConcept ;
    skos:prefLabel "Ontotext Metadata Studio" .

onto:Ontotext_Refine a onto:DomainConcept ;
    skos:prefLabel "Ontotext Refine" .

onto:Ontotext_Semantic_Objects a onto:DomainConcept ;
    skos:prefLabel "Ontotext Semantic Objects" .

onto:Opaque_Cost a onto:DomainConcept ;
    skos:prefLabel "Opaque Cost" .

onto:Open_Data_Solution a onto:DomainConcept ;
    skos:prefLabel "Open Data Solution" .

onto:Our_Journey_and_Current_Focus a onto:DomainConcept ;
    skos:prefLabel "Our Journey and Current Focus" .

onto:PROCESSED_httpswwwyoutubecomwatchv8nbb6CwpPMA a onto:DomainConcept ;
    skos:prefLabel "[PROCESSED] https://www.youtube.com/watch?v=8nbb6CwpPMA" .

onto:Performance_Quality a onto:DomainConcept ;
    skos:prefLabel """Performance 
Quality""" .

onto:Post_Draft a onto:DomainConcept ;
    skos:prefLabel "Post Draft" .

onto:Powered_Target_Discovery a onto:DomainConcept ;
    skos:prefLabel "Powered Target Discovery" .

onto:Previous_Next a onto:DomainConcept ;
    skos:prefLabel "Previous Next" .

onto:Privacy_Policy a onto:DomainConcept ;
    skos:prefLabel "Privacy Policy" .

onto:Products_Overview a onto:DomainConcept ;
    skos:prefLabel "Products Overview" .

onto:Public_Procurement a onto:DomainConcept ;
    skos:prefLabel "Public Procurement" .

onto:RDF-Star_A_Game_Changer a onto:DomainConcept ;
    skos:prefLabel "RDF-Star: A Game Changer" .

onto:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability a onto:DomainConcept ;
    skos:prefLabel "RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits: Standards, Semantics & Interoperability" .

onto:Reading_Time a onto:DomainConcept ;
    skos:prefLabel "Reading Time" .

onto:Redefining_Data_Management a onto:DomainConcept ;
    skos:prefLabel """Redefining Data
Management""" .

onto:Regulatory_Framework a onto:DomainConcept ;
    skos:prefLabel "Regulatory Framework" .

onto:Renaud_Delbru a onto:DomainConcept ;
    skos:prefLabel "Renaud Delbru" .

onto:Research_Data a onto:DomainConcept ;
    skos:prefLabel """Research
Data""" .

onto:Resource_Description_Framework a onto:DomainConcept ;
    skos:prefLabel "Resource Description Framework" .

onto:Sci_Data a onto:DomainConcept ;
    skos:prefLabel "Sci Data" .

onto:Science_University a onto:DomainConcept ;
    skos:prefLabel """Science 
University""" .

onto:Scope_Chapter a onto:DomainConcept ;
    skos:prefLabel """Scope
Chapter""" .

onto:Semantic_Data_Modelling a onto:DomainConcept ;
    skos:prefLabel "Semantic Data Modelling" .

onto:Semantic_Web_Activity_Homepage a onto:DomainConcept ;
    skos:prefLabel "Semantic Web Activity Homepage" .

onto:Semantic_Web_Technologies_Fabian a onto:DomainConcept ;
    skos:prefLabel """Semantic Web Technologies
Fabian""" .

onto:Service_Deloitte_Survey a onto:DomainConcept ;
    skos:prefLabel """Service
Deloitte Survey""" .

onto:Service_Level_Agreements a onto:DomainConcept ;
    skos:prefLabel "Service Level Agreements" .

onto:Shaping_Europe a onto:DomainConcept ;
    skos:prefLabel "Shaping Europe" .

onto:Share_Buttons a onto:DomainConcept ;
    skos:prefLabel "Share Buttons" .

onto:Sirima_Holding_Group a onto:DomainConcept ;
    skos:prefLabel "Sirima Holding Group" .

onto:Sirma_Group_Holding a onto:DomainConcept ;
    skos:prefLabel "Sirma Group Holding" .

onto:Social_Network_Benchmark a onto:DomainConcept ;
    skos:prefLabel "Social Network Benchmark" .

onto:Sofia_Stock_Exchange a onto:DomainConcept ;
    skos:prefLabel "Sofia Stock Exchange" .

onto:Sofia_University a onto:DomainConcept ;
    skos:prefLabel "Sofia University" .

onto:Strategic_Migration a onto:DomainConcept ;
    skos:prefLabel "Strategic Migration" .

onto:Suggested_Images a onto:DomainConcept ;
    skos:prefLabel "Suggested Images" .

onto:Technical_Complexity a onto:DomainConcept ;
    skos:prefLabel "Technical Complexity" .

onto:Technology_At a onto:DomainConcept ;
    skos:prefLabel """Technology

At""" .

onto:Technology_Digitalization a onto:DomainConcept ;
    skos:prefLabel """Technology
Digitalization""" .

onto:The_EU_Data_Act_A_Regulatory_Framework_for_Data_Empowerment a onto:DomainConcept ;
    skos:prefLabel "The EU Data Act: A Regulatory Framework for Data Empowerment" .

onto:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability a onto:DomainConcept ;
    skos:prefLabel "The EU Data Act and the Promise of Linked Data: Addressing Vendor Lock-in and Data Silos Through Interoperability" .

onto:The_Importance_of_RDF a onto:DomainConcept ;
    skos:prefLabel "The Importance of RDF" .

onto:The_Promise_of_Linked_Data a onto:DomainConcept ;
    skos:prefLabel "The Promise of Linked Data" .

onto:The_Value_of_Knowledge_Graphs a onto:DomainConcept ;
    skos:prefLabel "The Value of Knowledge Graphs" .

onto:The_recording_of_this_webinar_is_available_on__YouTubehttpsyoutube8nbb6CwpPMA_ a onto:DomainConcept ;
    skos:prefLabel "The recording of this webinar is available on **_[YouTube](https://youtu.be/8nbb6CwpPMA)_**." .

onto:Till_Contzen_Why a onto:DomainConcept ;
    skos:prefLabel """Till Contzen

Why""" .

onto:Tim_Berners a onto:DomainConcept ;
    skos:prefLabel "Tim Berners" .

onto:Trade_Secrets_Directive a onto:DomainConcept ;
    skos:prefLabel "Trade Secrets Directive" .

onto:Trusted_Data_Transactions a onto:DomainConcept ;
    skos:prefLabel "Trusted Data Transactions" .

onto:Trustworthiness_Requirements a onto:DomainConcept ;
    skos:prefLabel "Trustworthiness Requirements" .

onto:Under_Chapter a onto:DomainConcept ;
    skos:prefLabel "Under Chapter" .

onto:Using_Template a onto:DomainConcept ;
    skos:prefLabel "Using Template" .

onto:Vasil_Vasilev a onto:DomainConcept ;
    skos:prefLabel "Vasil Vasilev" .

onto:Weizenbaum_Institute a onto:DomainConcept ;
    skos:prefLabel "Weizenbaum Institute" .

onto:Why_Linked_Data_Infrastructure a onto:DomainConcept ;
    skos:prefLabel "Why Linked Data Infrastructure" .

onto:Wistor_Alternative a onto:DomainConcept ;
    skos:prefLabel "Wistor Alternative" .

onto:Wistor_Blog_Post_Draft a onto:DomainConcept ;
    skos:prefLabel "Wistor Blog Post Draft" .

onto:YouTube-8nbb6CwpPMA a onto:DomainConcept ;
    skos:prefLabel "YouTube-8nbb6CwpPMA" .

onto:YouTube_Links_to_Process a onto:DomainConcept ;
    skos:prefLabel "YouTube Links to Process" .

onto:Zohar_Efroni a onto:DomainConcept ;
    skos:prefLabel "Zohar Efroni" .

sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_6 a onto:Chunk ;
    onto:chunkIndex 6 ;
    onto:chunkText """## Want more like this?  ![learn more about the recommended content](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2016%2016'%3E%3C/svg%3E)![learn more about the recommended content](/wp-content/uploads/2024/07/icon-help-circle.svg) The Ontotext Recommendations engine combines content and its semantic fingerprint to retrieve knowledge graph-driven recommendations. It is integrated with the Ontotext Metadata Studio tagging to power meaningful recommendations based on both semantic relevancy and recency.

Check out our knowledge graph's recommendations.

## [How GraphDB 11 11.1 Let Organizations Unlock AI-powered Knowledge Graphs GraphDB latest versions power enterprise AI with knowledge-grounded data, LLM integration & scalable graph performance Go to page  ](https://www.ontotext.com/company/news/how-graphdb-11-enables-organizations-to-create-an-enterprise-wide-data-fabric-for-reliable-ai) ## [CDW21 Talk: RDF Leveled the Advantages of LPG and Keeps 3 Key Benefits: Standards, Semantics & Interoperability A talk by Atanas Kiryakov, CEO at Ontotext, presented at Connected Data World 2021 Go to page  ](https://www.ontotext.com/knowledgehub/videos/cdw21-rdf-leveled-the-advantages-of-lpg/) ## [Graphwise Reconciliation: Build Custom Reconciliation Services Over Your Knowledge Graphs Read about how Graphwise Reconciliation empowers seamless data integration and enrichment by building custom reconciliation services over knowledge graphs. Go to page  ](https://www.ontotext.com/company/news/graphwise-reconciliation-build-custom-reconciliation-services-over-your-knowledge-graphs) ## [Knowledge Graphs 101: The Story (and Benefits) Behind the Hype Ontotext's Doug Kimball talks about data management challenges, data fabric, knowledge graphs and more in this Dataversity article Go to page  ](https://www.ontotext.com/blog/knowledge-graphs-101-the-story-and-benefits-behind-the-hype/) ## [How Far We Can Go with GenAI as an Information Extraction Tool How we used Ontotext GraphDB and LLMs to improve CV selection Go to page  ](https://www.ontotext.com/blog/how-far-we-can-go-with-genai-as-an-information-extraction-tool/) ## [Choosing A Graph Data Model to Best Serve Your Use Case This post discusses the LPG-RDF vis-a-vis graph models and why enterprises should invest in knowledge graphs with RDFs for their data management practices Go to page  ](https://www.ontotext.com/blog/choosing-a-graph-data-model-to-best-serve-your-use-case/) ## [My Dear Watson, it is Great to Have Someone to Talk to Join us to learn how we empower users to sift through a large pool of data with the help of a trusted assistant – the GraphDB 10.8 Talk To Your Graph agent. Go to page  ](https://www.ontotext.com/blog/graphdb-talk-to-your-graph-customized-agent/) View More

## Want to chat more with us? Reach out and let's do it!

[Contact us](https://www.ontotext.com/contact/)

[![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20166%2032'%3E%3C/svg%3E)![](https://www.ontotext.com/wp-content/uploads/2024/09/Ontotext-Logo-White.svg)](https://www.ontotext.com/)

[ ](https://github.com/Ontotext-AD) [ ](https://www.linkedin.com/company/ontotext-ad) [ ](https://medium.com/@ontotext) [ ](https://www.youtube.com/ontotext) [ ](https://twitter.com/ontotext)

Europe

Bulgaria

111R Tsarigradsko Shosse  
Synergy Tower, fl. 12  
Sofia 1784  
Bulgaria  
[+359 2 974 61 60](tel:+359 2 974 61 60)

Switzerland

Switzerland Innovation Park   
Basel Area   
Hegenheimermattweg 167A   
4123 Allschwil, Switzerland

North America""" ;
    onto:mentionsConcept onto:Connected_Data_World,
        onto:Europe_Bulgaria,
        onto:Graphwise_Reconciliation,
        onto:Have_Someone,
        onto:Information_Extraction_Tool_How,
        onto:Key_Benefits,
        onto:My_Dear_Watson,
        onto:Ontotext_Metadata_Studio,
        onto:Want_more_like_this_learn_more_about_the_recommended_contentdataimagesvgxml3Csvg20xmlnshttpwwww3org2000svg20viewBox0200201620163E3Csvg3Elearn_more_about_the_recommended_contentwp-contentuploads202407icon-help-circlesvg_The_Ontotext_Recommendations_engine_combines_content_and_its_semantic_fingerprint_to_retrieve_knowledge_graph-driven_recommendations_It_is_integrated_with_the_Ontotext_Metadata_Studio_tagging_to_power_meaningful_recommendations_based_on_both_semantic_relevancy_and_recency,
        onto:Want_to_chat_more_with_us_Reach_out_and_lets_do_it .

sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """# The EU Data Act and the Promise of Linked Data: Addressing Vendor Lock-in and Data Silos Through Interoperability

The digital transformation of industries has led to increased reliance on cloud platforms, raising critical issues surrounding vendor lock-in, data silos, and interoperability. This article emphasizes the importance of the EU Data Act as a regulatory framework that can mitigate these challenges while promoting the benefits of Linked Data and semantic web technologies.

## The EU Data Act: A Regulatory Framework for Data Empowerment

The EU Data Act represents a significant step towards enhancing data accessibility and interoperability across cloud platforms. By mandating that data holders provide easier access to data, the Act seeks to empower users and foster competition among service providers. This regulation is particularly crucial in addressing the pervasive issue of vendor lock-in, a situation in which customers become overly reliant on a single service provider due to proprietary technologies or data formats.

Vendor lock-in results in numerous challenges, including limited flexibility, higher costs, and a lack of innovation. The EU Data Act tackles these challenges by ensuring that companies have the right to move their data between different service providers seamlessly. This provision facilitates data portability, enabling organizations to avoid the pitfalls of being tied to a single vendor's ecosystem. In this way, the EU Data Act not only promotes fair competition but also empowers organizations to make strategic decisions about their data management practices.

## Data Silos: A Critical Challenge

Data silos are another significant challenge facing organizations today. These are isolated repositories of data that are not easily accessible or shareable with other systems or organizations. Data silos can arise from various factors, including the use of proprietary systems, a lack of standardized data formats, and organizational barriers to collaboration. The consequences of data silos are profound, as they hinder effective data governance, limit analytical capabilities, and restrict innovation.

The EU Data Act aims to dismantle these silos by promoting interoperability, allowing organizations to share data more freely. By encouraging the adoption of standardized data formats and protocols, the Act facilitates the integration of disparate data sources, ultimately leading to more comprehensive insights and better decision-making.

## Data Interoperability: The Key to Breaking Down Barriers""" ;
    onto:mentionsConcept onto:Addressing_Vendor_Lock,
        onto:Breaking_Down_Barriers,
        onto:Critical_Challenge_Data,
        onto:Data_Act,
        onto:Data_Interoperability_The_Key_to_Breaking_Down_Barriers,
        onto:Data_Silos,
        onto:Data_Silos_A_Critical_Challenge,
        onto:Linked_Data,
        onto:Regulatory_Framework,
        onto:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability .

sources:YouTube-8nbb6CwpPMA_chunk_2 a onto:Chunk ;
    onto:chunkIndex 2 ;
    onto:chunkText """Next, we will delve into graph traversal, a computationally intensive task. Finding paths in a graph can be challenging, but our extended SPARQL syntax allows for efficient path searching. This functionality is crucial for applications such as navigation, supply chain analysis, and social network analysis.

We benchmarked our graph path search extension against other engines, confirming that our approach not only meets but exceeds performance expectations in many cases.

### The Value of Knowledge Graphs

Knowledge graphs excel in scenarios where comprehensive domain knowledge is required. They enable organizations to unify diverse datasets and extract insights efficiently. This is particularly important in fields such as life sciences, finance, and infrastructure management, where understanding complex relationships is crucial.

### Conclusion and Q&A

In conclusion, RDF provides explicit semantics, interoperability, and a structured approach to metadata management that is essential for effective data governance. While labeled property graphs have their advantages in specific scenarios, RDF's comprehensive features make it a superior choice for enterprise-level applications involving knowledge graphs.

Thank you for your attention. I would now like to open the floor for questions. We appreciate your engagement and will ensure that all inquiries are addressed, whether during the session or afterward via email with the recording.

Thank you once again for joining us today, and I look forward to our discussion!

---

**Source:** [YouTube Video](https://www.youtube.com/watch?v=8nbb6CwpPMA)""" ;
    onto:mentionsConcept onto:Conclusion_and_QA,
        onto:Knowledge_Graphs_Knowledge,
        onto:The_Value_of_Knowledge_Graphs .

sources:YouTube_Links_to_Process_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """# YouTube Links to Process
# Add one URL per line, lines starting with # are ignored
# [PROCESSED] https://www.youtube.com/watch?v=8nbb6CwpPMA""" ;
    onto:mentionsConcept onto:Add_one_URL_per_line_lines_starting_with_are_ignored,
        onto:PROCESSED_httpswwwyoutubecomwatchv8nbb6CwpPMA,
        onto:YouTube_Links_to_Process .

sources:arxiv_13054054v1pdf_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """Data Quality Principles in the Semantic Web 
 
Ahmad Assaf and Aline Senart 
SAP Research, SAP Labs France SAS  
805 avenue du Dr. Maurice Donat, BP 1216, 06254 Mougins Cedex, France 
firstname.lastname@sap.com 
 
 
 
Abstract— The increasing size and availabilit y of web data make 
data quality a core challenge in many applications. Principles of 
data quality are recognized as essential to ensure  that data fit for 
their intended use in operations, decision -making, and planning. 
However, with the rise of the Semanti c Web, new data quality 
issues appear and require deeper consideration. In this paper, we 
propose to extend the data quality principles to the context of 
Semantic Web. Based on our extensive industrial experience in 
data integration, we identify five main classes suited for data 
quality in Semantic Web. For each class, we list the principles 
that are involved at all stages of the data management process. 
Following these principles will provide a sound basis for better 
decision-making within organizations an d will maximize long -
term data integration and interoperability.  
Keywords: Semantic Web, Data Quality, Data Integration, 
Quality Principles 
I.  INTRODUCTION  
 
Data quality is complex and involves data management, 
modeling, analysis, storage and presentation , quality control 
and assurance [1] . Moreover, data quality is subjective and as 
the saying goes "beauty is in the eye of the beholder". Data 
quality cannot indeed be assessed easily and independently by 
the user. The actual value of data is realized when it is used [2], 
thus the quality relates directly to the ability of satisfying the 
users’ continuous needs. It was found out that many data 
quality problems are in fact “data misinterpretations”, or 
problems with the data semantics [ 3]. For example, the P/E 
ratio 1  obtained for a certain stock from several financial 
information systems can be different. The ambiguity is caused 
by the fact that each source can have its own interpretation and 
application of the financial term P/E; the earnings in one source 
can be for one year where it is only defined quarterly in 
another.  Moreover, different sources having the earnings 
defined for one year can have different interpretations for it; is 
it the calendar year, fiscal year, or the last 12 months? 
The rise of Semantic Web in recent years was followed by a 
tremendous increase in the amount of data; everyone today has 
the ability to publish and retrieve information to be consumed 
or integrated into their applications. The Semantic Web has 
significantly changed people’s perceptions of the Internet. The 
Semantic Web is seen as a “global database” [5] that machines 
                                                           
1 A measure of the price paid for a share relative to the annual Earnings per Share [4] 
can directly access and naturally understand [ 6]. Lots of 
organizations are therefore trying to leverage external data 
sources from t he Semantic Web like social media feeds, 
weblogs, sensor data or data published by governments or 
organizations [7] in order to produce more informed business 
decisions.  
However, these external sources exhibit heterogeneous 
models, formats and terminologi es. Finding and retrieving 
accurate information on demand is very difficult for 
organizations. Lots  of work is being done to improve the 
quality of this structured knowledge [ 8][9] but data quality for 
Semantic Web is mainly pe rformed in silos without following 
general methodologies. Tools and best practices are therefore 
required to help data consumers identify their needs and 
evaluate the quality of data. 
Based on our extensive experience in data integration at 
SAP, we identify in this paper five principle classes to describe 
the quality of a particular linked dataset. For each class, we list 
the principles that are involved at all stages of the data 
management process. Using our principles, it becomes possible 
to automate the process of controlling and guaranteeing data 
quality and consequently to increase the quality of decisions in 
a business environment. 
The remainder of this paper is organized as follows: Section II 
presents the related work; Section III deﬁnes the classification 
of the principles; and finally Section IV presents concluding 
remarks and identiﬁes promising areas of research. 
 
II. RELATED WORK 
 
Semantic data is widely available and the development and 
application of ontologies have been gaining big momentum in a 
range of application domains, such as government 
organizations, healthcare or media [10] [11][12]. Several 
semantic groups have been building or contributing to the 
development of ontologies, for example [ 13]. Although 
numerous methodologies and design patterns exist to support 
their building process and ensure better data quality, ontologies 
exhibit heterogeneous structure and content. Deciding what 
ontology to use becomes one of the most difficult and 
challenging task for organizations.  
Some projects have proposed so lutions to identify good 
data sources simplifying greatly the task of finding and 
consuming high-quality data. In [ 14][15] a resource is ranked 
by the quality of the incoming and outgoing links. Moreover, 
“Sieve” [ 16] is a fra mework that tries to express quality 
assessment methods as well as fusion methods.  
Although these projects go in the right direction, there is 
still a need for data quality principles in the Semantic Web 
context. An initial attempt to identify quality criteria for Linked 
Data sources can be found in [22]. Though this classification is 
good, some criteria  on the quality of the used ontologies and 
the links between data and ontology concepts are missing . In 
this paper, we extend this initial list by considering all possible 
criteria from multiple context factors and by selecting the most 
relevant indicators to assess data quality in the Semantic Web. 
III. CLASSIFICATION OF DATA QUALITY PRINCIPLES IN THE 
SEMANTIC WEB 
 
The main goal behind using Linked Data is to e asily enable 
knowledge sharing and publishing. The basic assumption is 
that the usefulness of Linked data will increase if it is more 
interlinked with other data; Tim Berners -Lee defined 4 keys 
principles for publishing [17]: 
 Make the data available on the  web: assign URIs to 
identify things. 
 Make the data machine readable: use HTTP URIs so 
that looking up these names is easy. 
 Use publishing standards: when the lookup is done 
provide useful information using standards like RDF. 
 Link your data: include links  to other resources to 
enable users to discover more things. 
By following these guidelines, a certain level of uniformity 
is achieved, which increases the usability of data. To fully 
leverage all the benefits of the Semantic Web, data quality 
principles in  Semantic Web should embrace and adopt the 
guidelines for Linked Open Data. 
Building on these principles and based on our experience 
with powerful data integration software to extract, transform, 
and load data from applications, databases and other data 
sources, we have derived five principles for data quality in the 
Semantic Web (see Table 1). These principles are: 
 Quality of data source: This principle is related to the 
availability of the data and the credibility of the data 
source. 
 Quality of raw data : This principle is mainly related 
to the absence of duplicates, entry mistakes, and noise 
in the data. 
 Quality of the semantic conversion : This principle is 
related to the transformation of raw data into rich data 
by using vocabularies. 
 Quality of the linki ng process : This principle is 
related to the quality of links between two datasets. 
 Global quality : This principle is cross -cutting the 
other principles and covers the source, raw data, 
semantic conversion, reasoning and links quality. 
 
Data Quality Principle Attribute 
Quality of Data Sources 
Accessibility 
Authority & Sustainability 
License 
Trustworthiness & verifiability 
Performance 
Quality of raw data 
Accuracy 
Referential 
correspondence 
Cleanness 
Consistency 
Comprehensibility 
Completeness 
Typing 
Provenance 
Versatility 
Traceability 
Quality of the semantic 
conversion 
Correctness 
Granularity 
Consistency 
Quality of the linking 
process 
Connectedness 
Isomorphism 
Directionality 
 
Table 1- Data quality principles in the Semantic Web 
A. Quality of data source 
 
This principle is related to the availability of the data and 
the credibility of the data source. 
 Accessibility: Do access methods and protocols 
perform properly? Is all the URIs de-referenceable? Do 
the in-going and out-going links operate correctly? 
 Authority & Sustainability : Is the data source 
provider a known credible source or is he sponsored by 
well-known associations and providers? Are there 
credible basis for beli eving the data source will be 
maintained and available in the future? 
 License: Is the data source license clearly defined?  
 Trustworthiness & Verifiability : Can the data 
consumer examine the correctness and accuracy of the 
data source? The consumer should also be sure that the 
data he receives is the same data he has vouched for 
and from the same resource. This can be ensured using 
digital signatures thus verifying all possible 
serialization of that data [18]. 
 Performance: Is the data source capable of copi ng 
with increasing requests in low latency res ponse time 
and high throughput? 
B. Quality of the raw data 
 
This principle is mainly related to the absence of 
duplicates, entry mistakes, and noise in the data. 
 
 Accuracy: Are the nodes referring to factually and  
lexically correct information? 
 Referential correspondence : Is the data 
described using accurate labels without 
duplications? The goal is to have one -to-one 
references between data and real world. 
 Cleanness: Is the data clean and not polluted 
with irreleva nt or outdated data? Are there 
duplicates? Is the data formatted in a 
consistent way (i.e., are the dates all 
formatted yyyy/mm/dd)? Tools such as 
Google Refine [19] or Data Wrangler [20] 
provide already a good answer to these issues 
by allowing the cleani ng of complex data 
sets. 
 Consistency: does the data contradict itself? 
For example, is the population of Europe the 
same as the sum of the population of the 
European countries? To achieve that we need 
to validate the underlying vocabulary and 
syntax of the document with other resources 
 Comprehensibility: Are the data concepts 
understandable to humans? Do they convey logical 
meaning of the described entity and allow easy 
consumption and utilization of the data? If a concept is 
described using multiple labels  (a set of concepts in a 
owl:sameAs relationship), which one should be 
consumed? How can we specify which label is 
canonical? 
 Completeness: Do we have all the data needed to 
represent all the information related to a real world 
entity? Moreover, is the dat a related or linked to this 
set complete as well, e.g., all European countries, all 
French cities, all street addresses, all postal codes…? 
 Typing: Is the data properly typed as a concept from a 
vocabulary or just as a string literal? Having the data 
properly typed allows users to go a step further in the 
business analysis and decision process. 
 Provenance: provenance in the Semantic Web is 
considered as one of the most important indicators of 
"quality."  Data sets can be used or rejected depending 
on the av ailability of sufficient and/or relevant 
metadata attached. 
 Versatility: Can the data provided be presented using 
alternative representations? This can be achieved by 
conversion into various formats or if the data source 
enables content negotiation. 
 Traceability: Are all the elements of my data traceable 
(including data itself but also queries, formulae)? Can I 
know from what data sources they come? 
C. Quality of the semantic conversion 
 
Semantic conversion is the process of transforming 
“normal” raw data into “rich” data, i.e. input: [tabular data]  
output: [RDF using x Vocabulary]. The use of high quality 
vocabularies and the efficiency of data discovery process are 
major factors in increasing the quality of data. However, one of 
the most  important aspect that affects the quality of the 
semantic conversion is the quality and suitability of its data 
model with the intended usage . The quality of a data model 
strongly depends on the following aspects: 
 Correctness: Is the data structure properly modeled 
and presented for future conversion?  
 Granularity: does the model capture enough 
information to be useful?  Are all the expected data 
present? 
 Consistency: Is the direction of relations consisten tly 
done? 
D.  Moreover, there shouldn’t be any redefinitions of existing 
properties and no stating of inconsistent values for them. 
Quality of the linkage 
 
This principle is related to the quality of links between two 
datasets. 
 Connectedness: Is the combination of datasets done at 
the correct resources? Frameworks like Silk [ 21] ease 
the linking process but don’t tackle per se the quality of 
the links that are generated. The quality depends on the 
link generation configuration. The quality is however 
improved if your data is linked to some reference 
dataset.  
 Isomorphism: Are the combined datasets modeled in a 
compatible way? Are the combined models reconciled? 
 Directionality: After the linkage, is  the knowledge 
represented in the resulting graph of resources still 
consistent?  
E. Global quality 
 
These principles are applicable to all aspects of a Semantic 
System (data source, raw data, links, etc.).  
 Timeliness: Is the data up -to date? Does the data 
source contain the latest raw data presented with the 
last updated model? Are the links from and to the data 
source updated to the latest references? Does the 
source state the update and validation frequencies? 
Failing in updating the source data increases the chance 
that the referenced URIs have changed. 
 History: Can we keep track of who edited my data and 
when? 
 Freshness: The ability to replicate the remote 
repository into local triple stores and maintain the 
timeliness of the replica. 
IV. SUMMARY 
In this paper, we presented five main classes of data quality 
principles for the Semantic Web. For each class, we listed the 
specific criteria that represent the quality of a data source on 
the Web. This new vocabulary to express Linked Data quality 
can be used by data publishers to refine and improve their 
datasets, and by consumers to select the most relevant public 
datasets with highest quality . Following the se principles will 
lead to higher quality Semantic Web, which will result in better 
data usage and mash-ups thus more informed decisions.  
Trust issues have always been dominant in the world of the 
Internet, no one believes everything that is out there, but rather 
relies on context, provenance and authority. If the data source 
cannot be directly trusted th en users generally question the 
data. The unique problem for Linked data is that it considers 
data as a big graph that originates from users all over the world. 
The borders of provenance in this case can easily become 
vague especially when trying to infer across multiple datasets. 
We will investigate these issues in future work. 
REFERENCES 
[1] Chapman, Arthur D. 20 05. Principles of Data Quality. 
Copenhagen. : Report for the Global Biodiversity 
Information Facility, 2005. 
[2] Juran, Joseph M. and Godfrey, A. Blanton.  Juran's 
Quality Handbook. s.l. : McGraw-Hill, 1998. 
[3] Improving Data Quality Through Effective Use of Data 
Semantics. Madnick, Stuart and Zhu, Hongwei. 2005.  
Cambridge, MA  : Composite Information Systems 
Laboratory (CISL), 2005. 
[4] ULC, Investopedia.  Investopedia. [Online] [Cited: 6 20, 
2012.] http://www.investopedia.com/terms/p/price -
earningsratio.asp. 
[5] Semantic W eb Road map . W3C. [Online] [Cited: 6 19, 
2012.] http://www.w3.org/DesignIssues/Semantic.html. 
[6] Berners-Lee, Tim and Fischetti, Mark. 2000.  Weaving 
the Web. s.l. : Harper Business, 2000. 
[7] Six Provocations for Big Data. Boyd, Danah and 
Crawford, Kate. 2011.  1, s.l. : Computer and 
Information Science, 2011, Vol. 123. 
[8] Improving Schema Matching with Linked Data. A. Assaf, 
E. Louw, A. Senart, C. Follenfant, R. Troncy and D. 
Trastour. 2012. s.l. : 1st International Workshop on Open 
Data (WOD), 2012 
[9] Public Data Integ ration with WebSmatch. R. Coletta, E. 
Castanier, P. Valduriez, C. Frisch, D. Ngo and Z. 
Bellahsene. 2012.  s.l. : 1st International Workshop on 
Open Data (WOD), 2012 
[10] Towards an Ontology for e -Document Management in 
Public Administration – the Case of Schles wig-Holstein. 
Klischewski, R. 2012.  s.l. : Proceedings HICSS -36, 
IEEE, 2012 
[11] Publishing Life Science Data as Linked Open Data: the 
Case Study of miRBase. T. Dalamagas, N. Bikakis, G. 
Papastefanatos, Y. Stavrakas and A. Hatzigeorgiou. 
2012. s.l. : 1st Intern ational Workshop on Open Data 
(WOD), 2012 
[12] Publishing and linking transport data on the Web. 
Scharffe, J. Plu and F. 2012.  s.l. : 1st International 
Workshop on Open Data (WOD), 2012 
[13] OHSU Ontology Development Group. Oregon Health & 
Science 
University.http://www.ohsu.edu/xd/education/library/abo
ut/departments/ontology-development.cfm 
[14] Hierarchical Link Analysis for Ranking Web. Renaud 
Delbru, Nickolai Toupikov, M ichele Catasta, 
Giovanni. 2010. s.l. : Springer Berlin Heidelberg, 2010, 
Vol. 6089 
[15] Sindice at SemSearch 2010. Renaud Delbru, Nur Aini 
Rakhmawati, Giovanni Tummarello. 2010.  s.l. : 
WWW2010, 2010 
[16] Sieve: Linked Data Quality Assessment and Fusion. 
Pablo N. Men des, Hannes Mühleisen, Christian Bizer. 
2012. Berlin : LWDM2012, 2012 
[17] Berners-Lee, Tim. 2006.  Linked Data. W3C. [Online] 
2006. [Cited: 6 18, 2012.] 
http://www.w3.org/DesignIssues/LinkedData.html 
[18] Privacy for Semantic Web Mining using Advanced DSA – 
Spatial LBS Case Study in mining . S.Nagaprasad Sri, 
A.VinayaBabu, K.Madhukar, Marlene Grace 
Verghese, A.Pratima, V.Mallaiah, A.Sreelatha. 2010.  
9, s.l.  : International Journal of Engineering Science a nd 
Technology, 2010, Vol. 2 
[19] Google Code. Google Refine . [Online]. 
http://code.google.com/p/google-refine/ 
[20] Stanford Visualization Group. Data Wrangler . [online]. 
http://vis.stanford.edu/wrangler/ 
[21] Freie Universitat, Berlin. Silk – A link Discovery 
Framework for the Web of Data  [online]. 
http://www4.wiwiss.fu-berlin.de/bizer/silk/ 
[22] MediaWiki. Quality Criteria for Linked Data sources. 
SourceForge. [Online] [Cited: 6 19, 2012.]""" ;
    onto:mentionsConcept onto:Aline_Senart,
        onto:Cleanness_Consistency_Comprehensibility_Completeness,
        onto:Data_Quality,
        onto:Information_Science,
        onto:International_Journal,
        onto:Open_Data,
        onto:Performance_Quality,
        onto:Renaud_Delbru,
        onto:Science_University,
        onto:Tim_Berners .

onto:By_Application_Menu_Toggle a onto:DomainConcept ;
    skos:prefLabel "By Application Menu Toggle" .

onto:Conclusion_A_Call_for_Action a onto:DomainConcept ;
    skos:prefLabel "Conclusion: A Call for Action" .

onto:Contact_Us a onto:DomainConcept ;
    skos:prefLabel "Contact Us" .

onto:Content_Management a onto:DomainConcept ;
    skos:prefLabel "Content Management" .

onto:Data_Interoperability_The_Key_to_Breaking_Down_Barriers a onto:DomainConcept ;
    skos:prefLabel "Data Interoperability: The Key to Breaking Down Barriers" .

onto:Data_Silos_A_Critical_Challenge a onto:DomainConcept ;
    skos:prefLabel "Data Silos: A Critical Challenge" .

onto:Data_Structure a onto:DomainConcept ;
    skos:prefLabel "Data Structure" .

onto:Dimitar_Taskov a onto:DomainConcept ;
    skos:prefLabel "Dimitar Taskov" .

onto:European_Union a onto:DomainConcept ;
    skos:prefLabel "European Union" .

onto:Knowledge_Graph_Applications a onto:DomainConcept ;
    skos:prefLabel "Knowledge Graph Applications" .

onto:Life_Sciences_Accelerators_Menu a onto:DomainConcept ;
    skos:prefLabel "Life Sciences Accelerators Menu" .

onto:Meet_the_speakers a onto:DomainConcept ;
    skos:prefLabel "Meet the speakers" .

onto:Open_Data a onto:DomainConcept ;
    skos:prefLabel """Open 
Data""" .

onto:Presentation_by_Atanas_Kirakov a onto:DomainConcept ;
    skos:prefLabel "Presentation by Atanas Kirakov" .

onto:Semantic_Data_Modeling a onto:DomainConcept ;
    skos:prefLabel "Semantic Data Modeling" .

onto:The_Interplay_Between_the_EU_Data_Act_and_Linked_Data a onto:DomainConcept ;
    skos:prefLabel "The Interplay Between the EU Data Act and Linked Data" .

onto:Want_more_like_this_learn_more_about_the_recommended_contentdataimagesvgxml3Csvg20xmlnshttpwwww3org2000svg20viewBox0200201620163E3Csvg3Elearn_more_about_the_recommended_contentwp-contentuploads202407icon-help-circlesvg_The_Ontotext_Recommendations_engine_combines_content_and_its_semantic_fingerprint_to_retrieve_knowledge_graph-driven_recommendations_It_is_integrated_with_the_Ontotext_Metadata_Studio_tagging_to_power_meaningful_recommendations_based_on_both_semantic_relevancy_and_recency a onto:DomainConcept ;
    skos:prefLabel "Want more like this?  ![learn more about the recommended content](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2016%2016'%3E%3C/svg%3E)![learn more about the recommended content](/wp-content/uploads/2024/07/icon-help-circle.svg) The Ontotext Recommendations engine combines content and its semantic fingerprint to retrieve knowledge graph-driven recommendations. It is integrated with the Ontotext Metadata Studio tagging to power meaningful recommendations based on both semantic relevancy and recency." .

onto:Want_to_chat_more_with_us_Reach_out_and_lets_do_it a onto:DomainConcept ;
    skos:prefLabel "Want to chat more with us? Reach out and let's do it!" .

onto:Welcome_to_the_OntoText_Webinar a onto:DomainConcept ;
    skos:prefLabel "Welcome to the OntoText Webinar" .

sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_1 a onto:Chunk ;
    onto:chunkIndex 1 ;
    onto:chunkText """**Wistor** makes compliance lead to collaboration. The platform provides the foundation to build, connect, and scale data ecosystems that align with European data legislation. By shifting to native Linked Data, organizations can move beyond storing raw data and instead focus on connecting data, enriching metadata, and improving the traceability of information.

*(****Actionable Insight:*** *The first step is to* ***Map your data landscape****,* ***Adopt open standards****, and* ***Set up governance*** *for your resulting data graph.)*

*Read my full article here in Wistor blog:*

**Wistor Blog Post Draft (Introduction Section - Est. 550-650 words of 1,500-2,500 total)**

**TITLE: Compliance as Catalyst: Why the EU Data Act Forces a Strategic Migration from Cloud Silos (AWS/Azure) to Native Linked Data** (Template: The Product Showdown / Myth Debunker)

**1. The Legal Imperative: Data Ownership is No Longer Negotiable**

The **EU Data Act**, effective September 12, 2025, is more than a legal update; it is a **cultural and technical change** that redefines digital trust and data ownership across Europe. For decades, data generated by connected products remained **"locked inside the systems of manufacturers or software providers"**. This law overturns that, granting users—be they individuals, businesses, or public organizations—the **right to access and share the data they generate**. The core principle established by the European Commission is simple: **both parties can access all data collected by a machine**.

This mandate creates an immediate, pervasive requirement for **semantic interoperability**. Data must be ready for instantaneous exchange and reuse, which is a challenge traditional infrastructures often fail to meet.

**2. The Cloud Paradox: The Dual Crisis of Hyperscalers (AWS, Azure, and GCP)**

The modern data landscape relies heavily on distributed cloud systems, including major platforms like **Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP)**. While offering scale and flexibility, traditional big data management within these architectures faces a dual crisis that undermines Data Act compliance:""" ;
    onto:mentionsConcept onto:Actionable_Insight,
        onto:Cloud_Silos,
        onto:Data_Ownership,
        onto:European_Commission,
        onto:Introduction_Section,
        onto:Microsoft_Azure,
        onto:Myth_Debunker,
        onto:Native_Linked_Data,
        onto:Strategic_Migration,
        onto:Wistor_Blog_Post_Draft .

sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_3 a onto:Chunk ;
    onto:chunkIndex 3 ;
    onto:chunkText """* **Native Standards:** Wistor is natively designed around **RDF, OWL, and SHACL**. Every object, attribute, and relation is stored as linked data from the start, avoiding the compromises of middleware solutions typically needed to integrate semantics into traditional cloud silos.
* **Decoupling and Control:** The platform strictly decouples the data layer and the application layer. This separation ensures that the data remains independent, fully owned by the organization, and that there is **no vendor lock-in** because there is no dependency on proprietary formats.
* **Enhanced Solutions:** Wistor's native approach enables sophisticated governance (using SHACL validation for compliance) and cost-effective reuse, allowing data to be **reusable across projects, systems, and partners**. We empower data engineers to configure apps using SPARQL directly on the triple store.

By making the data itself the stable core, Wistor transforms the regulatory requirement of the EU Data Act into an architectural advantage, proving that **compliance should lead to collaboration**.

Suggested Images:

[I believe we have to create our own diagrams with good designs but these are some things to inspire:

![The EU Data Act explained: rights, obligations and challenges for data  holders and manufacturers](data:image/jpeg;base64...)Source: <https://diconium.com/en/blog/eu-data-act>.

And this presentation has a good explanations + diagrams to inspire: <https://www.slideshare.net/slideshow/linked-data-for-lean-enterprise-data-management>

![](data:image/png;base64...)

![](data:image/png;base64...)

![](data:image/png;base64...)""" ;
    onto:mentionsConcept onto:Data_Act,
        onto:Enhanced_Solutions,
        onto:Native_Standards,
        onto:Suggested_Images .

sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """[ Skip to content](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#content)

Making Sense of Text and Data

* [News and webinars](https://www.ontotext.com/company/news/)
  * [Careers](https://www.ontotext.com/company/careers/)
  * [Graphwise](https://graphwise.ai/)

[  
![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/github.svg)![](/wp-content/uploads/2024/10/github.svg)  
](https://github.com/Ontotext-AD)  
[  
![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/LinkedIn-2.svg)![](/wp-content/uploads/2024/10/LinkedIn-2.svg)  
](https://www.linkedin.com/company/ontotext-ad)  
[  
![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/medium.svg)![](/wp-content/uploads/2024/10/medium.svg)  
](https://medium.com/@ontotext)  
[  
![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/Youtube.svg)![](/wp-content/uploads/2024/10/Youtube.svg)  
](https://www.youtube.com/ontotext)  
[  
![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/X.svg)![](/wp-content/uploads/2024/10/X.svg)  
](https://twitter.com/ontotext)

[![Ontotext](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/Ontotext-A-Graphwise-company.svg)![Ontotext](https://www.ontotext.com/wp-content/uploads/2024/11/Ontotext-A-Graphwise-company.svg)](https://www.ontotext.com/)

[ Ontotext ](https://www.ontotext.com/)

* [ Products ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * [ Products Overview![mm-ast-icon-55](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-55](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg) ](https://www.ontotext.com/products/)Menu Toggle
      * [ ![mm-ast-icon-64032](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-64032](https://www.ontotext.com/wp-content/uploads/2024/09/icon-graphdb.svg)GraphDB ](https://www.ontotext.com/products/graphdb/)

Link diverse data, index it for semantic search and enrich it via text analysis to build big knowledge graphs

Menu Toggle
        * [ ![mm-ast-icon-57577](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-57577](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Release notes](https://graphdb.ontotext.com/documentation/11.0/)
        * [ ![mm-ast-icon-57578](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2018'%3E%3C/svg%3E)![mm-ast-icon-57578](https://www.ontotext.com/wp-content/uploads/2024/09/icon-inbox.svg)Quick start guide](https://graphdb.ontotext.com/documentation/11.0/how-to-install-graphdb.html?_gl=1*e0acjk*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNTkxOS4wLjAuMA..)
        * [ ![mm-ast-icon-57579](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-57579](https://www.ontotext.com/wp-content/uploads/2024/09/icon-book.svg)Documentation](https://graphdb.ontotext.com/documentation/11.0/?_gl=1*2lq5zz*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNjAwMy4wLjAuMA..)
      * [ ![mm-ast-icon-57505](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-57505](https://www.ontotext.com/wp-content/uploads/2024/09/icon-metadata-studiosvg.svg)Metadata Studio ](https://www.ontotext.com/products/ontotext-metadata-studio/)

Easily integrate and evaluate any text analysis service against your ground truth data

Menu Toggle
        * [ ![mm-ast-icon-57597](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-57597](https://www.ontotext.com/wp-content/uploads/2024/09/icon-settings.svg)Installation](https://platform.ontotext.com/omds/installation.html?_gl=1*1a55rrd*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
        * [ ![mm-ast-icon-57598](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-57598](https://www.ontotext.com/wp-content/uploads/2024/09/icon-monitor-alt.svg)Configuration](https://platform.ontotext.com/omds/configuration.html?_gl=1*1a55rrd*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
        * [ ![mm-ast-icon-57599](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-57599](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Release notes](https://platform.ontotext.com/omds/release-notes.html?_gl=1*2s09ev*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
      * [ ![mm-ast-icon-57589](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2022'%3E%3C/svg%3E)![mm-ast-icon-57589](https://www.ontotext.com/wp-content/uploads/2024/09/icon-semantic-objects.svg)Ontotext Semantic Objects ](https://www.ontotext.com/products/semantic-objects/)

Organize your information into enterprise knowledge graphs for synergistic data management and analytics

Menu Toggle
        * [ ![mm-ast-icon-57594](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-57594](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Release notes](https://platform.ontotext.com/semantic-objects/release-notes.html?_gl=1*173mruu*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNjk0MC4wLjAuMA..)
        * [ ![mm-ast-icon-57595](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2018'%3E%3C/svg%3E)![mm-ast-icon-57595](https://www.ontotext.com/wp-content/uploads/2024/09/icon-inbox.svg)Quick start guide](https://platform.ontotext.com/semantic-objects/installation/?_gl=1*173mruu*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNjk0MC4wLjAuMA..)
        * [ ![mm-ast-icon-57596](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-57596](https://www.ontotext.com/wp-content/uploads/2024/09/icon-book.svg)Documentation](https://platform.ontotext.com/semantic-objects/)
      * [ ![mm-ast-icon-57506](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2018'%3E%3C/svg%3E)![mm-ast-icon-57506](https://www.ontotext.com/wp-content/uploads/2024/09/icon-refine.svg)Ontotext Refine ](https://www.ontotext.com/products/ontotext-refine/)

Automate converting messy string data into a knowledge graph with Ontotext’s free application

Menu Toggle
        * [ ![mm-ast-icon-57600](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-57600](https://www.ontotext.com/wp-content/uploads/2024/09/icon-settings.svg)Installation](https://platform.ontotext.com/ontorefine/install-migrate.html?_gl=1*2s09ev*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
        * [ ![mm-ast-icon-57601](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-57601](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Release notes](https://platform.ontotext.com/ontorefine/release-notes.html?_gl=1*ul01od*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
        * [ ![mm-ast-icon-57602](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2020'%3E%3C/svg%3E)![mm-ast-icon-57602](https://www.ontotext.com/wp-content/uploads/2024/09/icon-refresh.svg)Data loading](https://platform.ontotext.com/ontorefine/loading-data-using-ontorefine.html?_gl=1*ul01od*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
        * [ ![mm-ast-icon-57603](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2021%2022'%3E%3C/svg%3E)![mm-ast-icon-57603](https://www.ontotext.com/wp-content/uploads/2024/09/icon-data.svg)RDF-izing tabular data](https://platform.ontotext.com/ontorefine/rdfizing.html?_gl=1*ul01od*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
    * [ Architecture patterns![mm-ast-icon-57580](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-57580](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg) ](https://www.ontotext.com/architecture-patterns/)Menu Toggle
      * [ ![mm-ast-icon-57583](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2012%2012'%3E%3C/svg%3E)![mm-ast-icon-57583](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-down.svg)Generative AI](https://www.ontotext.com/architecture-patterns/?p=generative-ai)
      * [ ![mm-ast-icon-57582](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2012%2012'%3E%3C/svg%3E)![mm-ast-icon-57582](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-down.svg)Domain Knowledge Graph](https://www.ontotext.com/architecture-patterns/?p=domain-knowledge-graph)
      * [ ![mm-ast-icon-57581](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2012%2012'%3E%3C/svg%3E)![mm-ast-icon-57581](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-down.svg)Data Fabric](https://www.ontotext.com/architecture-patterns/?p=data-fabric)
      * [ ![mm-ast-icon-57584](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2012%2012'%3E%3C/svg%3E)![mm-ast-icon-57584](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-down.svg)Graph Analytics](https://www.ontotext.com/architecture-patterns/?p=graph-analytics)
      * [ ![mm-ast-icon-57585](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2012%2012'%3E%3C/svg%3E)![mm-ast-icon-57585](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-down.svg)Semantic Content Hub](https://www.ontotext.com/architecture-patterns/?p=semantic-content-hub)
  * [ Solutions ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * [ Solutions Overview![mm-ast-icon-60484](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-60484](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg)](https://www.ontotext.com/solutions/)
    * Life Sciences Accelerators Menu Toggle
      * [ ![mm-ast-icon-62732](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-62732](https://www.ontotext.com/wp-content/uploads/2024/09/icon-circles.svg)LinkedLifeData Inventory](https://www.ontotext.com/solutions/healthcare-and-life-sciences/linked-life-data-inventory/)

Get 200+ semantics ready biomedical datasets covering various life sciences domains

* [ ![mm-ast-icon-62733](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2022'%3E%3C/svg%3E)![mm-ast-icon-62733](https://www.ontotext.com/wp-content/uploads/2024/09/icon-rocket.svg)AI Powered Target Discovery](https://www.ontotext.com/solutions/ontotexts-target-discovery/)

Expedite discovering efficient drug candidates from scientific publications, patents, and clinical trials

* By Industry Menu Toggle
      * [ ![mm-ast-icon-57509](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2023%2020'%3E%3C/svg%3E)![mm-ast-icon-57509](https://www.ontotext.com/wp-content/uploads/2024/09/icon-activity.svg)Healthcare and Life Sciences](https://www.ontotext.com/solutions/healthcare-and-life-sciences/)""" ;
    onto:mentionsConcept onto:Domain_Knowledge_Graph,
        onto:Graph_Analytics,
        onto:Life_Sciences_Accelerators_Menu,
        onto:Making_Sense,
        onto:Menu_Toggle,
        onto:Metadata_Studio,
        onto:Ontotext_Refine,
        onto:Powered_Target_Discovery,
        onto:Products_Overview,
        onto:Semantic_Content_Hub .

sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_1 a onto:Chunk ;
    onto:chunkIndex 1 ;
    onto:chunkText """Discover new drug targets faster, enable drug safety analytics and regulatory intelligence with ease

* [ ![mm-ast-icon-57512](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2015%2018'%3E%3C/svg%3E)![mm-ast-icon-57512](https://www.ontotext.com/wp-content/uploads/2024/09/icon-bar-chart.svg)Financial Services](https://www.ontotext.com/solutions/financial-services/)

Enhance investment intelligence, inventory management, and regulatory compliance with better data insights

* [ ![mm-ast-icon-57510](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-57510](https://www.ontotext.com/wp-content/uploads/2024/09/icon-settings.svg)Manufacturing](https://www.ontotext.com/solutions/manufacturing/)

Optimize manufacturing processes with advanced data integration, analysis, and predictive insights

* [ ![mm-ast-icon-59015](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2023%2021'%3E%3C/svg%3E)![mm-ast-icon-59015](https://www.ontotext.com/wp-content/uploads/2024/09/icon-park-city.svg)AECO & Infrastructure](https://www.ontotext.com/solutions/aeco-infrastructure/)

Optimize your industrial processes and product development

* [ ![mm-ast-icon-57513](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2023'%3E%3C/svg%3E)![mm-ast-icon-57513](https://www.ontotext.com/wp-content/uploads/2024/09/icon-megaphone.svg)Media & Publishing](https://www.ontotext.com/solutions/media-and-publishing/)

Improve engagement, discoverability, and personalized recommendations for media and publishing industries

* [ ![mm-ast-icon-57511](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2023%2020'%3E%3C/svg%3E)![mm-ast-icon-57511](https://www.ontotext.com/wp-content/uploads/2024/09/icon-folder.svg)Public Sector](https://www.ontotext.com/solutions/public-sector/)

Unlock intelligent public services and applications for government and defense

* By Application Menu Toggle
      * [ ![mm-ast-icon-60482](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-60482](https://www.ontotext.com/wp-content/uploads/2024/10/icon-cpu.svg)Knowledge Graph Applications](https://www.ontotext.com/knowledge-graph-applications/)

Enable unified data access across systems with the flexible, precise structure of a knowledge graph model

* [ ![mm-ast-icon-60483](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-60483](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Text Analysis for Content Management](https://www.ontotext.com/solutions/text-analysis-for-content-management/)

Interlink your organization’s data and content by using knowledge graph powered natural language processing

* [ Services ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * [ Services Overview![mm-ast-icon-57516](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-57516](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg) ](https://www.ontotext.com/services/)Menu Toggle
      * [ ![mm-ast-icon-1675](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2020%2020'%3E%3C/svg%3E)![mm-ast-icon-1675](https://www.ontotext.com/wp-content/uploads/2024/09/icon-message-square.svg)Strategy and Technology Consulting](https://www.ontotext.com/services/semantic-technology-consulting/)
      * [ ![mm-ast-icon-57535](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-57535](https://www.ontotext.com/wp-content/uploads/2024/09/icon-settings.svg)GraphDB Development Support](https://www.ontotext.com/services/graphdb-development-support/)
      * [ ![mm-ast-icon-57527](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2020'%3E%3C/svg%3E)![mm-ast-icon-57527](https://www.ontotext.com/wp-content/uploads/2024/09/icon-sliders.svg)Semantic Data Modeling](https://www.ontotext.com/services/semantic-data-modeling/)
      * [ ![mm-ast-icon-57536](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2021%2021'%3E%3C/svg%3E)![mm-ast-icon-57536](https://www.ontotext.com/wp-content/uploads/2024/09/icon-tool.svg)GraphDB Managed Services](https://www.ontotext.com/services/graphdb-managed-services/)
      * [ ![mm-ast-icon-1677](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-1677](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Text Analytics](https://www.ontotext.com/services/text-mining-and-text-analytics/)
      * [ ![mm-ast-icon-1679](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2014'%3E%3C/svg%3E)![mm-ast-icon-1679](https://www.ontotext.com/wp-content/uploads/2024/09/icon-trending-up.svg)Trainings](https://www.ontotext.com/services/semantic-technology-trainings/)
  * [ Knowledge Hub ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * Resources Menu Toggle
      * [ ![mm-ast-icon-52802](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2023%2024'%3E%3C/svg%3E)![mm-ast-icon-52802](https://www.ontotext.com/wp-content/uploads/2024/09/icon-shine.svg)AI in Action](https://www.ontotext.com/ai-in-action/)
      * [ ![mm-ast-icon-26394](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2016%2020'%3E%3C/svg%3E)![mm-ast-icon-26394](https://www.ontotext.com/wp-content/uploads/2024/09/icon-bookmark.svg)Case studies](https://www.ontotext.com/knowledge-hub/case-studies/)
      * [ ![mm-ast-icon-26395](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-26395](https://www.ontotext.com/wp-content/uploads/2024/09/icon-book.svg)White papers](https://www.ontotext.com/knowledge-hub/white_paper/)
      * [ ![mm-ast-icon-26392](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2024'%3E%3C/svg%3E)![mm-ast-icon-26392](https://www.ontotext.com/wp-content/uploads/2024/09/icon-light.svg)Fundamentals](https://www.ontotext.com/knowledge-hub/fundamentals/)
      * [ ![mm-ast-icon-59010](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2022'%3E%3C/svg%3E)![mm-ast-icon-59010](https://www.ontotext.com/wp-content/uploads/2024/10/ontotext-icon-demo-services-icon.svg)Technology Demonstrators](https://www.ontotext.com/knowledge-hub/demoservices/)
      * [ ![mm-ast-icon-26396](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2022'%3E%3C/svg%3E)![mm-ast-icon-26396](https://www.ontotext.com/wp-content/uploads/2024/09/icon-play.svg)Videos](https://www.ontotext.com/knowledge-hub/videos/)
      * [ ![mm-ast-icon-26390](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-26390](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Publications](https://www.ontotext.com/knowledge-hub/publications/)
    * News and webinars Menu Toggle
      * [ ![mm-ast-icon-57525](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2023'%3E%3C/svg%3E)![mm-ast-icon-57525](https://www.ontotext.com/wp-content/uploads/2024/09/icon-megaphone.svg)News](https://www.ontotext.com/company/news/)
      * [ ![mm-ast-icon-26393](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2016'%3E%3C/svg%3E)![mm-ast-icon-26393](https://www.ontotext.com/wp-content/uploads/2024/09/icon-camera.svg)Webinars](https://www.ontotext.com/knowledge-hub/webinars/)
    * Latest resource

* [![SynthMedic: Utilizing large language models for synthetic discharge summary generation, correction and validation](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202000%201000'%3E%3C/svg%3E)![SynthMedic: Utilizing large language models for synthetic discharge summary generation, correction and validation](https://www.ontotext.com/wp-content/uploads/2024/04/Publication.png)](https://www.ontotext.com/knowledgehub/publications/using-llm-for-synthetic-discharge-summary-generation-correction-validation/)

## [SynthMedic: Utilizing large language models for synthetic discharge summary generation, correction and validation](https://www.ontotext.com/knowledgehub/publications/using-llm-for-synthetic-discharge-summary-generation-correction-validation/)

Georgi Grazhdanski, Vasil Vasilev, Sylvia Vassileva, Dimitar Taskov, Izabel Antova, Ivan Koychev, Svetla Boytcheva, SynthMedic: Utilizing large language models for

[**Read more**](https://www.ontotext.com/knowledgehub/publications/using-llm-for-synthetic-discharge-summary-generation-correction-validation/)

* [ Blog ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * [ Blog![mm-ast-icon-57545](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-57545](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg) ](https://www.ontotext.com/blog/)Menu Toggle
      * [ ![mm-ast-icon-61523](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2023%2024'%3E%3C/svg%3E)![mm-ast-icon-61523](https://www.ontotext.com/wp-content/uploads/2024/09/icon-shine.svg)AI in Action](https://www.ontotext.com/category/ai/)
      * [ ![mm-ast-icon-61517](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-61517](https://www.ontotext.com/wp-content/uploads/2024/09/icon-book.svg)Informational](https://www.ontotext.com/category/informational/)
      * [ ![mm-ast-icon-61518](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-61518](https://www.ontotext.com/wp-content/uploads/2024/10/briefcase-orange.svg)Business](https://www.ontotext.com/category/business/)
      * [ ![mm-ast-icon-61519](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-61519](https://www.ontotext.com/wp-content/uploads/2024/09/icon-settings.svg)Technology](https://www.ontotext.com/category/technology/)
      * [ ![mm-ast-icon-61520](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-61520](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)GraphDB Q&As](https://www.ontotext.com/category/graphdb-qnas/)
      * [ ![mm-ast-icon-61521](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2016%2024'%3E%3C/svg%3E)![mm-ast-icon-61521](https://www.ontotext.com/wp-content/uploads/2024/10/microphone.svg)Interviews](https://www.ontotext.com/category/interviews/)
      * [ ![mm-ast-icon-61522](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2020'%3E%3C/svg%3E)![mm-ast-icon-61522](https://www.ontotext.com/wp-content/uploads/2024/09/icon-users.svg)Guest Posts](https://www.ontotext.com/category/guest-posts/)
      * [ ![mm-ast-icon-61524](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2023'%3E%3C/svg%3E)![mm-ast-icon-61524](https://www.ontotext.com/wp-content/uploads/2024/09/icon-megaphone.svg)In the Media](https://www.ontotext.com/category/in-the-media/)
  * [ Company ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * Company Menu Toggle
      * [ ![mm-ast-icon-38352](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-38352](https://www.ontotext.com/wp-content/uploads/2024/09/icon-flag.svg)About us](https://www.ontotext.com/about-us/)
      * [ ![mm-ast-icon-1941](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2022'%3E%3C/svg%3E)![mm-ast-icon-1941](https://www.ontotext.com/wp-content/uploads/2024/09/icon-rocket.svg)Customers](https://www.ontotext.com/company/customers/)
      * [ ![mm-ast-icon-2199](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-2199](https://www.ontotext.com/wp-content/uploads/2024/09/icon-suitcase.svg)CareersWe’re hiring!](https://www.ontotext.com/company/careers/)
      * [ ![mm-ast-icon-31866](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2020'%3E%3C/svg%3E)![mm-ast-icon-31866](https://www.ontotext.com/wp-content/uploads/2024/09/icon-users.svg)Our team](https://www.ontotext.com/company/team/)
      * [ ![mm-ast-icon-58370](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-58370](https://www.ontotext.com/wp-content/uploads/2024/09/icon-circles.svg)Partners](https://www.ontotext.com/company/partners/)
      * [ ![mm-ast-icon-57849](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2024'%3E%3C/svg%3E)![mm-ast-icon-57849](https://www.ontotext.com/wp-content/uploads/2024/09/icon-light.svg)Research projects](https://www.ontotext.com/research-projects/)
    * [ Looking for a new career? Get in touch![mm-ast-icon-57521](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-57521](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg)](mailto:jobs@ontotext.com)
  * [ Ask our AI](https://www.ontotext.com/ontotext-knowledge-graph/)
  * [ Contact Us](https://www.ontotext.com/contact/)

[ Ask our AI ](https://www.ontotext.com/ontotext-knowledge-graph/)[Ask our AI](https://www.ontotext.com/ontotext-knowledge-graph/)""" ;
    onto:mentionsConcept onto:By_Application_Menu_Toggle,
        onto:Contact_Us,
        onto:Content_Management,
        onto:Dimitar_Taskov,
        onto:Knowledge_Graph_Applications,
        onto:Managed_Services,
        onto:Menu_Toggle,
        onto:Public_Sector,
        onto:Semantic_Data_Modeling,
        onto:SynthMedic_Utilizing_large_language_models_for_synthetic_discharge_summary_generation_correction_and_validationhttpswwwontotextcomknowledgehubpublicationsusing-llm-for-synthetic-discharge-summary-generation-correction-validation .

sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_3 a onto:Chunk ;
    onto:chunkIndex 3 ;
    onto:chunkText """* [ Services ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * [ Services Overview![mm-ast-icon-57516](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-57516](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg) ](https://www.ontotext.com/services/)Menu Toggle
      * [ ![mm-ast-icon-1675](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2020%2020'%3E%3C/svg%3E)![mm-ast-icon-1675](https://www.ontotext.com/wp-content/uploads/2024/09/icon-message-square.svg)Strategy and Technology Consulting](https://www.ontotext.com/services/semantic-technology-consulting/)
      * [ ![mm-ast-icon-57535](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-57535](https://www.ontotext.com/wp-content/uploads/2024/09/icon-settings.svg)GraphDB Development Support](https://www.ontotext.com/services/graphdb-development-support/)
      * [ ![mm-ast-icon-57527](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2020'%3E%3C/svg%3E)![mm-ast-icon-57527](https://www.ontotext.com/wp-content/uploads/2024/09/icon-sliders.svg)Semantic Data Modeling](https://www.ontotext.com/services/semantic-data-modeling/)
      * [ ![mm-ast-icon-57536](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2021%2021'%3E%3C/svg%3E)![mm-ast-icon-57536](https://www.ontotext.com/wp-content/uploads/2024/09/icon-tool.svg)GraphDB Managed Services](https://www.ontotext.com/services/graphdb-managed-services/)
      * [ ![mm-ast-icon-1677](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-1677](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Text Analytics](https://www.ontotext.com/services/text-mining-and-text-analytics/)
      * [ ![mm-ast-icon-1679](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2014'%3E%3C/svg%3E)![mm-ast-icon-1679](https://www.ontotext.com/wp-content/uploads/2024/09/icon-trending-up.svg)Trainings](https://www.ontotext.com/services/semantic-technology-trainings/)
  * [ Knowledge Hub ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * Resources Menu Toggle
      * [ ![mm-ast-icon-52802](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2023%2024'%3E%3C/svg%3E)![mm-ast-icon-52802](https://www.ontotext.com/wp-content/uploads/2024/09/icon-shine.svg)AI in Action](https://www.ontotext.com/ai-in-action/)
      * [ ![mm-ast-icon-26394](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2016%2020'%3E%3C/svg%3E)![mm-ast-icon-26394](https://www.ontotext.com/wp-content/uploads/2024/09/icon-bookmark.svg)Case studies](https://www.ontotext.com/knowledge-hub/case-studies/)
      * [ ![mm-ast-icon-26395](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-26395](https://www.ontotext.com/wp-content/uploads/2024/09/icon-book.svg)White papers](https://www.ontotext.com/knowledge-hub/white_paper/)
      * [ ![mm-ast-icon-26392](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2024'%3E%3C/svg%3E)![mm-ast-icon-26392](https://www.ontotext.com/wp-content/uploads/2024/09/icon-light.svg)Fundamentals](https://www.ontotext.com/knowledge-hub/fundamentals/)
      * [ ![mm-ast-icon-59010](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2022'%3E%3C/svg%3E)![mm-ast-icon-59010](https://www.ontotext.com/wp-content/uploads/2024/10/ontotext-icon-demo-services-icon.svg)Technology Demonstrators](https://www.ontotext.com/knowledge-hub/demoservices/)
      * [ ![mm-ast-icon-26396](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2022'%3E%3C/svg%3E)![mm-ast-icon-26396](https://www.ontotext.com/wp-content/uploads/2024/09/icon-play.svg)Videos](https://www.ontotext.com/knowledge-hub/videos/)
      * [ ![mm-ast-icon-26390](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-26390](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Publications](https://www.ontotext.com/knowledge-hub/publications/)
    * News and webinars Menu Toggle
      * [ ![mm-ast-icon-57525](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2023'%3E%3C/svg%3E)![mm-ast-icon-57525](https://www.ontotext.com/wp-content/uploads/2024/09/icon-megaphone.svg)News](https://www.ontotext.com/company/news/)
      * [ ![mm-ast-icon-26393](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2016'%3E%3C/svg%3E)![mm-ast-icon-26393](https://www.ontotext.com/wp-content/uploads/2024/09/icon-camera.svg)Webinars](https://www.ontotext.com/knowledge-hub/webinars/)
    * Latest resource

* [![SynthMedic: Utilizing large language models for synthetic discharge summary generation, correction and validation](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202000%201000'%3E%3C/svg%3E)![SynthMedic: Utilizing large language models for synthetic discharge summary generation, correction and validation](https://www.ontotext.com/wp-content/uploads/2024/04/Publication.png)](https://www.ontotext.com/knowledgehub/publications/using-llm-for-synthetic-discharge-summary-generation-correction-validation/)

## [SynthMedic: Utilizing large language models for synthetic discharge summary generation, correction and validation](https://www.ontotext.com/knowledgehub/publications/using-llm-for-synthetic-discharge-summary-generation-correction-validation/)

Georgi Grazhdanski, Vasil Vasilev, Sylvia Vassileva, Dimitar Taskov, Izabel Antova, Ivan Koychev, Svetla Boytcheva, SynthMedic: Utilizing large language models for

[**Read more**](https://www.ontotext.com/knowledgehub/publications/using-llm-for-synthetic-discharge-summary-generation-correction-validation/)

* [ Blog ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * [ Blog![mm-ast-icon-57545](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-57545](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg) ](https://www.ontotext.com/blog/)Menu Toggle
      * [ ![mm-ast-icon-61523](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2023%2024'%3E%3C/svg%3E)![mm-ast-icon-61523](https://www.ontotext.com/wp-content/uploads/2024/09/icon-shine.svg)AI in Action](https://www.ontotext.com/category/ai/)
      * [ ![mm-ast-icon-61517](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-61517](https://www.ontotext.com/wp-content/uploads/2024/09/icon-book.svg)Informational](https://www.ontotext.com/category/informational/)
      * [ ![mm-ast-icon-61518](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-61518](https://www.ontotext.com/wp-content/uploads/2024/10/briefcase-orange.svg)Business](https://www.ontotext.com/category/business/)
      * [ ![mm-ast-icon-61519](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-61519](https://www.ontotext.com/wp-content/uploads/2024/09/icon-settings.svg)Technology](https://www.ontotext.com/category/technology/)
      * [ ![mm-ast-icon-61520](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-61520](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)GraphDB Q&As](https://www.ontotext.com/category/graphdb-qnas/)
      * [ ![mm-ast-icon-61521](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2016%2024'%3E%3C/svg%3E)![mm-ast-icon-61521](https://www.ontotext.com/wp-content/uploads/2024/10/microphone.svg)Interviews](https://www.ontotext.com/category/interviews/)
      * [ ![mm-ast-icon-61522](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2020'%3E%3C/svg%3E)![mm-ast-icon-61522](https://www.ontotext.com/wp-content/uploads/2024/09/icon-users.svg)Guest Posts](https://www.ontotext.com/category/guest-posts/)
      * [ ![mm-ast-icon-61524](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2023'%3E%3C/svg%3E)![mm-ast-icon-61524](https://www.ontotext.com/wp-content/uploads/2024/09/icon-megaphone.svg)In the Media](https://www.ontotext.com/category/in-the-media/)
  * [ Company ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * Company Menu Toggle
      * [ ![mm-ast-icon-38352](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-38352](https://www.ontotext.com/wp-content/uploads/2024/09/icon-flag.svg)About us](https://www.ontotext.com/about-us/)
      * [ ![mm-ast-icon-1941](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2022'%3E%3C/svg%3E)![mm-ast-icon-1941](https://www.ontotext.com/wp-content/uploads/2024/09/icon-rocket.svg)Customers](https://www.ontotext.com/company/customers/)
      * [ ![mm-ast-icon-2199](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-2199](https://www.ontotext.com/wp-content/uploads/2024/09/icon-suitcase.svg)CareersWe’re hiring!](https://www.ontotext.com/company/careers/)
      * [ ![mm-ast-icon-31866](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2020'%3E%3C/svg%3E)![mm-ast-icon-31866](https://www.ontotext.com/wp-content/uploads/2024/09/icon-users.svg)Our team](https://www.ontotext.com/company/team/)
      * [ ![mm-ast-icon-58370](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-58370](https://www.ontotext.com/wp-content/uploads/2024/09/icon-circles.svg)Partners](https://www.ontotext.com/company/partners/)
      * [ ![mm-ast-icon-57849](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2024'%3E%3C/svg%3E)![mm-ast-icon-57849](https://www.ontotext.com/wp-content/uploads/2024/09/icon-light.svg)Research projects](https://www.ontotext.com/research-projects/)
    * [ Looking for a new career? Get in touch![mm-ast-icon-57521](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-57521](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg)](mailto:jobs@ontotext.com)
  * [ Ask our AI](https://www.ontotext.com/ontotext-knowledge-graph/)
  * [ Contact Us](https://www.ontotext.com/contact/)

[Knowledge Hub](https://www.ontotext.com/knowledge-hub/) ![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/chevron-right.svg)![](/wp-content/uploads/2024/06/chevron-right.svg) [Webinars](https://www.ontotext.com/knowledge-hub/webinars/)

#  RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits: Standards, Semantics & Interoperability

For many years, two main advantages of labeled property graphs (LPG) have been pointed out: they can deal with properties on edges in the graph and they are good for graph traversal. Watch this webinar to learn why are they gone now.

![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/ontotext-clock-icon.svg)![](/wp-content/uploads/2024/06/ontotext-clock-icon.svg) January 27, 07:30 PM +0330

[ ](https://www.ontotext.com/#copy_link) [ ](https://www.ontotext.com/#linkedin) [ ](https://www.ontotext.com/#x) [ ](https://www.ontotext.com/#facebook)

![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/RDF-Levels-the-Advantages-of-Labeled-Property-Graphs-Keeps-.png)![](https://www.ontotext.com/wp-content/uploads/2021/12/RDF-Levels-the-Advantages-of-Labeled-Property-Graphs-Keeps-Three-Key-Benefits-Standards-Semantics-Interoperabilit_01-1024x512.png)""" ;
    onto:mentionsConcept onto:Contact_Us,
        onto:Dimitar_Taskov,
        onto:Ivan_Koychev,
        onto:Keeps_Three_Key,
        onto:Managed_Services,
        onto:Menu_Toggle,
        onto:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability,
        onto:Semantic_Data_Modeling,
        onto:SynthMedic_Utilizing_large_language_models_for_synthetic_discharge_summary_generation_correction_and_validationhttpswwwontotextcomknowledgehubpublicationsusing-llm-for-synthetic-discharge-summary-generation-correction-validation,
        onto:Vasil_Vasilev .

sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_4 a onto:Chunk ;
    onto:chunkIndex 4 ;
    onto:chunkText """#### The recording of this webinar is available on **_[YouTube](https://youtu.be/8nbb6CwpPMA)_**.

####

Knowledge graphs are the next generation tool for helping businesses make critical decisions, based on harmonized knowledge models and data derived from siloed source systems. Due to the huge value generated by their data standardization and semantic modelling capabilities, knowledge graphs are most often associated with data integration, linking, unification and information reuse. As more and more organizations are turning to knowledge graphs for better data and content analytics, search and graph exploration become key requirements also.

For many years, two main advantages of labelled property graphs (LPG) have been pointed out:

1. They can deal with properties on edges in the graph, and
  2. They are good for graph traversal.

These advantages seem less powerful now with leading triplestores supporting RDF-star, which offers a simple and efficient mechanism to attach metadata to the edges of a graph (e.g. weights, access restrictions and provenance information), and SPARQL extensions that allow for exploration of multi-hop relationships in graphs.

The support for these extensions of the RDF and SPARQL is not implemented as a patch allowing us to check the box. RDF-star is already used by tools downstream and evaluations that prove efficiency improvement in managing Wikidata. RDF-star goes beyond the expressivity of LPG offering, not just key-value pairs, but rather the full flexibility of making statements about statements.

Ever since version 1.1 SPARQL property paths support graph traversal, allowing you to discover relationships between resources through arbitrary length patterns. Property paths uncover the start and end nodes of a specific path, but not the intermediate ones. There are standard complaint extensions of SPARQL now, which offer exploration of the paths and support all the different variants of the task, e.g. shortest path vs. all paths. And there are RDF engines that take advantage of their reasoning capabilities to score well at the LDBC Social Network Benchmark.""" ;
    onto:mentionsConcept onto:Knowledge_graphs_are_the_next_generation_tool_for_helping_businesses_make_critical_decisions_based_on_harmonized_knowledge_models_and_data_derived_from_siloed_source_systems_Due_to_the_huge_value_generated_by_their_data_standardization_and_semantic_modelling_capabilities_knowledge_graphs_are_most_often_associated_with_data_integration_linking_unification_and_information_reuse_As_more_and_more_organizations_are_turning_to_knowledge_graphs_for_better_data_and_content_analytics_search_and_graph_exploration_become_key_requirements_also,
        onto:Social_Network_Benchmark,
        onto:The_recording_of_this_webinar_is_available_on__YouTubehttpsyoutube8nbb6CwpPMA_ .

sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_5 a onto:Chunk ;
    onto:chunkIndex 5 ;
    onto:chunkText """Having graph exploration covered, let us go back to the core requirements for knowledge graph management. RDF is recognized as the better option for knowledge graphs, because its web-native syntax supports data exchange and sharing and because its formal semantics allows for easy alignment of meaning and structure across sources, unified views and unambiguous interpretation. On the other hand, LPGs lack many features that are an absolute must for enterprise data management, e.g. schema language, data serialization formats and federation. On the semantics side, they lack ontology modelling language and data validation. What’s most important, there are no standards in the LPG space to guarantee interoperability and reduce vendor lock-in.

RDF engines check all the boxes: simple-yet-powerful graph model, standard schema and query languages, formal semantics, efficient graph traversal, analytics and reasoning, packed with all the enterprise features. There are a couple of cases where LPGs still have an edge: a micromanaged exploration using Gremlin and heavy analytics for wardrobes with TBs of RAM.

**Who is this webinar for:**

* Enterprise information management professionals
  * Alliance managers of technology providers and consultants
  * Enterprise software salespeople

**Expected duration:**

* 45 minutes presentation
  * 15 minutes Q&A session

## Meet the speakers

![Atanas Kiryakov](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/Atanas-Kiryakov.png)

Atanas Kiryakov

CEO, Ontotext

Atanas Kiryakov is the founder and CEO of Ontotext and member of the board of the Linked Data Benchmarking Council – standardization body, who's members include the major graph database vendors. Kiryakov obtained his M.Sc. degree in AI from the Sofia University, Bulgaria, in 1995. Today he is a top expert in semantic graph databases, reasoning, knowledge graphs, text mining, semantic tagging, linking and search. Author of signature academic publications with more than 2500 citations. Atanas is partner and board member in Sirma Group Holding – one of the biggest Bulgarian IT businesses, listed at the Sofia Stock Exchange. Atanas started in Sirma as software engineer in 1993 and became a partner in 1997. In the 90s he has led projects in the areas of CASE, CSCW, and b2b for big corporations and government organizations in US and Canada.

[ ](https://www.linkedin.com/in/atanas-kiryakov-62a465/)

Share this webinar

[ ](https://www.ontotext.com/#copy_link) [ ](https://www.ontotext.com/#linkedin) [ ](https://www.ontotext.com/#x) [ ](https://www.ontotext.com/#facebook)""" ;
    onto:mentionsConcept onto:Atanas_Kiryakov,
        onto:Keeps_Three_Key,
        onto:Labeled_Property_Graphs,
        onto:Linked_Data_Benchmarking_Council,
        onto:Meet_the_speakers,
        onto:Ontotext_Atanas_Kiryakov,
        onto:Sirma_Group_Holding,
        onto:Sofia_Stock_Exchange,
        onto:Sofia_University .

sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability_chunk_1 a onto:Chunk ;
    onto:chunkIndex 1 ;
    onto:chunkText """Interoperability is essential for overcoming the challenges posed by data silos and vendor lock-in. It enables different systems and applications to communicate and share data effectively, fostering collaboration and innovation. The EU Data Act underscores the need for interoperability by requiring service providers to adopt standardized formats and protocols, thus ensuring that data can flow seamlessly between platforms.

Linked Data and semantic web technologies play a pivotal role in enhancing interoperability. By using standardized vocabularies and ontologies, Linked Data allows organizations to create rich, interconnected data networks that are easily accessible and understandable. This approach not only improves data integration but also enhances the ability to derive insights from diverse data sources.

### The Promise of Linked Data

Linked Data represents a paradigm shift in data management, moving away from traditional database models and toward a more interconnected approach. By enabling data to be linked and queried across different domains, Linked Data fosters a more holistic view of information. This interconnectedness is particularly beneficial in breaking down data silos, as it allows organizations to access and utilize data from various sources without being constrained by proprietary formats.

Moreover, Linked Data enhances data governance by providing clear semantics and context, enabling organizations to better understand the relationships between different data entities. This improved understanding is crucial for ensuring compliance with regulations like the EU Data Act, as organizations can more easily track data provenance and manage data sharing obligations.

## The Interplay Between the EU Data Act and Linked Data

The EU Data Act and Linked Data are complementary forces in the quest for better data management. The Act's regulatory framework encourages the adoption of Linked Data principles by promoting interoperability and data portability. As organizations increasingly embrace Linked Data, they can leverage the EU Data Act's provisions to enhance their data-sharing capabilities and reduce the risks associated with vendor lock-in.

For instance, organizations that implement Linked Data principles can more easily transition between service providers, as their data will be structured in a way that is compatible with various platforms. This compatibility not only facilitates smoother transitions but also encourages a more competitive marketplace, ultimately benefiting consumers.

### Knowledge Graphs: A Tool for Enhancing Data Interoperability""" ;
    onto:mentionsConcept onto:Data_Act,
        onto:Enhancing_Data_Interoperability,
        onto:Knowledge_Graphs,
        onto:Knowledge_Graphs_A_Tool_for_Enhancing_Data_Interoperability,
        onto:Linked_Data,
        onto:Linked_Data_Linked_Data,
        onto:The_Interplay_Between_the_EU_Data_Act_and_Linked_Data,
        onto:The_Promise_of_Linked_Data .

sources:The_EU_Data_Act_and_the_Promise_of_Linked_Data_Addressing_Vendor_Lock-in_and_Data_Silos_Through_Interoperability_chunk_2 a onto:Chunk ;
    onto:chunkIndex 2 ;
    onto:chunkText """Knowledge graphs are a powerful tool for enhancing data interoperability, particularly in the context of Linked Data. By representing data as a network of interconnected entities, knowledge graphs enable organizations to visualize relationships and dependencies between various data points. This visualization is crucial for breaking down data silos and promoting collaboration across different departments and organizations.

The use of knowledge graphs aligns with the objectives of the EU Data Act, as they provide a framework for organizing and managing data in a way that is both compliant with regulatory requirements and conducive to innovation. By adopting knowledge graphs, organizations can enhance their data governance practices, ensuring that data is accessible, understandable, and usable across different contexts.

## Conclusion: A Call for Action

The EU Data Act, along with the principles of Linked Data and the utilization of knowledge graphs, offers a promising path forward in addressing the challenges posed by vendor lock-in and data silos. As organizations increasingly recognize the importance of interoperability in their data management strategies, they must embrace these frameworks and technologies to unlock their full potential.

This is a call for action for policymakers, businesses, and technologists to collaborate in creating an ecosystem that prioritizes data accessibility, interoperability, and innovation. By doing so, we can empower organizations to navigate the complexities of the digital landscape while fostering a more competitive and equitable data economy. The future of data management lies in our ability to break down barriers, and the EU Data Act, Linked Data, and knowledge graphs are key to achieving this vision.""" ;
    onto:mentionsConcept onto:Conclusion_A_Call_for_Action,
        onto:Data_Act,
        onto:Linked_Data .

sources:The_FAIR_Guiding_Principles_for_scientific_data_management_and_stewardshippdf_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """Comment: The FAIR Guiding
Principles for scienti ﬁc data
management and stewardship
Mark D. Wilkinson et al. #
There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse
set of stakeholders — representing academia, industry, funding agencies, and scholarly publishers — have
come together to design and jointly endorse a concise and measureable set of principles that we refer
to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to
enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human
scholar, the FAIR Principles put speci ﬁc emphasis on enhancing the ability of machines to automatically
ﬁnd and use the data, in addition to supporting its reuse by individuals. This Comment is the ﬁrst
formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar
implementations in the community.
Supporting discovery through good data management
Good data management is not a goal in itself, but rather is the key conduit leading to knowledge
discovery and innovation, and to subsequent data and knowledge integration and reuse by the
community after the data publication process. Unfortunately, the existing digital ecosystem
surrounding scholarly data publication prevents us from extracting maximum bene ﬁtf r o mo u r
research investments (e.g., ref. 1). Partially in response to this, science funders, publishers and
governmental agencies are beginning to require data management and stewardship plans for data
generated in publicly funded experiments. Beyond proper collection, annotation, and archival, data
stewardship includes the notion of ‘long-term care’ of valuable digital assets, with the goal that they
should be discovered and re-used for downstream investigations, either alone, or in combination with
newly generated data. The outcomes from good data management and stewardship, therefore, are
high quality digital publications that facilitate and simplify this ongoing process of discovery, evaluation,
and reuse in downstream studies. What constitutes ‘good data management ’ is, however, largely
undeﬁned, and is generally left as a decision for the data or repository owner. Therefore, bringing some
clarity around the goals and desiderata of good data management and stewardship, and de ﬁning
simple guideposts to inform those who publish and/or preserve scholarly data, would be of great utility.
This article describes four foundational principles — Findability, Accessibility, Interoperability, and
Reusability— that serve to guide data producers and publishers as they navigate around these
obstacles, thereby helping to maximize the added-value gained by contemporary, formal scholarly
digital publishing. Importantly, it is our intent that the principles apply not only to ‘data’ in the
conventional sense, but also to the algorithms, tools, and work ﬂows that led to that data. All
scholarly digital research objects 2— from data to analytical pipelines — beneﬁt from application of
these principles, since all components of the research process must be available to ensure
transparency, reproducibility, and reusability.
There are numerous and diverse stakeholders who stand to bene ﬁt from overcoming these obstacles:
researchers wanting to share, get credit, and reuse each other ’s data and interpretations; professional
data publishers offering their services; software and tool-builders providing data analysis and
processing services such as reusable work ﬂows; funding agencies (private and public) increasingly
Correspondence and requests for materials should be addressed to B.M. (email: barend.mons@dtls.nl).
#A full list of authors and their af ﬁliations appears at the end of the paper.
Amended: Addendum
OPEN
SUBJECT CATEGORIES
» Research data
» Publication
characteristics
Received: 10 December 2015
Accepted: 12 February 2016
Published: 15 March 2016
www.nature.com/scientificdata
SCIENTIFIC DATA | 3:160018 | DOI: 10.1038/sdata.2016.18 1
concerned with long-term data stewardship; and a data science community mining, integrating and
analysing new and existing data to advance discovery. To facilitate the reading of this manuscript by
these diverse stakeholders, we provide de ﬁnitions for common abbreviations in Box 1. Humans,
however, are not the only critical stakeholders in the milieu of scienti ﬁc data. Similar problems are
encountered by the applications and computational agents that we task to undertake data retrieval
and analysis on our behalf. These ‘computational stakeholders ’are increasingly relevant, and demand
as much, or more, attention as their importance grows. One of the grand challenges of data-intensive
science, therefore, is to improve knowledge discovery through assisting both humans, and their
computational agents, in the discovery of, access to, and integration and analysis of, task-appropriate
scientiﬁc data and other scholarly digital objects.
For certain types of important digital objects, there are well-curated, deeply-integrated,
special-purpose repositories such as Genbank 3, Worldwide Protein Data Bank (wwPDB 4), and
UniProt5 in the life sciences; Space Physics Data Facility (SPDF; http://spdf.gsfc.nasa.gov/) and Set of
Identiﬁcations, Measurements and Bibliography for Astronomical Data (SIMBAD 6) in the space
sciences. These foundational and critical core resources are continuously curating and capturing high-
value reference datasets and ﬁne-tuning them to enhance scholarly output, provide support for both
human and mechanical users, and provide extensive tooling to access their content in rich, dynamic
ways. However, not all datasets or even data types can be captured by, or submitted to, these
repositories. Many important datasets emerging from traditional, low-throughput bench science don ’t
ﬁt in the data models of these special-purpose repositories, yet these datasets are no less important
with respect to integrative research, reproducibility, and reuse in general. Apparently in response to
this, we see the emergence of numerous general-purpose data repositories, at scales ranging from
institutional (for example, a single university), to open globally-scoped repositories such as Dataverse 7,
FigShare (http:// ﬁgshare.com), Dryad 8, Mendeley Data (https://data.mendeley.com/), Zenodo (http://
zenodo.org/), DataHub (http://datahub.io), DANS (http://www.dans.knaw.nl/), and EUDat 9. Such
repositories accept a wide range of data types in a wide variety of formats, generally do not attempt
to integrate or harmonize the deposited data, and place few restrictions (or requirements) on the
descriptors of the data deposition. The resulting data ecosystem, therefore, appears to be moving
away from centralization, is becoming more diverse, and less integrated, thereby exacerbating the
discovery and re-usability problem for both human and computational stakeholders.
As p e c iﬁc example of these obstacles could be imagined in the domain of gene regulation and expression
analysis. Suppose a researcher has generated a dataset of differentially-selected polyadenylation sites in
a non-model pathogenic organism grown under a variety of environmental conditions that stimulate its
pathogenic state. The researcher is interested in comparing the alternatively-polyadenylated genes in
this local dataset, to other examples of alternative-polyadenylation, and the expression levels of these
genes— both in this organism and related model organisms — during the infection process. Given that
there is no special-purpose archive for differential polyadenylation data, and no model organism
database for this pathogen, where does the researcher begin?
We will consider the current approach to this problem from a variety of data discovery and integration
perspectives. If the desired datasets existed, where might they have been published, and how would
one begin to search for them, using what search tools? The desired search would need to ﬁlter based
on speci ﬁc species, speci ﬁc tissues, speci ﬁc types of data (Poly-A, microarray, NGS), speci ﬁc
conditions (infection), and speci ﬁc genes — is that information ( ‘metadata’) captured by the
repositories, and if so, what formats is it in, is it searchable, and how? Once the data is discovered,
can it be downloaded? In what format(s)? Can that format be easily integrated with private in-house
data (the local dataset of alternative polyadenylation sites) as well as other data publications from
third-parties and with the community ’s core gene/protein data repositories? Can this integration be
Box 1 | Terms and Abbreviations
BD2K— Big Data 2 Knowledge, is a trans-NIH initiative established to enable biomedical research as a digital research enterprise, to facilitate discovery and
support new knowledge, and to maximise community engagement.
DOI— Digital Object Identi ﬁer; a code used to permanently and stably identify (usually digital) objects. DOIs provide a standard mechanism for retrieval of
metadata about the object, and generally a means to access the data object itself.
FAIR— Findable, Accessible, Interoperable, Reusable.
FORCE11— The Future of Research Communications and e-Scholarship; a community of scholars, librarians, archivists, publishers and research funders that
has arisen organically to help facilitate the change toward improved knowledge creation and sharing, initiated in 2011.
Interoperability— the ability of data or tools from non-cooperating resources to integrate or work together with minimal effort.
JDDCP— Joint Declaration of Data Citation Principles; Acknowledging data as a ﬁrst-class research output, and to support good research practices around
data re-use, JDDCP proposes a set of guiding principles for citation of data within scholarly literature, another dataset, or any other research obje ct.
RDF— Resource Description Framework; a globally-accepted framework for data and knowledge representation that is intended to be read and interpreted
by machines.
www.nature.com/sdata/
SCIENTIFIC DATA | 3:160018 | DOI: 10.1038/sdata.2016.18 2
done automatically to save time and avoid copy/paste errors? Does the researcher have permission to
use the data from these third-party researchers, under what license conditions, and who should be
cited if a data-point is re-used?
Questions such as these highlight some of the barriers to data discovery and reuse, not only for
humans, but even more so for machines; yet it is precisely these kinds of deeply and broadly
integrative analyses that constitute the bulk of contemporary e-Science. The reason that we often
need several weeks (or months) of specialist technical effort to gather the data necessary to answer
such research questions is not the lack of appropriate technology; the reason is, that we do not pay
our valuable digital objects the careful attention they deserve when we create and preserve them.
Overcoming these barriers, therefore, necessitates that all stakeholders — including researchers,
special-purpose, and general-purpose repositories — evolve to meet the emergent challenges
described above. The goal is for scholarly digital objects of all kinds to become ‘ﬁrst class citizens ’
in the scienti ﬁc publication ecosystem, where the quality of the publication — and more importantly,
the impact of the publication — is a function of its ability to be accurately and appropriately found, re-
used, and cited over time, by all stakeholders, both human and mechanical.
With this goal in-mind, a workshop was held in Leiden, Netherlands, in 2014, named ‘Jointly
Designing a Data Fairport ’. This workshop brought together a wide group of academic and private
stakeholders all of whom had an interest in overcoming data discovery and reuse obstacles. From the
deliberations at the workshop the notion emerged that, through the de ﬁnition of, and widespread
support for, a minimal set of community-agreed guiding principles and practices, all stakeholders
could more easily discover, access, appropriately integrate and re-use, and adequately cite, the vast
quantities of information being generated by contemporary data-intensive science. The meeting
concluded with a draft formulation of a set of foundational principles that were subsequently
elaborated in greater detail — namely, that all research objects should be Findable, Accessible,
Interoperable and Reusable (FAIR) both for machines and for people. These are now referred to as the
FAIR Guiding Principles. Subsequently, a dedicated FAIR working group, established by several
members of the FORCE 11 community10 ﬁne-tuned and improved the Principles. The results of these
efforts are reported here.
The signi ﬁcance of machines in data-rich research environments
The emphasis placed on FAIRness being applied to both human-driven and machine-driven activities,
is a speci ﬁc focus of the FAIR Guiding Principles that distinguishes them from many peer initiatives
(discussed in the subsequent section). Humans and machines often face distinct barriers when
attempting to ﬁnd and process data on the Web. Humans have an intuitive sense of ‘semantics’(the
meaning or intent of a digital object) because we are capable of identifying and interpreting a wide
variety of contextual cues, whether those take the form of structural/visual/iconic cues in the layout of
a Web page, or the content of narrative notes. As such, we are less likely to make errors in the
selection of appropriate data or other digital objects, although humans will face similar dif ﬁculties if
sufﬁcient contextual metadata is lacking. The primary limitation of humans, however, is that we are
unable to operate at the scope, scale, and speed necessitated by the scale of contemporary scienti ﬁc
data and complexity of e-Science. It is for this reason that humans increasingly rely on computational
agents to undertake discovery and integration tasks on their behalf. This necessitates machines to be
capable of autonomously and appropriately acting when faced with the wide range of types, formats,
and access-mechanisms/protocols that will be encountered during their self-guided exploration of the
global data ecosystem. It also necessitates that the machines keep an exquisite record of provenance
such that the data they are collecting can be accurately and adequately cited. Assisting these agents,
therefore, is a critical consideration for all participants in the data management and stewardship
process— from researchers and data producers to data repository hosts.
Throughout this paper, we use the phrase ‘machine actionable ’ to indicate a continuum of possible
states wherein a digital object provides increasingly more detailed information to an autonomously-
acting, computational data explorer. This information enables the agent — to a degree dependent on
the amount of detail provided — to have the capacity, when faced with a digital object never
encountered before, to: a) identify the type of object (with respect to both structure and intent), b)
determine if it is useful within the context of the agent ’s current task by interrogating metadata and/
or data elements, c) determine if it is usable, with respect to license, consent, or other accessibility or
use constraints, and d) take appropriate action, in much the same manner that a human would.
For example, a machine may be capable of determining the data-type of a discovered digital object,
but not capable of parsing it due to it being in an unknown format; or it may be capable of processing
the contained data, but not capable of determining the licensing requirements related to the retrieval
and/or use of that data. The optimal state — where machines fully ‘understand’and can autonomously
and correctly operate-on a digital object — may rarely be achieved. Nevertheless, the FAIR principles
provide ‘steps along a path ’ toward machine-actionability; adopting, in whole or in part, the FAIR
www.nature.com/sdata/
SCIENTIFIC DATA | 3:160018 | DOI: 10.1038/sdata.2016.18 3
principles, leads the resource along the continuum towards this optimal state. In addition, the idea of
being machine-actionable applies in two contexts — ﬁrst, when referring to the contextual metadata
surrounding a digital object ( ‘what is it? ’), and second, when referring to the content of the digital
object itself ( ‘how do I process it/integrate it? ’). Either, or both of these may be machine-actionable,
and each forms its own continuum of actionability.
Finally, we wish to draw a distinction between data that is machine-actionable as a result of speci ﬁc
investment in software supporting that data-type, for example, bespoke parsers that understand life
science wwPDB ﬁles or space science Space Physics Archive Search and Extract (SPASE) ﬁles, and
data that is machine-actionable exclusively through the utilization of general-purpose, open
technologies. To reiterate the earlier point — ultimate machine-actionability occurs when a machine
can make a useful decision regarding data that it has not encountered before. This distinction is
important when considering both (a) the rapidly growing and evolving data environment, with new
technologies and new, more complex data-types continuously being developed, and (b) the growth of
general-purpose repositories, where the data-types likely to be encountered by an agent are
unpredictable. Creating bespoke parsers, in all computer languages, for all data-types and all
analytical tools that require those data-types, is not a sustainable activity. As such, the focus on
assisting machines in their discovery and exploration of data through application of more generalized
interoperability technologies and standards at the data/repository level, becomes a ﬁrst-priority for
good data stewardship.
The FAIR Guiding Principles in detail
Representatives of the interested stakeholder-groups, discussed above, coalesced around four core
desiderata— the FAIR Guiding Principles — and limited elaboration of these, which have been re ﬁned
(Box 2) from the meeting ’s original draft, available at (https://www.force 11.org/node/6062). A
separate document that dynamically addresses community discussion relating to clari ﬁcations and
explanations of the principles, and detailed guidelines for and examples of FAIR implementations, is
currently being constructed (http://datafairport.org/fair-principles-living-document-menu). The FAIR
Guiding Principles describe distinct considerations for contemporary data publishing environments
with respect to supporting both manual and automated deposition, exploration, sharing, and reuse.
While there have been a number of recent, often domain-focused publications advocating for speci ﬁc
improvements in practices relating to data management and archival 1,11,12, FAIR differs in that it
describes concise, domain-independent, high-level principles that can be applied to a wide range of
scholarly outputs. Throughout the Principles, we use the phrase ‘(meta)data’ in cases where the
Principle should be applied to both metadata and data.
The elements of the FAIR Principles are related, but independent and separable. The Principles de ﬁne
characteristics that contemporary data resources, tools, vocabularies and infrastructures should
exhibit to assist discovery and reuse by third-parties. By minimally de ﬁning each guiding principle, the
barrier-to-entry for data producers, publishers and stewards who wish to make their data holdings
FAIR is purposely maintained as low as possible. The Principles may be adhered to in any combination
and incrementally, as data providers ’ publishing environments evolve to increasing degrees of
‘FAIRness’. Moreover, the modularity of the Principles, and their distinction between data and
metadata, explicitly support a wide range of special circumstances. One such example is highly
sensitive or personally-identi ﬁable data, where publication of rich metadata to facilitate discovery,
including clear rules regarding the process for accessing the data, provides a high degree of ‘FAIRness’
even in the absence of FAIR publication of the data itself. A second example involves the publication
Box 2 | The FAIR Guiding Principles
To be Findable:
F1. (meta)data are assigned a globally unique and persistent identi ﬁer
F2. data are described with rich metadata (de ﬁned by R 1 below)
F3. metadata clearly and explicitly include the identi ﬁer of the data it describes
F4. (meta)data are registered or indexed in a searchable resource
To be Accessible:
A1. (meta)data are retrievable by their identi ﬁer using a standardized communications protocol
A1.1 the protocol is open, free, and universally implementable
A1.2 the protocol allows for an authentication and authorization procedure, where necessary
A2. metadata are accessible, even when the data are no longer available
To be Interoperable:
I1. (meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation.
I2. (meta)data use vocabularies that follow FAIR principles
I3. (meta)data include quali ﬁed references to other (meta)data
To be Reusable:
R1. meta(data) are richly described with a plurality of accurate and relevant attributes
R1.1. (meta)data are released with a clear and accessible data usage license
R1.2. (meta)data are associated with detailed provenance
R1.3. (meta)data meet domain-relevant community standards
www.nature.com/sdata/
SCIENTIFIC DATA | 3:160018 | DOI: 10.1038/sdata.2016.18 4
of non-data research objects. Analytical work ﬂows, for example, are a critical component of the
scholarly ecosystem, and their formal publication is necessary to achieve both transparency and
scientiﬁc reproducibility. The FAIR principles can equally be applied to these non-data assets, which
need to be identi ﬁed, described, discovered, and reused in much the same manner as data.
Speciﬁc exemplar efforts that provide varying levels of FAIRness are detailed later in this document.
Additional issues, however, remain to be addressed. First, when community-endorsed vocabularies or
other (meta)data standards do not include the attributes necessary to achieve rich annotation, there
are two possible solutions: either publish an extension of an existing, closely related vocabulary, or — in
the extreme case — create and explicitly publish a new vocabulary resource, following FAIR principles
(‘I2’). Second, to explicitly identify the standard chosen when more than one vocabulary or other
(meta)data standard is available, and given that for instance in the life sciences there are over 600
content standards, the BioSharing registry (https://biosharing.org/) can be of use as it describes the
standards in detail, including versions where applicable.
The Principles precede implementation
These high-level FAIR Guiding Principles precede implementation choices, and do not suggest any
speciﬁc technology, standard, or implementation-solution; moreover, the Principles are not,
themselves, a standard or a speci ﬁcation. They act as a guide to data publishers and stewards to
assist them in evaluating whether their particular implementation choices are rendering their digital
research artefacts Findable, Accessible, Interoperable, and Reusable. We anticipate that these high
level principles will enable a broad range of integrative and exploratory behaviours, based on a wide
range of technology choices and implementations. Indeed, many repositories are already
implementing various aspects of FAIR using a variety of technology choices and several examples
are detailed in the next section; examples include Scientiﬁc Data itself and how narrative data articles
are anchored to a progressively FAIR structured metadata.
Examples of FAIRness, and the resulting value-added
Dataverse7: Dataverse is an open-source data repository software installed in dozens of institutions
globally to support public community repositories or institutional research data repositories. Harvard
Dataverse, with more than 60,000 datasets, is the largest of the current Dataverse repositories, and is
open to all researchers from all research ﬁelds. Dataverse generates a formal citation for each deposit,
following the standard de ﬁned by Altman and King 13. Dataverse makes the Digital Object Identi ﬁer
(DOI), or other persistent identi ﬁers (Handles), public when the dataset is published ( ‘F’). This resolves
to a landing page, providing access to metadata, data ﬁles, dataset terms, waivers or licenses, and
version information, all of which is indexed and searchable ( ‘F’, ‘A’, and ‘R’). Deposits include
metadata, data ﬁles, and any complementary ﬁles (such as documentation or code) needed to
understand the data and analysis ( ‘R’). Metadata is always public, even if the data are restricted or
removed for privacy issues ( ‘F’, ‘A’). This metadata is offered at three levels, extensively supporting the
‘I’and ‘R’FAIR principles: 1) data citation metadata, which maps to DataCite schema or Dublin Core
Terms, 2) domain-speci ﬁc metadata, which when possible maps to metadata standards used within a
scientiﬁc domain, and 3) ﬁle-level metadata, which can be deep and extensive for tabular data ﬁles
(including column-level metadata). Finally, Dataverse provides public machine-accessible interfaces to
search the data, access the metadata and download the data ﬁles, using a token to grant access when
data ﬁles are restricted ( ‘A’).
FAIRDOM (http://fair-dom.org/about): integrates the SEEK 14 and openBIS 15 platforms to produce a
FAIR data and model management facility for Systems Biology. Individual research assets (or
aggregates of data and models) are identi ﬁed with unique and persistent HTTP URLs, which can be
registered with DOIs for publication ( ‘F’). Assets can be accessed over the Web in a variety of formats
appropriate for individuals and/or their computers (RDF, XML) ( ‘I’). Research assets are annotated with
rich metadata, using community standards, formats and ontologies ( ‘I’). The metadata is stored as
RDF to enable interoperability and assets can be downloaded for reuse ( ‘R’).
ISA16: is a community-driven metadata tracking framework to facilitate standards-compliant
collection, curation, management and reuse of life science datasets. ISA provides progressively FAIR
structured metadata to Nature Scienti ﬁc Data ’s Data Descriptor articles, and many GigaScience data
papers, and underpins the EBI MetaboLights database among other data resources. At the heart is a
general-purpose, extensible ISA model, originally only available as a tabular representation but
subsequently enhanced as an RDF-based representation 17, and JSON serializations to enable the ‘I’
and ‘R’, becoming ‘FAIR’when published as linked data (http://elixir-uk.org/node-events/ 201cisa-as-a-
fair-research-object201d-hack-the-spec-event-1) and complementing other research objects 18.
Open PHACTS 19: Open PHACTS is a data integration platform for information pertaining to drug
discovery. Access to the platform is mediated through a machine-accessible interface 20 which
provides multiple representations that are both human (HTML) and machine readable (RDF, JSON,
www.nature.com/sdata/
SCIENTIFIC DATA | 3:160018 | DOI: 10.1038/sdata.2016.18 5
XML, CSV, etc), providing the ‘A’facet of FAIRness. The interface allows multiple URLs to be used to
access information about a particular entity through a mappings service ( ‘F’and ‘A’). Thus, a user can
provide a ChEMBL URL to retrieve information sourced from, for example, Chemspider or DrugBank.
Each call provides a canonical URL in its response ( ‘A’ and ‘I’). All data sources used are described
using standardized dataset descriptions, following the global VoID standard, with rich provenance ( ‘R’
and ‘I’). All interface features are described using RDF following the Linked Data API speci ﬁcation (‘A’).
Finally, a majority of the datasets are described using community agreed upon ontologies ( ‘I’).
wwPDB4,21: wwPDB is a special-purpose, intensively-curated data archive that hosts information
about experimentally-determined 3D structures of proteins and nucleic acids. All wwPDB entries are
stably hosted on an FTP server ( ‘A’) and represented in machine-readable formats (text and XML); the
latter are machine-actionable using the metadata provided by the wwPDB conforming to the
Macromolecular Information Framework (mmCIF 22), a data standard of the International Union of
Crystallography (IUCr) ( ‘F’,‘I’ for humans, ‘F’,‘I’ for IUCr-aware machines). The wwPDB metadata
contains cross-references to common identi ﬁers such as PubMed and NCBI Taxonomy, and their
wwPDB metadata are described in data dictionaries and schema documents (http://mmcif.wwpdb.org
and http://pdbml.wwpdb.org) which conform to the IUCr data standard for the chemical and
structural biology domains ( ‘R’). A variety of software tools are available to interpret both wwPDB
data and meta-data ( ‘I’,‘R’ for humans, ‘I’,‘R’ for machines with this software). Each entry is
represented by a DOI ( ‘F’, ‘A’ for humans and machines). The DOI resolves to a zipped ﬁle which
requires special software for further interrogation/interpretation. Other wwPDB access points 23–25
provide access to wwPDB records through URLs that are likely to be stable in the long-term ( ‘F’), and
all data and metadata is searchable through one or more of the wwPDB-af ﬁliated websites ( ‘F’)
UniProt26: UniProt is a comprehensive resource for protein sequence and annotation data. All entries
are uniquely identi ﬁed by a stable URL, that provides access to the record in a variety of formats
including a web page, plain-text, and RDF ( ‘F’and ‘A’). The record contains rich metadata ( ‘F’) that is
both human-readable (HTML) and machine-readable (text and RDF), where the RDF formatted
response utilizes shared vocabularies and ontologies such as UniProt Core, FALDO, and ECO ( ‘I’).
Interlinking with more than 150 different databases, every UniProt record has extensive links into, for
example, PubMed, enabling rich citation. These links are machine-actionable in the RDF
representation ( ‘R’). Finally, in the RDF representation, the UniProt Core Ontology explicitly types
all records, leaving no ambiguity — neither for humans nor machines — about what the data represents
(‘R’), enabling fully-automated retrieval of records and cross-referencing information.
In addition to, and in support of, communities and resources that are already pursuing FAIR
objectives, the Data Citation Implementation Group of Force 11 has published speci ﬁc technical
recommendations for how to implement many of the principles 27, with a particular focus on
identiﬁers and their resolution, persistence, and metadata accessibility especially related to citation.
In addition, the ‘Skunkworks’ group that emerged from the Lorentz Workshop has been creating
software supporting infrastructures 28 that are, end-to-end, compatible with FAIR principles, and can
be implemented over existing repositories. These code modules have a particular focus on metadata
publication and searchability, compatibility in cases of strict privacy considerations, and the extremely
difﬁcult problem of data and metadata interoperability (manuscript in preparation). Finally, there are
several emergent projects, some listed in Box 3, for which FAIR is a key objective. These projects may
provide valuable advice and guidance for those wishing to become more FAIR.
FAIRness is a prerequisite for proper data management and data stewardship
The ideas within the FAIR Guiding Principles re ﬂect, combine, build upon and extend previous work by
both the Concept Web Alliance (https://conceptweblog.wordpress.com/) partners, who focused on
machine-actionability and harmonization of data structures and semantics, and by the scienti ﬁc and
scholarly organizations that developed the Joint Declaration of Data Citation Principles (JDDCP 29),
Box 3 | Emergent community/collaborative initiatives with FAIR as a core focus or activity
bioCADDIE (https://biocaddie.org): The NIH BD 2K biomedical and healthCAre Data Discovery Index Ecosystem (bioCADDIE) consortium works to develop a
Data Discovery Index (DDI) prototype, which is set to be as transformative and impactful for data as PubMed for the biomedical literature 30. The DDI focuses
on ﬁnding (‘F’) and accessing ( ‘A’) the datasets stored across different sources, and progressively works to identify relevant metadata 31 (‘I’) and maps them to
community standards ( ‘R’), linking to BioSharing.
CEDAR32: The Center for Expanded Data Annotation and Retrieval (CEDAR) is an NIH BD 2K funded center of excellence to develop tools and technologies
that reduce the burden of authoring and enhancing metadata that meet community-based standards. CEDAR will enable the creation of metadata template s
that implement community based standards for experimental metadata, from BioSharing (https://biosharing.org), and that will be uniquely identi ﬁable and
retrievable with HTTP URIs, and annotated with vocabularies and ontologies drawn from BioPortal (http://bioportal.bioontology.org) ( ‘F’,‘A’,‘I’,‘R’). These
templates will guide users to create rich metadata with unique and stable HTTP identi ﬁers ( ‘F’) that can be retrieved using HTTP ( ‘A’) and accessible in a
variety of formats (JSON-LD, TURTLE, RDF/XML, CSV, etc) ( ‘I’). These metadata will use community standards, as de ﬁned by the template, and include
provenance and data usage ( ‘R’).
These two projects, among others, provide tools and or collaborative opportunities for those who wish to improve the FAIRness of their data.
www.nature.com/sdata/
SCIENTIFIC DATA | 3:160018 | DOI: 10.1038/sdata.2016.18 6
who focused on primary scholarly data being made citable, discoverable and available for reuse, so as
to be capable of supporting more rigorous scholarship. An attempt to de ﬁne the similarities and
overlaps between the FAIR Principles and the JDDCP is provided at (https://www.force 11.org/node/
6062). The FAIR Principles are also complementary to the ‘Data Seal of Approval ’ (DSA) (http://
datasealofapproval.org/media/ﬁler_public/2013/09/27/guidelines_2014-2015.pdf) in that they share
the general aim to render data re-usable for users other than those who originally generated them.
While the DSA focuses primarily on the responsibilities and conduct of data producers and
repositories, FAIR focuses primarily on the data itself. Clearly, the broader community of stakeholders
is coalescing around a set of common, dovetailed visions spanning all facets of the scholarly data
publishing ecosystem.
The end result, when implemented, will be more rigorous management and stewardship of these
valuable digital resources, to the bene ﬁt of the entire academic community. As stated at the outset,
good data management and stewardship is not a goal in itself, but rather a pre-condition supporting
knowledge discovery and innovation. Contemporary e-Science requires data to be Findable,
Accessible, Interoperable, and Reusable in the long-term, and these objectives are rapidly becoming
expectations of agencies and publishers. We demonstrate, therefore, that the FAIR Data Principles
provide a set of mileposts for data producers and publishers. They guide the implementation of
the most basic levels of good Data Management and Stewardship practice, thus helping researchers
adhere to the expectations and requirements of their funding agencies. We call on all data producers
and publishers to examine and implement these principles, and actively participate with the
FAIR initiative by joining the Force 11 working group. By working together towards shared, common
goals, the valuable data produced by our community will gradually achieve the critical goals
of FAIRness.
References
1. Roche, D. G., Kruuk, L. E. B., Lanfear, R. & Binning, S. A. Public Data Archiving in Ecology and Evolution: How Well Are
We Doing? PLOS Biol. 13, e1002295 (2015).
2. Bechhofer, S. et al. Research Objects: Towards Exchange and Reuse of Digital Knowledge. Nat. Preced. doi:10.1038/
npre.2010.4626.1 (2010).
3. Benson, D. A. et al. GenBank. Nucleic Acids Res. 41, D36–D42 (2013).
4. Berman, H., Henrick, K. & Nakamura, H. Announcing the worldwide Protein Data Bank. Nat. Struct. Biol. 10, 980–980 (2003).
5. The Uniprot Consortium. UniProt: a hub for protein information. Nucleic Acids Res. 43, D204–D212 (2015).
6. Wenger, M. et al. The SIMBAD astronomical database-The CDS reference database for astronomical objects. Astron. Astrophys.
Suppl. Ser. 143, 9–22 (2000).
7. Crosas, M. "The Dataverse Network ®: An Open-Source Application for Sharing, Discovering and Preserving Data". D-Lib Mag 17
(1), p2 (2011).
8. White, H. C., Carrier, S., Thompson, A., Greenberg, J. & Scherle, R. The Dryad data repository: A Singapore framework metadata
architecture in a DSpace environment. Univ. Göttingen , p157 (2008).
9. Lecarpentier, D. et al. EUDAT: A New Cross-Disciplinary Data Infrastructure for Science. Int. J. Digit. Curation 8,
279–287 (2013).
10. Martone, M. E. FORCE11: Building the Future for Research Communications and e-Scholarship. Bioscience 65, 635 (2015).
11. White, E. et al. Nine simple ways to make it easier to (re)use your data. Ideas Ecol. Evol. 6 (2013).
12. Sandve, G. K., Nekrutenko, A., Taylor, J. & Hovig, E. Ten Simple Rules for Reproducible Computational Research. PLoS Comput.
Biol. 9, e1003285 (2013).
13. Altman, M. & King, G. in D-Lib Magazine 13, no. 3/4 (2007).
14. Wolstencroft, K. et al. SEEK: a systems biology data and model management platform. BMC Syst. Biol. 9, 33 (2015).
15. Bauch, A. et al. openBIS: a ﬂexible framework for managing and analyzing complex data in biology research. BMC Bioinformatics
12, 468 (2011).
16. Sansone, S.-A. et al. Toward interoperable bioscience data. Nat. Genet. 44, 121–126 (2012).
17. González-Beltrán, A., Maguire, E., Sansone, S.-A. & Rocca-Serra, P. linkedISA: semantic representation of ISA-Tab experimental
metadata. BMC Bioinformatics 15, S4 (2014).
18. González-Beltrán, A. et al. From Peer-Reviewed to Peer-Reproduced in Scholarly Publishing: The Complementary Roles of Data
Models and Work ﬂows in Bioinformatics. PLoS ONE 10, e0127612 (2015).
19. Harland, L. Open PHACTS: A Semantic Knowledge Infrastructure for Public and Commercial Drug Discovery Research. Knowl.
Eng. Knowl. Manag. Lect. Notes Comput. Sci. 7603/2012, 1–7 (2012).
20. Groth, P. et al. API-centric Linked Data integration: The Open PHACTS Discovery Platform case study. Web Semant. Sci. Serv.
Agents World Wide Web 29, 12–18 (2014).
21. Berman, H. M. et al. The Protein Data Bank. Nucleic Acids Res. 28, 235–242 (2000).
22. Bourne, P. E., Berman, H. M., Watenpaugh, K., Westbrook, J. D. & Fitzgerald, P. M. D. The macromolecular crystallographic
information ﬁle (mmCIF). Meth. Enzym 277, 571–590 (1997).
23. Rose, P. W. et al. The RCSB Protein Data Bank: views of structural biology for basic and applied research and education. Nucleic
Acids Res. 43, D345–D356 (2015).
24. Kinjo, A. R. et al. Protein Data Bank Japan (PDBj): maintaining a structural data archive and resource description
framework format. Nucleic Acids Res. 40, D453–D460 (2012).
25. Gutmanas, A. et al. PDBe: Protein Data Bank in Europe. Nucleic Acids Res. 42, D285–D291 (2014).
26. UniProt Consortium. UniProt: a hub for protein information. Nucleic Acids Res. 43, D204–D212 (2015).
27. Starr, J. et al. Achieving human and machine accessibility of cited data in scholarly publications. PeerJ Comput. Sci. 1, e1 (2015).
28. Wilkinson, M., Dumontier, M. & Durbin, P. DataFairPort: The Perl libraries version 0.231 doi:10.5281/zenodo.33584 (2015).
29. Data Citation Synthesis Group: Joint Declaration of Data Citation Principles. San Diego CA: FORCE11. https://www.force11.org/
datacitation (2014).
30. Ohno-machado, L. et al. NIH BD2K bioCADDIE white paper — Data Discovery Index. http://dx.doi.org/10.6084/m9. ﬁg-
share.1362572 (2015).
www.nature.com/sdata/
SCIENTIFIC DATA | 3:160018 | DOI: 10.1038/sdata.2016.18 7
31. NIH BD2K bioCADDIE WG3 Members. WG3-MetadataSpeci ﬁcations: NIH BD2K bioCADDIE Data Discovery Index WG3
Metadata Speci ﬁcation v1 doi:10.5281/zenodo.28019 (2015).
32. Musen, M. A. et al. The center for expanded data annotation and retrieval. J. Am. Med. Informatics Assoc. 22, 1148–1152 (2015).
Acknowledgements
The original Lorentz Workshop ‘Jointly Designing a Data FAIRport ’was organized by Barend Mons in
collaboration with and co-sponsored by the Lorentz center, The Dutch Techcenter for the Life Sciences
and the Netherlands eScience Center. The principles and themes described in this manuscript represent
the signi ﬁcant voluntary contributions and participation of the authors at, and/or subsequent to, this
workshop and from the wider Force11, BD2K and ELIXIR communities. We also acknowledge and thank
the organizers and backers of the NBDC/DBCLS BioHackathon 2015, where several of the authors made
signiﬁcant revisions to the FAIR Principles.
Author Contributions
M.W. was the primary author of the manuscript, and participated extensively in the drafting and editing
of the FAIR Principles. M.D. was signi ﬁcantly involved in the drafting of the FAIR Principles. B.M.
conceived of the FAIR Data Initiative, contributed extensively to the drafting of the principles, and to this
manuscript text. All other authors are listed alphabetically, and contributed to the manuscript either by
their participation in the initial workshop and/or by editing or commenting on the manuscript text.
Additional Information
Competing ﬁnancial interests: M.A. is the Nature Genetics ’Editor in Chief; S.A.S. is Scientiﬁc Data ’s
Honorary Academic Editor and consultant.
How to cite this article: Wilkinson, M. D. et al. The FAIR Guiding Principles for scienti ﬁc data
management and stewardship. Sci. Data 3:160018 doi: 10.1038/sdata.2016.18 (2016).
This work is licensed under a Creative Commons Attribution 4.0 International License. The
images or other third party material in this article are included in the article ’s Creative
Commons license, unless indicated otherwise in the credit line; if the material is not included under the
Creative Commons license, users will need to obtain permission from the license holder to reproduce the
material. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0
Mark D. Wilkinson 1, Michel Dumontier 2, IJsbrand Jan Aalbersberg 3, Gabrielle Appleton 3,
Myles Axton 4, Arie Baak 5, Niklas Blomberg 6, Jan-Willem Boiten 7,
Luiz Bonino da Silva Santos 8, Philip E. Bourne 9, Jildau Bouwman 10, Anthony J. Brookes 11,
Tim Clark 12, Mercè Crosas 13, Ingrid Dillo 14, Olivier Dumon 3, Scott Edmunds 15,
Chris T. Evelo 16, Richard Finkers 17, Alejandra Gonzalez-Beltran 18, Alasdair J.G. Gray 19,
Paul Groth 3, Carole Goble 20, Jeffrey S. Grethe 21, Jaap Heringa 22, Peter A.C. ’t Hoen 23,
Rob Hooft 24, Tobias Kuhn 25, Ruben Kok 22, Joost Kok 26, Scott J. Lusher 27,
Maryann E. Martone 28, Albert Mons 29, Abel L. Packer 30, Bengt Persson 31,
Philippe Rocca-Serra 18, Marco Roos 32, Rene van Schaik 33, Susanna-Assunta Sansone 18,
Erik Schultes 34, Thierry Sengstag 35, Ted Slater 36, George Strawn 37, Morris A. Swertz 38,
Mark Thompson 32, Johan van der Lei 39, Erik van Mulligen 39, Jan Velterop 40,
Andra Waagmeester 41, Peter Wittenburg 42, Katherine Wolstencroft 43, Jun Zhao 44
& Barend Mons 45,46,47
1Center for Plant Biotechnology and Genomics, Universidad Politécnica de Madrid, Madrid 28223, Spain.
2Stanford University, Stanford 94305-5411, USA. 3Elsevier, Amsterdam 1043 NX, The Netherlands. 4Nature
Genetics, New York 10004-1562, USA. 5Euretos and Phortos Consultants, Rotterdam 2741 CA, The Netherlands.
6ELIXIR, Wellcome Genome Campus, Hinxton CB 10 1 SA, UK. 7Lygature, Eindhoven 5656 AG, The Netherlands.
8Vrije Universiteit Amsterdam, Dutch Techcenter for Life Sciences, Amsterdam 1081 HV, The Netherlands.
9Ofﬁce of the Director, National Institutes of Health, Rockville 20892, USA. 10TNO, Zeist 3700 AJ, The
Netherlands. 11Department of Genetics, University of Leicester, Leicester LE 17 RH, UK. 12Harvard Medical
School, Boston, Massachusetts MA 02115, USA. 13Harvard University, Cambridge, Massachusetts MA 02138,
USA. 14Data Archiving and Networked Services (DANS), The Hague 2593 HW, The Netherlands. 15GigaScience,
Beijing Genomics Institute, Shenzhen 518083, China. 16Department of Bioinformatics, Maastricht University,
Maastricht 6200 MD, The Netherlands. 17Wageningen UR Plant Breeding, Wageningen 6708 PB, The
Netherlands. 18Oxford e-Research Center, University of Oxford, Oxford OX 13 QG, UK. 19Heriot-Watt University,
Edinburgh EH 14 4 AS, UK. 20School of Computer Science, University of Manchester, Manchester M 13 9 PL, UK.
21Center for Research in Biological Systems, School of Medicine, University of California San Diego, La Jolla,
California 92093-0446, USA. 22Dutch Techcenter for the Life Sciences, Utrecht 3501 DE, The Netherlands.
23Department of Human Genetics, Leiden University Medical Center, Dutch Techcenter for the Life Sciences,
Leiden 2300 RC, The Netherlands. 24Dutch TechCenter for Life Sciences and ELIXIR-NL, Utrecht 3501 DE, The
www.nature.com/sdata/
SCIENTIFIC DATA | 3:160018 | DOI: 10.1038/sdata.2016.18 8
Netherlands. 25VU University Amsterdam, Amsterdam 1081 HV, The Netherlands. 26Leiden Center of Data
Science, Leiden University, Leiden 2300 RA, The Netherlands. 27Netherlands eScience Center, Amsterdam 1098
XG, The Netherlands. 28National Center for Microscopy and Imaging Research, UCSD, San Diego 92103, USA.
29Phortos Consultants, San Diego 92011, USA. 30SciELO/FAPESP Program, UNIFESP Foundation, São Paulo
05468-901, Brazil. 31Bioinformatics Infrastructure for Life Sciences (BILS), Science for Life Laboratory, Dept of
Cell and Molecular Biology, Uppsala University, S- 751 24 , Uppsala, Sweden. 32Leiden University Medical Center,
Leiden 2333 ZA, The Netherlands. 33Bayer CropScience, Gent Area 1831, Belgium. 34Leiden Institute for
Advanced Computer Science, Leiden University Medical Center, Leiden 2300 RA, The Netherlands. 35Swiss
Institute of Bioinformatics and University of Basel, Basel 4056, Switzerland. 36Cray, Inc., Seattle 98164, USA.
37Unafﬁliated. 38University Medical Center Groningen (UMCG), University of Groningen, Groningen 9713 GZ, The
Netherlands. 39Erasmus MC, Rotterdam 3015 CE, The Netherlands. 40Independent Open Access and Open
Science Advocate, Guildford GU 13 PW, UK. 41Micelio, Antwerp 2180, Belgium. 42Max Planck Compute and Data
Facility, MPS, Garching 85748, Germany. 43Leiden Institute of Advanced Computer Science, Leiden University,
Leiden 2333 CA, The Netherlands. 44Department of Computer Science, Oxford University, Oxford OX 13 QD, UK.
45Leiden University Medical Center, Leiden and Dutch TechCenter for Life Sciences, Utrecht 2333 ZA, The
Netherlands. 46Netherlands eScience Center, Amsterdam 1098 XG, The Netherlands. 47Erasmus MC, Rotterdam
3015 CE, The Netherlands.
www.nature.com/sdata/
SCIENTIFIC DATA | 3:160018 | DOI: 10.1038/sdata.2016.18 9""" ;
    onto:mentionsConcept onto:Concept_Web_Alliance,
        onto:Creative_Commons,
        onto:Data_Management,
        onto:Dutch_Techcenter,
        onto:Informatics_Assoc,
        onto:Jointly_Designing,
        onto:Lib_Magazine,
        onto:Life_Sciences,
        onto:Lorentz_Workshop .

sources:YouTube-8nbb6CwpPMA_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """# YouTube-8nbb6CwpPMA

## Welcome to the OntoText Webinar

Hello everyone, my name is Jason Stokov, and I want to welcome you all to our latest OntoText webinar. This is our second webinar for January and the first one of the year with our speaker, Atanas Kirakov, the CEO of OntoText. The topic of today's discussion is how RDF levels the advantages of labeled property graphs, focusing on three key benefits: standards, semantics, and interoperability.

### Introducing Atanas Kirakov

Atanas Kirakov is the founder and CEO of OntoText. He holds a master's degree in AI from Sofia University and is a board member of the Linked Data Benchmarking Council. Additionally, he is a partner and part of the board of directors at Sirima Holding Group, one of the largest IT companies in Bulgaria. Atanas is a top expert in graph databases, knowledge graphs, and many surrounding technologies.

### Housekeeping Details

Before we begin, here are a few housekeeping details. This webinar is live and will be recorded, with the recording distributed to all participants possibly by tomorrow. Currently, everyone is muted to minimize background noise and allow Atanas to present without interruptions. However, you can communicate with us using the question box in your GoToWebinar panel. We strongly encourage you to ask questions, as we have a planned Q&A session at the end of the webinar.

Now, without further ado, I would like to hand over the stage to Atanas. Atanas, the floor is yours.

## Presentation by Atanas Kirakov

Thank you for joining us today. Let’s start with a quick introduction. I founded OntoText in the year 2000 during the pioneering years of the semantic web. Since then, we have been part of a community focused on advancing the way we handle content, semantics, and data to create a more connected and automated environment.

### Our Journey and Current Focus""" ;
    onto:mentionsConcept onto:Atanas_Kirakov,
        onto:Atanas_Kirakov_Thank,
        onto:Current_Focus,
        onto:Housekeeping_Details,
        onto:Jason_Stokov,
        onto:Our_Journey_and_Current_Focus,
        onto:Presentation_by_Atanas_Kirakov,
        onto:Sirima_Holding_Group,
        onto:Welcome_to_the_OntoText_Webinar,
        onto:YouTube-8nbb6CwpPMA .

sources:arxiv_200502614v1pdf_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """Piveau: A Large-scale Open Data Management
Platform based on Semantic Web Technologies
Fabian Kirstein1,2   , Kyriakos Stefanidis1 Benjamin Dittwald1, Simon
Dutkowski1, Sebastian Urbanek1,2, and Manfred Hauswirth 1,2,3
1 Fraunhofer FOKUS, Berlin, Germany
2 Weizenbaum Institute for the Networked Society, Berlin, Germany
3 TU Berlin, Open Distributed Systems, Berlin, Germany
{firstname.lastname}@fokus.fraunhofer.de
Abstract. The publication and (re)utilization of Open Data is still fac-
ing multiple barriers on technical, organizational and legal levels. This
includes limitations in interfaces, search capabilities, provision of quality
information and the lack of deﬁnite standards and implementation guide-
lines. Many Semantic Web speciﬁcations and technologies are speciﬁcally
designed to address the publication of data on the web. In addition, many
oﬃcial publication bodies encourage and foster the development of Open
Data standards based on Semantic Web principles. However, no existing
solution for managing Open Data takes full advantage of these possi-
bilities and beneﬁts. In this paper, we present our solution Piveau, a
fully-ﬂedged Open Data management solution, based on Semantic Web
technologies. It harnesses a variety of standards, like RDF, DCAT, DQV,
and SKOS, to overcome the barriers in Open Data publication. The solu-
tion puts a strong focus on assuring data quality and scalability. We give
a detailed description of the underlying, highly scalable, service-oriented
architecture, how we integrated the aforementioned standards, and used
a triplestore as our primary database. We have evaluated our work in a
comprehensive feature comparison to established solutions and through
a practical application in a production environment, the European Data
Portal. Our solution is available as Open Source.
Keywords: Open Data ·DCAT ·Scalability.
1 Introduction
Open Data constitutes a prospering and continuously evolving concept. At the
very core, this includes the publication and re-utilization of datasets. Typical ac-
tors and publishers are public administrations, research institutes, and non-proﬁt
organizations. Common users are data journalists, businesses, and governments.
The established method of distributing Open Data is via a web platform that is
responsible for gathering, storing, and publishing the data. Several software so-
lutions and speciﬁcations exist for implementing such platforms. Especially the
Resource Description Framework (RDF) data model and its associated vocab-
ularies represent a foundation for fostering interoperability and harmonization
arXiv:2005.02614v1  [cs.IR]  6 May 2020
2 F. Kirstein et al.
of diﬀerent data sources. The Data Catalog Vocabulary (DCAT) is applied as a
comprehensive model and standard for describing datasets and data services on
Open Data platforms [1]. However, RDF is only a subset of the Semantic Web
stack and Open Data publishing does not beneﬁt from the stack’s full potential,
which oﬀers more features beyond data modeling. Therefore, we developed a
novel and scalable platform for managing Open Data, where the Semantic Web
stack is a ﬁrst-class citizen. Our work focuses on two central aspects: (1) The
utilization of a variety of Semantic Web standards and technologies for covering
the entire life-cycle of the Open Data publishing process. This covers particu-
larly data models for metadata, quality veriﬁcation, reporting, harmonization,
and machine-readable interfaces. (2) The application of state-of-the-art software
engineering approaches for development and deployment to ensure production-
grade applicability and scalability. Hence, we integrated a tailored microservice-
based architecture and a suitable orchestration pattern to ﬁt the requirements
in an Open Data platform.
It is important to note, that currently our work emphasizes the management of
metadata, as intended by the DCAT speciﬁcation. Hence, throughout the paper
the notion of data is used in terms of metadata.
In Section 2 we describe the overall problem and in Section 3 we discuss related
and existing solutions. Our software architecture and orchestration approach is
described in Section 4. Section 5 gives a detailed overview of the data workﬂow
and the applied Semantic Web standards. We evaluate our work in Section 6
with a feature analysis and an extensive use case. To conclude, we summarize
our work and give an outlook for future developments.
2 Problem Statement
A wide adoption of Open Data by data providers and data users is still facing
many barriers. Beno et al. [7] conducted a comprehensive study of these barriers,
considering legal, organizational, technical, strategic, and usability aspects. Ma-
jor technical issues for users are the limitations in the Application Programming
Interfaces (APIs), diﬃculties in searching and browsing, missing information
about data quality, and language barriers. Generally, low data quality is also a
fundamental issue, especially because (meta)data is not machine-readable or, in
many cases, incomplete. In addition, low responsiveness and bad performance of
the portals have a negative impact on the adoption of Open Data. For publish-
ers, securing the integrity and authenticity, enabling resource-eﬃcient provision,
and clear licensing are highly important issues. The lack of a deﬁnite standard
and technical solutions is listed as a core barrier.
The hypothesis of our work is, that a more sophisticated application of
Semantic Web technologies can lower many barriers in Open Data
publishing and reuse. These technologies intrinsically oﬀer many aspects,
which are required to improve the current support of Open Data. Essentially,
the Semantic Web is about deﬁning a common standard for integrating and har-
nessing data from heterogeneous sources [2]. Thus, it constitutes an excellent
Piveau 3
match for the decentralized and heterogeneous nature of Open Data.
Widespread solutions for implementing Open Data platforms are based on canon-
ical software stacks for web applications with relational and/or document databases.
The most popular example is the Open Source solution Comprehensive Knowl-
edge Archive Network (CKAN) [10], which is based on a ﬂat JSON data schema,
stored in a PostgreSQL database. This impedes a full adoption of Semantic Web
principles. The expressiveness of such a data model is limited and not suited for
a straightforward integration of RDF.
3 Related Work
Making Open Data and Linked Data publicly available and accessible is an ongo-
ing process that involves innovation and standardization eﬀorts in various topics
such as semantic interoperability, data and metadata quality, standardization as
well as toolchain and platform development.
One of the most widely adopted standards for the description of datasets
is DCAT and its extension DCAT Application proﬁle for data portals in Eu-
rope (DCAT-AP) [12]. The latter adds metadata ﬁelds and mandatory prop-
erty ranges, making it suitable for use with Open Data management platforms.
Its adoption by various European countries led to the development of country-
speciﬁc extensions such as the oﬃcial exchange standard for open governmental
data in Germany [17] and Belgium’s extension [24]. Regarding Open Data man-
agement platforms, the most widely known Open Source solution is CKAN [10].
It is considered the de-facto standard for the public sector and is also used by pri-
vate organizations. It does not provide native Linked Data capabilities but only
a mapping between existing data structures and RDF. Another widely adopted
platform is uData [23]. It is a catalog application for collecting data and meta-
data focused on being more contributive and inclusive than other Open Data
platforms by providing additional functionality for data reuse and community
contributions. Other Open Source alternatives include the repository solution
DSpace which dynamically translates [13] relational metadata into native RDF
metadata and oﬀers it via a SPARQL endpoint. WikiData also follows a similar
approach [36]; it uses a custom structure for identiﬁable items, converts them
to native RDF and provides an API endpoint. Another, proprietary, solution is
OpenDataSoft [26], which has limited support for Linked Data via its interop-
erability mode. There are also solutions that oﬀer native Linked Data support
following the W3C recommendation for Linked Data Platforms (LDPs). Apache
Marmotta [38] has native implementation of RDF with a pluggable triplestore
for Linked Data publication. Virtuoso [27] is a highly scalable LDP implemen-
tation that supports a wide array of data access standards and output formats.
Fedora [21] is a native Linked Data repository suited for digital libraries. Recent
research eﬀorts [30] focusses on the notion of dynamic Linked Data where con-
text aware services and applications are able to detect changes in data by means
of publish-subscribe mechanisms using SPARQL.
4 F. Kirstein et al.
A core feature of most big commercial platforms is the Extract, Transform,
Load (ETL) functionality. It refers to the three basic data processing stages of
reading data (extract) from heterogeneous sources, converting it (transform) to
a suitable format, and storing it (load) into a database. Platforms that oﬀer ETL
as a core functionality include IBM InfoSphere [16] with its DataStage module,
Oracle Autonomus Data Warehouse [28] with its Data Integrator module and
SAS Institute’s data warehouse [31]. Moreover, various Open Source solutions
such as Scriptella [35] and Talend Open Studio [32] are based on ETL. The above
data warehouses oﬀer highly scalable ETL functionality but do not support
Linked Data and DCAT. On the other hand, the previously mentioned Linked
Data platforms do not oﬀer any real ETL capabilities. Bridging this gap was the
main objective that led to the development of the Piveau pipeline as a core part
of our architecture. Similar data pipelines can be found as stand-alone services
and applications such as AWS Data Pipeline [5], Data Pipes from OKFN [25],
North Concepts Data Pipeline [22], and Apache Airﬂow [33].
4 A Flexible Architecture for Semantic Web Applications
Semantic Web technologies are mainly supported by speciﬁcations, standards,
libraries, full frameworks, and software. The underlying concept of our architec-
ture is the encapsulation of Semantic Web functionalities to make them reusable
and interoperable, which is considered a classical software engineering principle.
Our Open Data platform introduces a state-of-the-art, tailored architecture to
orchestrate these encapsulations and make them easy to apply in production
environments. It is based on a microservice architecture and a custom pipeline
system, facilitating a ﬂexible and scalable feature composition of Open Data
platforms. This enables the application of Piveau for various use cases and audi-
ences. Furthermore, it enables the re-use of features in other environments and
applications.
4.1 The Piveau Pipeline
The basic requirements of our architecture were the use of microservices, high
scalability, lightweight in application and management, and suitable for large-
scale data processing. Existing workﬂow engines and ETL systems are either
not designed for Linked Data and/or limited solely to extensive data integration
tasks (see Section 3). To lower complexity and maintenance needs, we aimed for
an unifying architecture and data processing concept, which targets speciﬁcally
our needs. Therefore, we designed and implemented the Piveau pipeline (PPL).
The PPL builds upon three principal design choices: (1) All services and fea-
tures expose RESTful interfaces and comply with the microservice style. (2)
The services can be connected and orchestrated in a generic fashion to imple-
ment speciﬁc data processing chains. (3) There is no central instance, which is
responsible for orchestrating the services.
Piveau 5
A PPL orchestration is described by adescriptor, which is a plain JSON docu-
ment, including a list of segments, where each segment describes a step (a service)
in the data processing chain. Every segment includes at least meta-information,
targeting the respective service and deﬁning the consecutive service(s).4 The en-
tire descriptor is passed from service to service as state information. Each service
identiﬁes its segment by a service identiﬁer, executes its deﬁned task and passes
the descriptor to the next service(s). Hence, the descriptor is a compilation and
self-contained description of a data processing chain. Each microservice must
expose an endpoint to receive the descriptor and must be able to parse and ex-
ecute its content. The processed data itself can be embedded directly into the
descriptor or passed via a pointer to a separate data store, e.g. a database, ﬁle
system or other storage. This depends on the requirements and size of data and
can be mixed within the process.
The PPL has been proven to be a ﬁtting middle ground between ETL ap-
proaches and workﬂow engines. On an architectural level, it allows to harvest
data from diverse data providers and orchestrate a multitude of services. Its
production-level implementation in the European Data Portal (EDP) supports
millions of open datasets with tens of thousands updates per day (see Section
6.2).
4.2 Architecture, Stack and Deployment
Fig. 1.Piveau High-Level Architecture
4 The PPL descriptor schema can be found at: https://gitlab.com/
piveau/pipeline/piveau-pipe-model/-/blob/master/src/main/resources/
piveau-pipe.schema.json
6 F. Kirstein et al.
The development of Piveau follows the reactive manifesto, which requires a
system to be responsive, resilient, elastic, and message driven [9]. The platform
is divided into three logical main components, each one responsible for a phase
within the life-cycle of the datasets: Consus, Hub and Metrics. Figure 1 illustrates
the overall architecture and structure.
Consus is responsible for the data acquisition from various sources and data
providers. This includes scheduling, transformation and harmonization. Hub is
the central component to store and register the data. Its persistence layer con-
sists of a Virtuoso triplestore 5 as the principal database, Elasticsearch 6 as the
indexing server and a MongoDB 7 for storing binary ﬁles. Metrics is responsi-
ble for creating and maintaining comprehensive quality information and feeding
them back to the Hub. Two web applications based on Vue.js 8 are available for
browsing the data. The services are written with the reactive JVM framework
Vert.x9 and orchestrated with the PPL within and across the logical components.
Several libraries for common tasks, RDF handling and the PPL orchestration
are re-used in all services.
In order to enable native cloud deployment, we use the Docker10 container tech-
nology. Each service is packaged as a container, supporting easy and scalable
deployment. In addition, Piveau was tested with Kubernetes-based 11 container
management solutions like Rancher12 and OpenShift13. Hence, our architecture
supports a production-grade development scheme and is ready for DevOps prac-
tices.
4.3 Security Architecture
In this section we will describe how Piveau handles authentication, authorization,
and identity management. The multitude of standardized system and network
security aspects that are part of the Piveau architectural design, such as com-
munication encryption, ﬁrewall zones and API design, are beyond the scope of
this paper.
Piveau is comprised of multiple microservices, Open Source software and a set
of distinct web-based user interfaces. In order to support Single Sign-On (SSO)
for all user interfaces and authentication/authorization to all microservices, we
use Keycloak14 as central identity and access management service. Keycloak also
supports federated identities from external providers. Speciﬁcally, in the case of
the EDP, we use ”EU Login” as the sole external identity provider without
5 https://virtuoso.openlinksw.com/
6 https://www.elastic.co/products/elasticsearch
7 https://www.mongodb.com/
8 https://vuejs.org/
9 https://vertx.io/
10 https://www.docker.com/
11 https://kubernetes.io/
12 https://rancher.com/
13 https://www.openshift.com/
14 https://www.keycloak.org/
Piveau 7
allowing any internal users apart from the administrators. Authentication and
authorization on both front-end and back-end services follows the OIDC protocol
[34]. More speciﬁcally, all web-based user interfaces follow the OIDC authoriza-
tion code ﬂow. This means that when a user tries to login to any of Piveau’s
user interfaces, they are redirected to the central Keycloak authentication form
(or the main identity provider’s authentication form) and, upon successful login,
they are redirected back to the requested web page. This provides a uniform user
experience and minimizes the risk of insecure implementation of custom login
forms.
All back-end services also follow OIDC by requiring valid access tokens for
each API call. Those tokens follow the JSON Web Token (JWT) standard. In
contrast to static internal API keys, this design pattern supports arbitrary back-
end services to be open to the public without any change to their authentication
mechanisms. Moreover, since the JWT tokens are self-contained, i.e. they con-
tain all the required information for user authentication and resource authoriza-
tion, the back-end services can perform the required checks without the need of
communication with a database or Keycloak. Not requiring round-trips greatly
enhances the performance of the whole platform.
The ﬁne-grained authorization follows the User-Managed Access (UMA) spec-
iﬁcation [18], where resource servers (back-end services) and a UMA-enabled
authorization server (Keycloak) can provide uniform management features to
user-owned resources such as catalogs and datasets.
5 Semantic Data Workﬂow
In the following, a typical data ﬂow in our Open Data platform is described to
illustrate our solution in detail. This covers the process of acquiring the data
from the original providers, evaluating the quality of that data, and presenting
and managing the data (see Figure 2). We focus on the used Semantic Web
technologies and speciﬁcations. The presented order reﬂects roughly the order
of execution. But since many processes run asynchronously, the order can vary
depending on their execution time.
5.1 Data Acquisition
The main entry point for any data workﬂow and orchestration is the scheduler.
Each data workﬂow, deﬁned as a PPL descriptor (see Section 4.1), is assigned
a list of triggers. A trigger may deﬁne a periodical execution (hourly, daily,
weekly, bi-weekly, yearly, etc.), number of execution times, a list of speciﬁc date
and times to execute, or an immediate execution. Each trigger is able to pass its
own process conﬁguration in order to individualize the workﬂow depending on
the execution time. Upon execution, the scheduler passes the descriptor to the
ﬁrst service in line, typically an importer.
An importer retrieves the metadata from the source portal(s). We have imple-
mented a range of importers to support a variety of interfaces and data formats,
8 F. Kirstein et al.
Fig. 2.Semantic Data Workﬂow
e.g. CKAN-API, OAI-PMH, uData, RDF, and SPARQL. The importer is re-
sponsible for extracting records of metadata from either an API or a dump ﬁle
and for sending it to the next processing step. This covers the generation of
a complete list of identiﬁers of all datasets, which will be required for a ﬁnal
synchronization, including the deletion of datasets, which are not present in the
source portal anymore.
The principal data format of Piveau is RDF, therefore non-RDF or not supported
RDF dialects sources require a transformation. A transformer generates RDF
from such source data, by applying light-weight transformation scripts written
in JavaScript. The ﬁnal output is always DCAT-compliant RDF. The scripts can
be managed externally (e.g. in Git) to ensure maintainability.
Finally, our exporter sends the RDF data to the Hub component. Non-existing
datasets are deleted by the exporter based on the identiﬁer list that is acquired
in the importing step.
5.2 Processing and Storing
The central service for dataset management is the registry. It acts as a middle-
ware and abstraction layer to interact with the triplestore. It oﬀers a RESTful
interface, supporting the major RDF serializations (Turtle, JSON-LD, N-Triples,
RDF/XML, Notation3). Its resources reﬂect the main DCAT entities: catalog,
Piveau 9
dataset, and distribution. The main task is to pre-process and harmonize the
data received from the exporter. This includes the application of consistent and
meaningful URI schemata [6], the generation of unique IDs, and the mapping
to linked, existing entities. It ensures the integrity and traceability of the data
in the triplestore. The indexing service is responsible for managing the high-
performance search index. It receives the processed RDF data from the registry
and ﬂattens it into a plain JSON representation, which is suitable for indexing.
Firstly, this is done by extracting relevant literals from the data, e.g. from proper-
ties like title and description. Secondly, linked resources are resolved and proper
literals are extracted from the result (for instance by looking for rdfs:label). The
service supports the use of existing and well-maintained vocabularies and on-
tologies for that purpose. Piveau ships with a selection of vocabularies, e.g. for
human languages, licenses, and geolocations. The result of the search service
constitutes one of the main access points to the data, because it is much more
human-readable than native RDF.
The translation service manages the machine translation of literals into mul-
tiple languages. It represents a middleware to third-party translations services,
bundling strings from multiple datasets to an integrated request. After com-
pletion the service stores the translation by applying the native multi-language
features of RDF. As soon as a dataset is retrieved, the existing original languages
are identiﬁed and added to the text information using a language tag inside the
dataset. This labeling is based on ISO 639-1 language codes. In addition, meta-
data about the translation status are stored in the dataset, indicating when a
translation was started and when it was completed. Translated text information
are labeled with an extended language tag to diﬀerentiate them from the origi-
nal text. It follows the schema en-t-de-t0-abc [11], where the target language is
named ﬁrst, followed by a t and the original language.
Finally, the data is accessible via multiple means. The triplestore exposes a
SPARQL endpoint, which oﬀers raw und direct access to the data. A RESTful
API allows the access to the RDF serializations, provided by the registry and to
the indexed serializations, provided by the search service. A web user interface
oﬀers access to end users and interacts directly with the RESTful API.
5.3 Quality Evaluation
In parallel with the main data processing steps, the data is processed by dedi-
cated services to assess its quality. Semantic Web technologies oﬀer mature tools
and standards to conduct this task.
The validator provides a formal validation of each dataset. We apply the W3C
Shapes Constraint Language (SHACL) [20], where a pre-deﬁned set of rules is
tested against a dataset. Currently the DCAT-AP SHACL rules [15] are included.
The validation results include detailed information about issues and violations.
This result covers the exact paths and reasons for the identiﬁed deﬁcits. The
applied rules can also be extended or replaced. In addition, the URL checker
performs accessibility tests on each linked distribution (the actual data) and as-
sesses its availability via HTTP status codes.
10 F. Kirstein et al.
The DQV annotator [4] provides a qualitative assessment for each dataset.
It is based on a custom metrics scheme, which is inspired by the FAIR princi-
ples [39]. The ﬁndability dimension refers to completeness of the metadata, e.g.
whether keywords, geo data or time information are provided. Accessibility refers
to the results from the URL checker. Interoperability is assessed by evaluating
the format and type of data, which is referenced in a dataset (distribution). For
instance, if the data is in a machine-readable and/or non-proprietary format.
Reusability is mostly conﬁrmed by checking the availability of licensing informa-
tion. Beyond this FAIR evaluation, the similarity of a dataset to other datasets
is calculated based on locality-sensitive hashing (LSH) algorithm.
The results of the validation and annotator services are summarized in a quality
report and attached as RDF to the concerned dataset in the triplestore. This
report uses a custom quality vocabulary, which applies the W3C Data Quality
Vocabulary (DQV) and reﬂects our metric scheme. In addition, an aggregated
report is attached to the respective catalog.
The reporter oﬀers a variety of human-readable versions of the quality reports.
It collects all data from the triplestore and renders visually appealing reports
of the information. It supports PDF, XLS or ODS. In addition, a comprehen-
sive web front-end is available, and is integrated into the front-end of the Hub
component.
6 Evaluation
We have evaluated our work according to three quantitative and qualitative
aspects. In Section 6.1 we compare Piveau with two well-known Open Data
solutions. In Section 6.2 we describe a real-world application based on Piveau.
Finally, in Section 6.3 we present an analysis of the impact of Semantic Web
technologies on the perceived barriers of Open Data.
6.1 Feature Comparison with Open Data Solutions
No deﬁnite metric exists to speciﬁcally assess the technical performance of Open
Data technologies and infrastructures. However, a lot of work and research was
conducted in the ﬁeld of requirements and evaluation modeling for Open Data.
An extensive review covering a broad variety of dimensions (economical, organi-
zational, ergonomic, etc.) is presented by Charalabidis et al. [3] This includes an
overview of ”Functional Requirements of an Open Data Infrastructure”, which
acts as the main basis for our feature matrix [3]. It is supplemented by indica-
tors from the outcome of ”Adapting IS [Information Systems] Success Model on
Open Data Evaluation” [3]. Furthermore, we translated the W3C recommenda-
tion for best practices for publishing data on the web into additional indicators
[37]. Finally, the matrix is complemented by custom indicators to reﬂect our
experiences in designing and developing Open Data infrastructures. In the selec-
tion process we only focused on indicators, which were applicable to measurable
technical aspects that reﬂect the overall objective of managing metadata. More
Piveau 11
personal indicators, like ”The web pages look attractive”, were not considered.
Still, this approach led to a large number of indicators ( >50), which we seman-
tically combined to generate a compact and meaningful feature matrix. 15
We compared Piveau with the popular Open Data solutions CKAN and uData
(see Section 3). The selection criteria were: (1) Must be freely available as Open
Source software; (2) Must not be a cloud- or hosting-only solution; (3) Has a high
rate of adoption and (4) Primarily targets public sector data. Table 1 shows the
ﬁnal feature matrix and the result of the evaluation. Each measure was rated
with the following scale: 0 - not supported, 1 - partially supported, 2 - fully
supported. An explanation is given for each rating, where required.
The overall result indicates that our solution can match with existing and
established solutions and even reaches the highest score. Piveau oﬀers strong
features regarding searching and ﬁnding datasets and data provision. The com-
prehensive metadata is a great foundation for analyses and visualizations. Our
features for quality assurance are unrivaled and we support the most scalable
architecture. Yet, uData oﬀers unique features for interaction and CKAN is very
mature and industry-proven.
6.2 The European Data Portal
The EDP16 is a central portal, publishing all metadata of Open Data provided
by public authorities of the European Union (EU). It gathers the data from
national Open Data portals and geographic information systems. It was initially
launched in November 2015 by the European Commission (EC). Its design and
development was driven by the DCAT-AP speciﬁcation.
The EDP was one of the ﬁrst implementations of the DCAT-AP speciﬁca-
tion. In order to comply with established Open Data publishing concepts, the
ﬁrst version was based on an extended CKAN with an additional layer for trans-
forming and replicating all metadata into RDF. This setup required additional
mechanisms to transform data and, thus, proved to be too complex and limited
for the growing amounts of Open Data in Europe. [19] We successfully improved
this ﬁrst version with our solution Piveau. This successfully enrolled our solution
in a large-scale production environment. Our translation middleware integrates
the eTranslation Service of the EU Commission [29], enabling the provision of
metadata in 25 European languages. As of December 2019 the EDP oﬀers ap-
proximately one million DCAT datasets, in total consisting of more than 170
million RDF triples, fetched from more than 80 data providers. Open Data is
considered to be a key building block of Europe’s data economy [14], indicating
the practical relevance of our work.
15 The exact provenance and creation process of the feature matrix is available as
supplementary material: https://zenodo.org/record/3571171
16 https://www.europeandataportal.eu
12 F. Kirstein et al.
Piveau CKAN uData
Searching and Finding Data
Support for data federation 2 Native support through
SPARQL
1 Indirect through
harvesting
1 Indirect through harvest-
ing
Integration of controlled vocabularies2 Support for structured
controlled vocabulary
1 Support for simple
controlled vocabulary
1 Support for simple con-
trolled vocabulary
Filtering, sorting, structuring,
browsing and ordering search results
by diverse dimensions
2 Application of search
engine
2 Application of search
engine
2 Application of search en-
gine
Offer a strong and interoperable API2 DCAT compliant REST 2 DCAT compliant REST 2 DCAT compliant REST
Support multiple languages 2 On interface and dataset
level
1 Only on interface level 2 On interface and dataset
level
Linked Data interface 2 SPARQL endpoint 0 0
Geo-Search 2 Available 2 Available 2 Available
Data Provision and Processing
Data Upload 1 Binary data upload 2 Binary and structured
data upload
1 Binary data upload
Data Enrichment and Cleansing 0 0 0
Support for linking and referring
other data
2 Any number of links
possible
1 Restrictive schema 1 Restrictive schema
Analysis and Visualization
Provide comprehensive metadata 2 Complete and extensible
schema
1 Restricted schema 1 Restricted schema
Offer tools for analyses 0 1 Preview of tabular data 0
Visualizing data on maps 1 Visualization of geo
metadata
1 Visualization of geo
metadata
1 Visualization of geo meta-
data
Detailed reuse information 0 0 1 Indicates purpose and
user
Quality Assurance
Information about data quality 2 Comprehensive quality
evaluation
0 1 Simple quality evaluation
Provide quality dimensions to
compare datasets and its evolution
2 Comprehensive quality
evaluation
0 0
Interaction
Support interaction and
communication between various
stakeholders
0 0 2 Discussion platform
Enrich data 0 0 1 Additional community re-
sources
Support revisions and version history0 1 Metadata revision 0
Track reuse 0 0 2 Linked reuse in dataset
Performance and Architecture
Maturity 1 Application in a few
portals
2 Application in many
portals
1 Application in a few por-
tals
Personalization and Custom Themes 1 Replaceable themes 2 Use of theme API 1 Replaceable themes
Scalable Architecture 2 Microservice architecture 1 Monolithic architecture 1 Monolithic architecture
Score 28 21 24
Table 1.Feature Comparison
Piveau 13
6.3 Impact of Semantic Web Technologies
The initially required development eﬀort was higher and partly more challenging
than with more traditional approaches. Some artifacts of the Semantic Web have
not yet reached the required production readiness or caught up with latest pro-
gresses in software development. This increased integration eﬀort and required
some interim solutions for providing a production system. For instance, integrat-
ing synchronous third-party libraries into our asynchronous programming model.
Particularly challenging was the adoption of a triplestore as primary database.
The access is implemented on a very low level via SPARQL, since a mature
object-relational mapping (ORM) tool does not exist. Most of the integrity and
relationship management of the data is handled on application level and needed
to be implemented there, since the triplestore, unlike relational databases, cannot
handle constraints directly. In addition, the SPARQL endpoint should be openly
available. This currently prevents the management of closed or draft data and
will require a more elaborated approach. To the best of our knowledge no (free)
production triplestore is available, supporting that kind of access control on the
SPARQL endpoint. Furthermore, in the Open Data domain there is no suitable
and mature method to present RDF in a user interface. Hence, the transforma-
tion and processing of RDF is still required before ﬁnal presentation. Usually,
this presentation is domain-depended and builds on custom implementations.
We solved this by applying our search service for both, strong search capabili-
ties and immediate presentation of the data in a user front-end.
However, the overall beneﬁts outweigh the initial barriers and eﬀorts. With our
native application of the Semantic Web data model and its deﬁnite standards
via a triplestore as principal data layer, we are much more able to harness the
full potential of many Open Data speciﬁcations. This particularly concerns the
required implementation of DCAT-AP. The direct reuse and linking to existing
vocabularies or other resources enable a more expressive and explicit description
of the data, e.g. for license, policy, and provenance information. In addition,
this approach increases the machine-readability. The good supply of tools for
working with RDF simpliﬁes the integration into third-party applications and
creates new possibilities for browsing, processing, and understanding the data.
Especially, the availability of tools for reasoning can support the creation of new
insights and derived data. The native capabilities of RDF to handle multiple
languages support the cross-national aspect of Open Data. The application of
SHACL in connection with DQV allowed us to generate and provide comprehen-
sive quality information in a very eﬀective fashion. In general, the strong liaison
of the Semantic Web technologies facilitates a seamless integration of the data
processing pipe.
7 Conclusions and Outlook
In this paper we have presented our scalable Open Data management platform
Piveau. It provides functions for Open Data publication, quality assurance, and
reuse, typically conducted by public administrations, research institutes and
14 F. Kirstein et al.
journalists. We applied a wide range of Semantic Web technologies and princi-
ples in our solution to overcome barriers and to address functional requirements
of this domain. Although the Open Data community has always leveraged spec-
iﬁcations of the Semantic Web, our work takes a previously untaken step by
designing our platform around Semantic Web technologies from scratch. This
allows for a much more eﬃcient and immediate application of existing Open
Data speciﬁcations. Hence, Piveau closes a gap between formal speciﬁcations
and their utilization in production. We combined this with a new scalable ar-
chitecture and an eﬃcient development lice-cycle approach. Our orchestration
approach enables a sustainable and ﬂexible creation of Open Data platforms.
Furthermore, it fosters the reuse of individual aspects of Piveau beyond the
scope of Open Data. We have shown that our work can compete with exist-
ing Open Data solutions and exceed their features in several aspects. We have
improved the generation and provision of quality information, enhanced the ex-
pressiveness of the metadata model and the support for multilingualism. As the
core technology of the European Data Portal, Piveau promotes the Semantic
Web as a highly relevant concept for Europe’s data economy and has proven to
be ready for production and reached a high degree of maturity. Finally, our work
is a relevant contribution to the 5-star deployment scheme of Open Data, which
supports the concept of Linked Open Data [8]. The source code of Piveau can
be found on GitLab. 17
In the next steps, Piveau will be extended with additional features. This includes
support for user interaction, data enrichment, and data analysis. The support
for further Semantic Web features is also planned, e.g. compliance with the
LDP speciﬁcations and the extension beyond metadata to manage actual data
as RDF. Open research questions are the implementation of revision and access
control on triplestore level, which cannot be satisﬁed yet on production-grade.
In general, we aim to increase the overall readiness, broaden the target group
beyond the Open Data community, and strengthen the meaning of Semantic
Web technologies as core elements of data ecosystems.
Acknowledgments
This work has been partially supported by the Federal Ministry of Education and
Research of Germany (BMBF) under grant no. 16DII111 (”Deutsches Internet-
Institut”) and by the EU Horizon 2020 project ”Reﬂow” under grant agreement
no. 820937. The implementation and provision of the European Data Portal is
funded by the European Commission under contracts DG CONNECT SMART
2014/1072 and SMART 2017/1123.
17 https://gitlab.com/piveau
Piveau 15
References
1. Data Catalog Vocabulary (DCAT), https://www.w3.org/TR/vocab-dcat/
2. W3C Semantic Web Activity Homepage. https://www.w3.org/2001/sw/
3. The World of Open Data: Concepts, Methods, Tools and Experiences. Springer
Science+Business Media, New York, NY (2018)
4. Albertoni, R., Isaac, A.: Data on the web best practices: Data quality vocabulary.
https://www.w3.org/TR/vocab-dqv/, (Accessed 3.12.2019)
5. Amazon Web Services Inc.: Aws data pipeline. https://aws.amazon.com/
datapipeline/, (Accessed 3.12.2019)
6. Archer, P., Goedertier, S., Loutas, N.: D7.1.3 - Study on persistent URIs, with
identiﬁcation of best practices and recommendations on the topic for the MSs
and the EC (Dec 2012), https://joinup.ec.europa.eu/sites/default/files/
document/2013-02/D7.1.3%20-%20Study%20on%20persistent%20URIs.pdf
7. Beno, M., Figl, K., Umbrich, J., Polleres, A.: Perception of Key Barriers in Using
and Publishing Open Data. JeDEM - eJournal of eDemocracy and Open Govern-
ment 9(2), 134–165 (Dec 2017). https://doi.org/10.29379/jedem.v9i2.465
8. Berners-Lee, T.: Linked Data, https://www.w3.org/DesignIssues/LinkedData.
html, (Accessed: 11.03.2019)
9. Bonr, J., Farley, D., Kuhn, R., Thompson, M.: The ractive manifesto. https:
//www.reactivemanifesto.org/, (Accessed 5.12.2019)
10. CKAN Association: CKAN, https://ckan.org/
11. Davis, M., Phillips, A., Umaoka, Y., Falk, C.: Bcp 47 extension t - transformed
content. https://tools.ietf.org/html/rfc6497, (Accessed 03.12.2019)
12. Dragan, A.: DCAT Application Proﬁle for data portals in Europe (Nov 2018),
https://joinup.ec.europa.eu/sites/default/files/distribution/access_
url/2018-11/014bde52-eb3c-4060-8c3c-fcd0dfc07a8a/DCAT_AP_1.2.pdf
13. DuraSpace Wiki: Linked (Open) Data, https://wiki.duraspace.org/display/
DSDOC6x/Linked+%28Open%29+Data, (Accessed: 11.03.2019)
14. European Commision: Open data — Digital Single Market, https://ec.europa.
eu/digital-single-market/en/open-data , (Accessed: 11.03.2019)
15. European Commission: DCAT-AP 1.2.1. https://joinup.ec.europa.eu/
solution/dcat-application-profile-data-portals-europe/distribution/
dcat-ap-121-shacl , (Accessed 3.12.2019)
16. IBM: Ibm infosphere datastage. https://www.ibm.com/products/
infosphere-datastage, (Accessed 3.12.2019)
17. ]init[ AG und SID Sachsen: DCAT-AP.de Speziﬁkation, https://www.dcat-ap.
de/def/dcatde/1.0.1/spec/specification.pdf, (Accessed: 11.03.2019)
18. Kantara Initiative: Federated authorization for user-managed ac-
cess (uma) 2.0. https://docs.kantarainitiative.org/uma/wg/
oauth-uma-federated-authz-2.0-09.html , (Accessed 3.12.2019)
19. Kirstein, F., Dittwald, B., Dutkowski, S., Glikman, Y., Schimmler, S., Hauswirth,
M.: Linked data in the european data portal: A comprehensive platform for apply-
ing dcat-ap. In: International Conference on Electronic Government. pp. 192–204
(2019), https://academic.microsoft.com/paper/2967218146
20. Knublauch, H., Kontokostas, D.: Shapes constraint language (shacl). https://
www.w3.org/TR/shacl/, (Accessed 3.12.2019)
21. LYRASIS: Fedora - the ﬂexible, modular, open source repository platform. https:
//duraspace.org/fedora/, (Accessed 22.11.2019)
16 F. Kirstein et al.
22. North Concepts Inc.: Data pipeline. https://northconcepts.com/, (Accessed
3.12.2019)
23. Open Data Team: Customizable and skinnable social platform dedicated to
(open)data., https://github.com/opendatateam/udata, (Accessed: 11.03.2019)
24. Open Knowledge BE: Dcat-be. linking data portals across belgium. http://dcat.
be/, (Accessed 22.11.2019)
25. Open Knowledge Foundation Labs: Data pipes. https://datapipes.okfnlabs.
org/, (Accessed 3.12.2019)
26. OpenDataSoft: Open Data Solution, https://www.opendatasoft.com/
solutions/open-data/, (Accessed: 11.03.2019)
27. OpenLink Software: About OpenLink Virtuoso, https://virtuoso.openlinksw.
com/, (Accessed: 11.03.2019)
28. Oracle: Oracle autonomous data warehouse. https://www.oracle.com/de/
database/data-warehouse.html, (Accessed 3.12.2019)
29. Publications Oﬃce of the EU: Authority tables, https://publications.europa.
eu/en/web/eu-vocabularies/authority-tables, (Accessed: 11.03.2019)
30. Roﬃa, L., Azzoni, P., Aguzzi, C., Viola, F., Antoniazzi, F., Cinotti, T.: Dynamic
linked data: A sparql event processing architecture. Future Internet 10, 36 (04
2018). https://doi.org/10.3390/ﬁ10040036
31. SAS Institue: Sas. https://www.sas.com/, (Accessed 3.12.2019)
32. Talend: Talend open studio. https://www.talend.com/products/
talend-open-studio/, (Accessed 3.12.2019)
33. The Apache Software Foundation: Apache airﬂow. https://airflow.apache.
org/, (Accessed 3.12.2019)
34. The OpenID Foundation: Openid connect core 1.0 incorporating errata
set 1. https://openid.net/specs/openid-connect-core-1_0.html , (Accessed
3.12.2019)
35. The Scriptella Project Team: Scriptella etl project. https://scriptella.org/,
(Accessed 3.12.2019)
36. Vrandei, D., Krtzsch, M.: Wikidata: A Free Collaborative Knowledgebase. Com-
mun. ACM 57(10), 78–85 (Sep 2014). https://doi.org/10.1145/2629489
37. W3C: Data on the web best practices. https://www.w3.org/TR/dwbp/, (Accessed
02.12.2019)
38. W3C Wiki: LDP Implementations, https://www.w3.org/wiki/LDP_
Implementations, (Accessed: 11.03.2019)
39. Wilkinson, M., Dumontier, M., Aalbersberg, et al., I.: The fair guiding prin-
ciples for scientiﬁc data management and stewardship. Sci Data 3 (2016).
https://doi.org/10.1038/sdata.2016.18""" ;
    onto:mentionsConcept onto:Electronic_Government,
        onto:European_Data_Portal,
        onto:Feature_Comparison,
        onto:Interaction_Support,
        onto:Open_Data,
        onto:Open_Data_Solution,
        onto:Sci_Data,
        onto:Semantic_Web_Activity_Homepage,
        onto:Semantic_Web_Technologies_Fabian,
        onto:Weizenbaum_Institute .

sources:node_12633_printable_pdfpdf_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """Data Act explained
A comprehensive overview of the Data Act, including its objectives and how it works in practice.
Why the Data Act ?
The Data Act (https://eur-lex.europa.eu/eli/reg/2023/2854/oj) is a law designed to enhance the EU’s data economy and foster a
competitive data market by making data (in particular industrial data) more accessible and usable, encouraging data-driven
innovation and increasing data availability. To achieve this, the Data Act ensures fairness in the allocation of the value of data
amongst the actors in the data economy. It clariﬁes who can use what data and under which conditions. For more in-depth
information, please examine the Data Act FAQs
(https://digital-strategy.ec.europa.eu/en/news/commission-publishes-frequently-asked-questions-about-data-act).”
In recent years, there has been a rapid growth in the availability of products connected to the internet (‘connected products’) on
the European market. These products, which together compose a network known as the Internet-of-things (IoT), signiﬁcantly
increase the volume of data available for reuse in the EU. This represents a huge potential for innovation and competitiveness in
the EU.
The Data Act gives users of connected products (businesses or individuals that own, lease or rent such a product) greater
control over the data they generate, while maintaining incentives for those who invest in data technologies. In addition, it lays
down general conditions for situations where a business has a legal obligation to share data with another business.
The Data Act also includes measures to increase fairness and competition in the European cloud market as well as to protect
companies from unfair contractual terms related to data sharing imposed by stronger players. It also establishes a mechanism
through which public sector bodies can request data from a business where there is an exceptional need, for example in public
emergency situations, and provides clear rules on how such requests should be made. In addition, it introduces safeguards to
avoid that government bodies from third countries can access non-personal data where this would go against EU or national law.
Finally, the Data Act deﬁnes essential requirements regarding interoperability to ensure that data can ﬂow seamlessly between
sectors and Member States, facilitated by Common European Data Spaces
(https://digital-strategy.ec.europa.eu/en/policies/data-spaces), as well as between data processing services providers. 
The Data Act was published in the Oﬃcial Journal of the EU (https://eur-lex.europa.eu/eli/reg/2023/2854/oj) on 22 December
2023 and it will become applicable on 12 September 2025.
The Data Act complements the Data Governance Act
(https://digital-strategy.ec.europa.eu/en/policies/data-governance-act-explained), the ﬁrst deliverable under the European
strategy for data (https://europa.eu/!7jbCBV). The Data Governance Act became applicable in September 2023. While the Data
Governance Act increases trust in voluntary data-sharing mechanisms, the Data Act provides legal clarity regarding the access
to and use of data.
Together with other policy measures and funding opportunities, these two regulations will contribute to the establishment of an
EU single market for data, making Europe a leader in the data economy by harnessing the potential of the ever-increasing
amounts of data, in particular industrial data, for the beneﬁt of the European economy and society.""" ;
    onto:mentionsConcept onto:Common_European_Data_Spaces,
        onto:Data_Act,
        onto:Data_Governance_Act,
        onto:Member_States .

onto:Keeps_Three_Key a onto:DomainConcept ;
    skos:prefLabel "Keeps Three Key" .

onto:Life_Sciences a onto:DomainConcept ;
    skos:prefLabel "Life Sciences" .

onto:Managed_Services a onto:DomainConcept ;
    skos:prefLabel "Managed Services" .

onto:Member_State a onto:DomainConcept ;
    skos:prefLabel "Member State" .

onto:Metadata_Studio a onto:DomainConcept ;
    skos:prefLabel "Metadata Studio" .

onto:Public_Sector a onto:DomainConcept ;
    skos:prefLabel "Public Sector" .

onto:Semantic_Content_Hub a onto:DomainConcept ;
    skos:prefLabel "Semantic Content Hub" .

onto:SynthMedic_Utilizing_large_language_models_for_synthetic_discharge_summary_generation_correction_and_validationhttpswwwontotextcomknowledgehubpublicationsusing-llm-for-synthetic-discharge-summary-generation-correction-validation a onto:DomainConcept ;
    skos:prefLabel "[SynthMedic: Utilizing large language models for synthetic discharge summary generation, correction and validation](https://www.ontotext.com/knowledgehub/publications/using-llm-for-synthetic-discharge-summary-generation-correction-validation/)" .

sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """Shaping Europe’s digital future
BROCHUREPublication 23 September 2019
Cloud and Edge Computing: adifferent way of using IT —Brochure
Find out more about cloud and edge computing and what the EU is doing in this area.
Page contents
 
A future-proof model for IT(#Future)
Unlocking the cloud(#Unlocking)
The European Alliance for Industrial Data, Edge and Cloud(#Alliance)
Investing in cloud(#Investing)
Building an EU marketplace for cloud services(#Market)
The cloud rulebook(#Rule)
Green cloud solutions(#Green)
Cloud computing is essential to deploying technologies such as artificial intelligence, the Internet of
Things, blockchain and data analytics.
The European Commission’s activities on cloud fall into 2 categories:
1. investing funds in cutting-edge projects related to cloud and edge computing;
2. developing policies and rules that protect cloud users, make cloud services safer, ensure fair
competition and create the optimal framework conditions for a thriving European cloud industry.
A future-proof model for IT
Cloud technologies offer a model of on-demand data storage and processing, both in centralised data
centres and in distributed connected devices close to the user (at the 'edge' of the network). As cloud
technologies are faster, cheaper and more flexible than conventional computing methods, many of our
everyday services are based on the cloud, such as web-based email, entertainment systems, and public
services including health and transportation
Whereas conventional cloud computing takes place in centralised data centres, edge computing data
is processed in connected objects closer to the users. This allows for much faster operations and gives
users more control over their data.
Large economic benefits come from the widespread use of cloud and edge solutions by EU businesses
and public organisations thanks to the significant reduction of IT costs. Cloud and edge computing
unlocks access to future and emerging technologies, such as artificial intelligence, the Internet of
Things and blockchain. It plays a key role in fostering a competitive and innovative European economy
in the digital age.
The cloud provides:
computing capacities on which all types of digital services can run, for all sectors of the economy;
on-demand computing and data storage resources, without having to invest in hardware;
easy and affordable access to scalable and powerful computing facilities for start-ups and SMEs.
Today, only 1 in 4 businesses and 1 in 5 SMEs are using cloud computing for their daily operations in
Europe. A significant increase in cloud and edge deployment will provide European businesses and
public organisation the key data processing technology to support their digital transformation and their
adoption of more advanced digital services like big data analytics and artificial intelligence. It will
subsequently strengthen the European economy’s competitiveness and its innovation potential.
Unlocking the cloud is unlocking data forEurope
Cloud technologies are a necessary tool to manage the huge flow and exchange of data generated by
our increasingly digital economy. For a flourishing economy, data should be able to move freely from
server to server across borders, organisations and individuals within the EU, in a trusted and secure
way.
For this to happen, the Commission’s cloud policies include:
building innovative ecosystems that are conducive to data sharing across businesses and public
organisations;
investing in new forms of cloud and edge computing to make Europe a frontrunner in ground-
breaking cloud technologies such as edge computing, swarm computing and mini-clouds;
fostering free flow of data to ensure that data can be stored in any EU Member State;
avoiding vendor lock-in to ensure that cloud users can easily move their data and applications
from one provider to another;
raising the standards for cloud services on the European market in terms of security,
environmental performance, fairness and competitiveness.
The next sections of this brochure describe how the European Commission aims to achieve these
objectives through policy actions and investments.
The Free Flow of Non-Personal Data Regulation
The Free Flow of non-personal Data Regulation, together with the General Data Protection Regulation
(GDPR), established the unrestricted movement of all data across Europe. All existing unjustified
data localisation restrictions must be removed, while competent authorities in each Member State
continue to have the right to access data stored throughout the EU. In order to avoid vendor lock-in,
the Regulation also introduced industry codes of conduct for data portability. Thanks to this, companies
are now able to freely move data around from provider to provider.
The combined application of the free flow of non-personal data regulation and the GDPR ensures that
both non-personal data and personal data can freely move around through the Union, as long as it is
adequately protected. The Commission has published informative guidance on the issue of mixed
datasets, i.e. datasets containing both personal and non-personal data.""" ;
    onto:mentionsConcept onto:Brochure_Find,
        onto:Data_Regulation,
        onto:Edge_Computing,
        onto:European_Commission,
        onto:Free_Flow,
        onto:General_Data_Protection_Regulation,
        onto:Industrial_Data,
        onto:Member_State,
        onto:Shaping_Europe .

sources:Cloud_switching_under_the_EU_Data_Actpdf_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """12 Sep 20257 minute read
Cloud switching under the EU Data
Act
Action planning and contract drafting in light of
interoperability and provider changes
A central component of the European data strategy is Regulation (EU)
2023/2854 of the European Parliament and of the Council of 13
December 2023 (hereinafter referred to as the ‘Data Act’), which
entered into force on 11 January 2024. Of the eleven chapters of the
Data Act, the requirements for ‘data sharing’ (in particular Chapters II
to IV of the Data Act) have attracted the most attention so far (click
here for our article).
In contrast, the topic of cloud switching and interoperability (in
particular Chapter VI of the Data Act) has received relatively little
attention to date, despite the sometimes far-reaching requirements.
In view of the immediate applicability of the Data Act throughout the
EU from 12 September 2025, this is likely to change. Companies are
therefore well advised to consider the implications for their business
models and contract design.
Authors: Christopher Eduard Bösch, LL.M.  Dr. Till Contzen

Why were the cloud switching
provisions introduced?
With the provisions on cloud switching (Chapter VI – Articles 23-31 of
the Data Act), the EU plans to promote competition and innovation
and prevent so-called ‘lock-in eﬀects’ by facilitating the switch
between ‘data processing services’ and reducing costs. To this end,
mandatory requirements for removing barriers to switching data
processing services are being introduced.
Print     

Reach out
 
Cross-jurisdictional Data
protection, cybersecurity and
AI overview - third edition
In today's digital economy, Data is king.
Yet, harnessing its power requires
navigating a complex and evolving legal
landscape. This report provides a…
Analysis5 minute read
Digital Law: Intangibles, Data
& Technology
Digitalization and technology do not only
foster today's growth and jobs, but are
also essential for tomorrow’s innovation
and competitiveness.
Service
Deloitte Survey: Scepticism
towards EU AI Act
The EU AI Act has oﬃcially been in force
since the beginning of August and must
now be implemented in the EU member
states. But how ready are German…
Research
Data & Data Security
Data and data protection law encompass
comprehensive advisory and
representation services in all matters
related to the protection, processing, an…
Service""" ;
    onto:mentionsConcept onto:Christopher_Eduard,
        onto:Data_Act,
        onto:Data_Act_Action,
        onto:Data_Security_Data,
        onto:Digital_Law,
        onto:European_Parliament,
        onto:Research_Data,
        onto:Service_Deloitte_Survey,
        onto:Technology_Digitalization,
        onto:Till_Contzen_Why .

sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """**Set 1 out of 3: Why, How, and Differences (Setting the Ground)**

Collection Name: **Why Linked Data Infrastructure and Wistor app in the age of EU Data Act?**

## Intro

Set 1 focuses on the crucial link between the EU Data Act mandate and the necessity of shifting from traditional cloud management (like AWS/Azure/GCP) to a **native Linked Data platform** like Wistor.

**LinkedIn Post Draft (Approx. 350 words)**

**Hook (Using Template: Contrarian Approach):** **Stop asking how to store more data on AWS/Azure. Start asking: Is my data *legally* accessible and *semantically* structured?**

The **EU Data Act**, fully applicable on **September 12, 2025**, marks a major shift in Europe's data landscape. It changes the status quo where data was **"locked inside the systems of manufacturers or software providers"**, granting users (individuals, businesses, or public organizations) the **right to access and share the data they generate**. The mandate is clear: **both parties can access all data collected by a machine**.

For Data Engineers and Decision Makers, this legal turning point is an **accelerator for semantic interoperability**. Traditional cloud-centric data architectures, relying on platforms like **Amazon Web Services, Azure, and Google Cloud Platform**, struggle with the resulting complexity because they are prone to technical and economic issues:

|  |  |
| --- | --- |
| Cloud-Centric (Traditional) Approach | Linked Data & Wistor Alternative |
| Data Structure: Uses "schema-on-read," creating inaccessible "data swamps". | **Data Structure:** Data is **structured, machine-readable, and reusable** using RDF and OWL, providing a formal semantic layer. |
| Metadata: Describes format, leading to governance gaps. | **Metadata:** Describes **meaning, not just format**. |
| Integration: Requires complex N:M conversions or extensive ETL between systems. | **Integration:** Promotes **1:N integration** using unique URIs and open standards. It also supports N:M conversions including first order logic enabling more interoperability |
| Data Lock-in: High risk due to dependency on proprietary platform features, especially on data access | **Data Lock-in:** Wistor is a **native linked data platform** built on **open standards (RDF, OWL, SHACL,SPARQL)**, ensuring **no dependency on proprietary platforms** and providing freedom of choice. |""" ;
    onto:mentionsConcept onto:Amazon_Web_Services,
        onto:Data_Act,
        onto:Data_Lock,
        onto:Data_Structure,
        onto:Intro_Set,
        onto:Linked_Data,
        onto:Post_Draft,
        onto:Using_Template,
        onto:Why_Linked_Data_Infrastructure,
        onto:Wistor_Alternative .

sources:The_EU_Data_Act_explained__rights_obligations_and_challenges_for_data_holders_and_manufacturerspdf_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """The EU Data Act explained: rights, ...
Agenda
1. What does the EU Data Act regulate?
Insights Blog
THE EU DATA ACTEXPLAINED: RIGHTS,OBLIGATIONS ANDCHALLENGES FOR DATAHOLDERS ANDMANUFACTURERS
Data & AI
Written by Zohar Efroni & Selman Özen
26 Jun, 2024
2. Which products are affected and what are the challenges for
manufacturers?
3. What challenges do data holders face?
4. Who are the various parties involved in the EU Data Act?
5. Consequences for the automotive industry
6. When does the EU Data Act come into force and when do the obligations
apply?
7. Conclusion and suggestions for preparation
 
What does the EU Data Act regulate?
The EU Data Act aims, among other things, to enable better access to IoT data
and to strengthen "fairness" in B2B contractual relationships over data. It
addresses the harmonization of rules on access to and use of IoT data within the
European Union by providing a comprehensive set of rules and a framework for
data sharing. This framework, including the implementation of various data
sharing concepts, impacts both individuals and organizations. This is in line with
the aim of promoting innovation and fair access to data, while protecting privacy
and continuing to ensure fair competition in the European Union's internal
market.
The law deﬁnes which user-generated data can or must be shared with companies and
authorities or public sector bodies, thereby promoting the maintenance of user control over
user-generated data and increasing data interoperability. The law regulates data access
and transfer by providing guidelines to which data intermediaries, platforms and other
relevant stakeholders must adhere. It also sets out clear responsibilities in relation to data
processing, transparency and accountability, while establishing mechanisms to resolve
disputes and enforce compliance.
Which products are affected and what are the
challenges for manufacturers?
According to Article 2 (5) of the EU Data Act, a "connected product" is
An item that obtains, generates or collects data concerning its use or
environment and that is able to communicate product data via an electronic
communications service, physical connection or on-device access, and whose
primary function is not the storing, processing or transmission of data on behalf
of any party other than the user
Some examples are consumer products such as connected cars, health
monitoring devices or smart home devices as well as industrial products such as
airplanes, robots or industrial machines. The scope of application is broad, and in
case of doubt, "connected products" are all connected devices that generate
data during use by the user. This may also include product categories that were
initially excluded from the scope of the EU Data Act at earlier stages of its
development (e.g. PCs or smartphones), although the ﬁnal version no longer
contains these exceptions. The concept of IoT devices is therefore broad.
Connected products (also known as "Internet of Things" (IoT) devices) generate a
large amount of data. According to the EU Data Act, users of such products
should be given more control over the data generated through their use. In
addition, the transfer of data to data recipients is to be simpliﬁed.
What challenges do data holders face?
What data should be shared?
The deﬁnition of data covered by the EU Data Act leaves some questions
unanswered, e.g. whether master data, product data or other static data, for
example on technical features of the IoT product, are covered by the EU Data
Act. Does the data holder only have to provide dynamic raw data, even if it is not
useful or ﬁt for purpose without supplementary, static data? Even if several users
use the different aspects of a product, each user is only entitled to their "own"
data but not to data generated by the use of others. How the data could be
dynamically segmented and shared remains a major challenge.
Which data should/cannot be shared?
The protection of intellectual property and trade secrets remains important and
is taken into account in the EU Data Act. The same applies to data protection. A
compromise had to be found with the purpose and implementation of data
sharing. Data protection, the protection of intellectual property or trade secrets
could restrict the obligation to share data, impose further conditions on it or
even serve as a reason for refusing to transfer data. In practice, it will be
particularly challenging to establish technical and organizational mechanisms
that consolidate compliance with the EU Data Act on the one hand, and data
protection, IP and trade secrets on the other.
How should the user's access to the data be guaranteed?
According to Art. 3 (1) EU Data Act, connected products must be "designed and
manufactured ... in such a manner that product data ... are, by default, easily,
securely, free of charge, in a comprehensive, structured, commonly used and
machine-readable format and, where relevant and technically feasible, directly
accessible to the user." It remains unclear what direct provision of the data can
or must look like technically in individual cases (see III below for more details).
How should the data recipient's access to the data be guaranteed?
If the data recipient wishes to receive the data at the request (with the consent)
of the user, he may receive the data under FRAND conditions. The data holder
may charge a fee for this but may not discriminate against data recipients or
impose unfair contractual terms. How these obligations  are interpreted and how
the consent ﬂows are checked remains to be seen.
What does the data controller's duty to inform include?
Manufacturers of connected products must provide users with comprehensive
and detailed information about product data capabilities. This information must
also be understandable and clearly presented, which is the opposite of
comprehensive and detailed. How a compromise between the two principles can
be found remains to be seen.
Who are the various parties involved in the
EU Data Act?
As described above, the EU Data Act focuses on data access rights to the
product data of an IoT product. However, the access rights created by this not
only affect users of IoT products, but are also aimed in particular at
manufacturers of connected products and providers of connected services as
well as data holders and public sector bodies. 
This results in various special features and obligations for the various parties
involved. The obligations arising from the EU Data Act must already be observed
during the manufacturing of IoT products. The products must therefore already
be manufactured in such a way that the product data can be made available
easily, securely, free of charge and in a comprehensive, structured, common and
machine-readable format as standard.
In the context of the EU Data Act, both manufacturers and data holder (if they
are not one and the same person) should therefore examine their technical
provision options, as manufacturers and data holder must provide the available
data at the request of the user under the aforementioned conditions. If such a
technical provision option does not yet exist, companies should introduce one in
good time.
However, as already mentioned, the provision of data is not limited to the user
himself. If the user requests the transfer of their data to third parties, the third
party receives this data on behalf of the user. In this context, however, the third
party is still obliged to comply with the relevant requirements within the EU Data
Act.
In cases in which personal data is processed in addition to non-personal data,
the GDPR must also be observed, as the GDPR continues to apply without
restriction in addition to the EU Data Act.
As already mentioned above, the protection of trade secrets, among other
things, may constitute an exception to the extensive right of access to data.
Insofar as the relevant data embodies trade secrets, these are covered by the
Trade Secrets Directive and may prevent or restrict a claim to the provision of
the data to the user or to third parties. However, such a refusal or rejection would
have to be considered and examined separately by the data holder in each
individual case, as the existence of a trade secret would have to be
demonstrated and proven.
Consequences for the automotive industry
The EU Data Act will have a signiﬁcant impact on the automotive industry -
particularly with regard to connected vehicles. For the mobility market, the EU
Data Act opens up numerous new opportunities for business models based on
the exchange of data in ecosystems, among other things. However, there are a
large number of different players in the mobility sector, whose different focuses
of interest and, in particular, the diversity and heterogeneity of mobility data, can
lead to numerous challenges, which are explained in more detail below.
In future, car owners should have the right to use their data themselves or to
pass it on to someone else, such as an independent workshop or insurance
company. To this end, manufacturers must design their products and services in
such a way that they technically enable access to the processed data ("data
access by design"), as customers currently only have limited access to this data
(e.g. via the right of access under Art. 15 GDPR). In addition, customers must be
informed which IoT data is collected and for what purpose before they purchase a
vehicle or use the (mobility) service (pre-contractual information obligations).
However, the legal framework that speciﬁes the technical way in which the data from the
vehicle can be made usable for all market participants is still missing. The problem here is
that the EU Data Act covers all networked devices: From televisions with internet access to
smartphones and smart fridges - modern cars are also covered. This approach is too broad
and unspeciﬁc because the requirements for the various products differ. What is sufﬁcient
for a smart refrigerator is by no means enough for a vehicle. Sector-speciﬁc regulations for
car data are reportedly planned, but have not yet been published by the EU Commission
(June 2024).
In legal terms, car manufacturers are subject to transparency and information
obligations, among other things. At the same time, they must comply with data
protection regulations for personal data and protect their trade secrets. The EU
Data Act also has an impact on various contractual documents in the
relationship between data holder and user. Purchase/rental/leasing conditions,
for example, must be adapted, as must terms of use.
There are also a number of organizational challenges. Data providers and data
recipients need to be brought together, access rights distributed and controls
enforced. Governance principles are needed for data exchange, for IT and cyber
security, and an agreement must be reached on who owns the customer
interface, who is responsible for it and who controls access to users' (personal)
data.
Car manufacturers are also concerned that third parties will enrich themselves
from their technical developments if they are to share the data with them
without restriction. A frequent concern of the industry is that knowledge of
technical developments and trade secrets could be passed on to competitors.
Insurers, on the other hand, are calling for a neutral data trustee, as they fear
that car manufacturers will want to claim the potentially lucrative data business
for their own beneﬁt. According to Allianz Insurance, insurers and other
companies could use vehicle data to offer new or better services, e.g. more risk-
appropriate insurance offers.
The EU Commission should take the EU Data Act as an opportunity to clarify
existing uncertainties for the automotive industry, particularly with regard to
competition and data protection issues.
At the private sector level, companies enter into data partnerships and data
cooperations with each other in order to ensure secure access to data that
promotes innovation. In order to promote cooperation, the legislator should
create greater legal certainty for cooperation agreements for data exchange
between competitors through clarifying regulations in antitrust law.
When does the EU Data Act come into force and
when do the obligations apply?
The EU Data Act provides for a staggered deadline for the respective
regulations, which are described in particular in Chapters 3 and 4.
After coming into force on January 11, 2024, the EU Data Act will be applicable
law throughout Europe for data holder with a basic transition period of 20
months from September 12, 2025. However, any exceptions must be observed
(see Art. 50 EU Data Act).
Conclusion and suggestions for preparation
Now is the time for the automotive industry and all commercial players that
operate in the automotive ecosystem and are addressees of the Data Act
standards to start a strategic compliance project. Even if the requirements will
not predominantly take effect until the end of 2025/2026, initial precautions
must already be taken now, taking into account various internal company
development cycles. This includes the creation, review and adaptation of B2C
and B2B contracts, including the General Terms and Conditions (GTC) for the
provision and use of data in accordance with the requirements of the EU Data
Act. It is not too early to develop an overall concept for compliance with the EU
Data Act. This should include at least the following aspects:
This is because it involves the development of a comprehensive, multi-layered
and cross-functional compliance mechanism that is likely to require
considerable investment and long-term planning. Its framework can only be
brieﬂy outlined here.
1. In order to meet the requirements of the EU Data Act, it is crucial for any car
manufacturer or data holder to ensure cooperation between various
departments in this context. At the very least, the project requires action and
collaboration between IT and product, legal, business development, operations,
sales and consumer-facing services.
Technical interfaces for transferring data to users and recipients
UX and backend adjustments
All B2B and B2C contracts must be re-examined and adapted if necessary
Data governance concept and workﬂow / approval schemes from data
request to activation of access to the data.
Possible mechanism for compliance with B2G data requests.
2. It is advisable to review existing and planned use cases to ensure that the
company complies with the obligations of the Data Act. In the case of connected
cars/OEMs, these are most likely 'data holders' who are obliged to share data
with users, third parties and government agencies under certain conditions.
3. Once the use cases have been identiﬁed and the role of the company has
been determined for each use case, the next step is to adapt the front and back-
end components of products and services in such a way that a smooth and EU
Data Act-compliant data transfer is possible. When the user triggers a request,
the technical process should take into account the obligations and standards
resulting from the role.
4. Compliance with the EU Data Act should be integrated into product
development protocols at an early stage ("accessibility by design"). Technical
adaptations such as system interfaces (API) with third-party providers or the
creation of a function that enables users to request data in a specific format go
hand in hand with the creation of a compliance and governance structure. This
means that before data is passed on to external parties, it undergoes a
standardized review process for data requests, which in certain aspects is similar
to a data protection review and documentation.
5. In this process, a decision is made before execution as to whether a particular
data request is approved and, if so, to what extent. It also determines which
technical modalities apply to the execution of the request. As part of the data
governance mechanisms, data holders define the function and responsibilities
within the organization, including the role of the data manager, in addition to
processes. Legal issues that may be associated with a particular request, such as
data protection compliance in the case of personal data or the confidentiality of
information in the case of trade secrets, must be clarified in advance.
6. An important pillar of the compliance mechanism is the review and adaptation
of the contracts that the OEM concludes with users and other parties. Among
other things, the B2C contracts must comprehensively cover the use of the co-
generated data by the OEM. Detailed B2B contracts with third parties (data
recipients) on the transfer and use of data are equally essential.
7. In addition, OEMs should examine new business models in which data transfer
can create new sources of income. It would also make sense to examine the extent
to which the OEM can benefit from the advantages of a data recipient. This would
be conceivable, for example, if users instruct other companies to transfer data to
the OEM. This data could potentially be used to enrich the OEM's own product and
service portfolio and lead to a significant increase in competitiveness. The
prohibition on developing competing products/services with such data must
always be taken into account.
RELATED ARTICLES
Contact us
How data culture prepares you…
 i ti f AI
Explore the pillars of data-driven
decision-making and the importance
of effective data management.
Read insight
Data management: How…
 i b tt th i
Explore how decentralizing data
management can enhance data
quality and agility in companies,
unlocking the full potential of data fo
Read insight
+49 711 2992 0
contact@diconium.com
    
Information requirements
Data protection
Offering
Success stories
About us
Career
Insights
Imprint
Code of conduct
LkSG Compliance
Whistleblower System
Copyright 2024 diconium GmbH | Rommelstraße 11 | 70376 Stuttgart""" ;
    onto:mentionsConcept onto:Allianz_Insurance,
        onto:Career_Insights_Imprint_Code,
        onto:Data_Act,
        onto:European_Union,
        onto:General_Terms,
        onto:Insights_Blog,
        onto:Offering_Success,
        onto:Trade_Secrets_Directive,
        onto:Zohar_Efroni .

sources:YouTube-8nbb6CwpPMA_chunk_1 a onto:Chunk ;
    onto:chunkIndex 1 ;
    onto:chunkText """Over the last 22 years, we have undergone various transformations and faced challenges in our quest to improve data management. Today, we are primarily known for developing GraphDB, a leading database engine, and for our work with knowledge graphs. We are proud to be at the center of an ecosystem of over 20 partners, and we have a diverse and growing client base that includes multinational companies across various sectors such as banking, finance, healthcare, and national security.

### The Importance of RDF

Our commitment to the semantic web and data standardization is evident through our participation in various organizations like W3C. RDF (Resource Description Framework) and related query languages play a crucial role in this ecosystem.

To illustrate our approach, consider the challenge of integrating proprietary information within enterprises. This involves mapping and linking diverse datasets to create a unified view of enterprise knowledge. Our unique approach leverages extensive domain knowledge, allowing us to enhance proprietary information by contextualizing it, much like a human expert would.

### Knowledge Graphs and Technology

At OntoText, we focus on knowledge graph management, which involves building, storing, indexing, and querying knowledge graphs. Our technology aims to provide better results and comprehensive outputs in less time. We have developed a solid offering for several capabilities, including database engine operations, analytics, and visualization, while also partnering with leading technology providers for areas outside our core focus.

### Advantages of RDF Over Labeled Property Graphs

The main topic of this webinar is how RDF addresses the historical advantages of labeled property graphs. For instance, property graphs allow for the attachment of properties to edges, a feature traditionally absent in RDF. However, recent advancements, such as RDF-star, enable the attachment of metadata to edges, significantly enhancing RDF's capabilities.

### RDF-Star: A Game Changer

RDF-star allows users to make statements about statements, thus enriching the metadata associated with relationships in the graph. This is a significant improvement over earlier methods, which often required complex workarounds. RDF-star simplifies the process of attaching expressive metadata, making it easier to manage and utilize.

We have conducted experiments comparing RDF-star implementations with traditional methods, demonstrating measurable gains in efficiency when using RDF-star in GraphDB.

### Graph Traversal and Performance""" ;
    onto:mentionsConcept onto:Advantages_of_RDF_Over_Labeled_Property_Graphs,
        onto:Game_Changer,
        onto:Graph_Traversal,
        onto:Graph_Traversal_and_Performance,
        onto:Knowledge_Graphs,
        onto:Knowledge_Graphs_and_Technology,
        onto:RDF-Star_A_Game_Changer,
        onto:Resource_Description_Framework,
        onto:Technology_At,
        onto:The_Importance_of_RDF .

sources:tr_104410v010101ppdf_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """ETSI TR 104 410 V1.1.1 (2025-10) 
Data Solutions (DATA); 
Data Act (art. 33) standardization suggestions 
 
  
 
TECHNICAL REPORT 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 2 
 
Reference 
DTR/DATA-00104410 
Keywords 
DATA, data interoperability, oneM2M, SAREF 
ETSI 
650 Route des Lucioles 
F-06921 Sophia Antipolis Cedex - FRANCE 
 
Tel.: +33 4 92 94 42 00   Fax: +33 4 93 65 47 16 
 
Siret N° 348 623 562 00017 - APE 7112B 
Association à but non lucratif enregistrée à la 
Sous-Préfecture de Grasse (06) N° w061004871 
 
Important notice 
The present document can be downloaded from the 
ETSI Search & Browse Standards application.  
The present document may be made available in electronic versions and/or in print. The content of any electronic and/or 
print versions of the present document shall not be modified without the prior written authorization of ETSI. In case of any 
existing or perceived difference in contents between such versions and/or in print, the prevailing version of an ETSI 
deliverable is the one made publicly available in PDF format on ETSI deliver repository. 
Users should be aware that the present document may be revised or have its status changed,  
this information is available in the Milestones listing. 
If you find errors in the present document, please send your comments to 
the relevant service listed under Committee Support Staff. 
If you find a security vulnerability in the present document, please report it through our  
Coordinated Vulnerability Disclosure (CVD) program. 
Notice of disclaimer & limitation of liability 
The information provided in the present deliverable is directed solely to professionals who have the appropriate degree of 
experience to understand and interpret its content in accordance with generally accepted engineering or  
other professional standard and applicable regulations.  
No recommendation as to products and services or vendors is made or should be implied. 
No representation or warranty is made that this deliverable is technically accurate or sufficient or conforms to any law 
and/or governmental rule and/or regulation and further, no representation or warranty is made of merchantability or fitness 
for any particular purpose or against infringement of intellectual property rights. 
In no event shall ETSI be held liable for loss of profits or any other incidental or consequential damages. 
 
Any software contained in this deliverable is provided "AS IS" with no warranties, express or implied, including but not 
limited to, the warranties of merchantability, fitness for a particular purpose and non-infringement of intellectual property 
rights and ETSI shall not be held liable in any event for any damages whatsoever (including, without limitation, damages 
for loss of profits, business interruption, loss of information, or any other pecuniary loss) arising out of or related to the use 
of or inability to use the software. 
Copyright Notification 
No part may be reproduced or utilized in any form or by any means, electronic or mechanical, including photocopying and 
microfilm except as authorized by written permission of ETSI. 
The content of the PDF version shall not be modified without the written authorization of ETSI. 
The copyright and the foregoing restriction extend to reproduction in all media. 
 
© ETSI 2025. 
All rights reserved. 
 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 3 
Contents 
Intellectual Property Rights ................................................................................................................................ 4 
Foreword ............................................................................................................................................................. 4 
Modal verbs terminology .................................................................................................................................... 4 
Introduction ........................................................................................................................................................ 4 
1 Scope ....................................................................................................................... ................................. 6 
2 References ................................................................................................................................................ 6  
2.1 Normative references ...................................................................................................... ................................... 6 
2.2 Informative references .................................................................................................... .................................... 7 
3 Definition of terms, sy mbols and abbreviations ....................................................................................... 7 
3.1 Terms .................................................................................................................................................................. 7  
3.2 Symbols ................................................................................................................... ........................................... 8 
3.3 Abbreviations ............................................................................................................. ........................................ 8 
4 oneM2M ...................................................................................................................... ............................. 9 
4.1 Introduction .............................................................................................................. .......................................... 9 
4.2 Use as it is to fulfil th e EU Data Act and the SReq ............................................................................................ 9 
4.3 Potential improvements .................................................................................................... ................................ 10 
4.4 Additional guidelines ..................................................................................................... .................................. 11 
5 SAREF ....................................................................................................................... ............................ 11 
5.1 Introduction .............................................................................................................. ........................................ 11 
5.2 Use of SAREF to fulfil the EU Data Act and the SReq ....................................................................... ............ 12 
5.3 Potential improvements .................................................................................................... ................................ 12 
6 NGSI-LD ..................................................................................................................... ........................... 13 
6.1 Introduction .............................................................................................................. ........................................ 13 
6.2 Use of NGSI-LD to fulfil th e EU Data Act and the SReq ................................................................................ 13 
6.3 Potential improvements .................................................................................................... ................................ 14 
7 oneM2M, SAREF and NGSI-LD cooperation to fulfil EU Data Act and SReq .................................... 14  
8 Conclusions ................................................................................................................. ........................... 15 
Annex A: Change history ....................................................................................................... ............... 16 
History .............................................................................................................................................................. 17 
 
  
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 4 
Intellectual Property Rights 
Essential patents  
IPRs essential or potentially essential to normative deliverables may have been declared to ETSI. The declarations 
pertaining to these essential IPRs, if any, are publicly available for ETSI members and non-members, and can be 
found in ETSI SR 000 314: "Intellectual Property Rights (IPRs); Essential, or potentially Essential, IPRs notified to 
ETSI in respect of ETSI standards", which is available from the ETSI Secretariat. Latest updates are available on the 
ETSI IPR online database. 
Pursuant to the ETSI Directives including the ETSI IPR Policy, no investigation regarding the essentiality of IPRs, 
including IPR searches, has been carried out by ETSI. No guarantee can be given as to the existence of other IPRs not 
referenced in ETSI SR 000 314 (or the updates on the ETSI Web server) which are, or may be, or may become, 
essential to the present document. 
Trademarks 
The present document may include trademarks and/or tradenames which are asserted and/or registered by their owners. 
ETSI claims no ownership of these except for any which are indicated as being the property of ETSI, and conveys no 
right to use or reproduce any trademark and/or tradename. Mention of those trademarks in the present document does 
not constitute an endorsement by ETSI of products, services or organizations associated with those trademarks. 
DECT™ , PLUGTESTS™ , UMTS™  and the ETSI logo are trademarks of ETSI registered for the benefit of its 
Members. 3GPP™ , LTE™  and 5G™  logo are trademarks of ETSI registered for the benefit of its Members and of the 
3GPP Organizational Partners. oneM2M™  logo is a trademark of ETSI registered for the benefit of its Members and of 
the oneM2M Partners. GSM
® and the GSM logo are trademarks registered and owned by the GSM Association. 
Foreword 
This Technical Report (TR) has been produced by ETSI Technical Committee Data Solutions (DATA). 
Modal verbs terminology 
In the present document "should", "should not", "may", "need not", "will", "will not", "can" and "cannot" are to be 
interpreted as described in clause 3.2 of the ETSI Drafting Rules (Verbal forms for the expression of provisions). 
"must" and "must not" are NOT allowed in ETSI deliverables except when used in direct citation. 
Introduction 
Data has become the backbone of the digital economy. The rapidly increasing availability of Internet-connected 
products ("connected products") on the European market, which are producing an enormous volume of data, has 
strengthened enabling economic growth and competitiveness, fostering innovation and improving public services. The 
importance of data exchange, data sharing and data flows becomes more and more significant for businesses and 
individuals worldwide. Seamless and secure data flows, which are enabled within and across different IoT domains 
(cross-border and cross-industry) using data spaces or data ecosystems provide crucial businesses value. 
The legal environment about data exchanges and data transactions plays an essential role in the development of data 
ecosystems as it brings a trust framework for all stakeholders, who are involved in the exchange of data. In Europe, the 
EU Data Act [i.2] is one of the key regulations, which came into force in December 2023 and aims to create a new legal 
framework for handling data. It gives users of connected products (companies or individuals who own, lease or rent 
such a product) greater control over the data they generate, while maintaining incentives for those who invest in data 
technologies. It also sets out general conditions for situations where a company is legally obliged to share data with 
another company. 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 5 
Article 33 of the EU Data Act [i.2] sets out comprehensive rules on the interoperability of data, mechanisms and 
services for data sharing and use in shared European Data Spaces. Data Spaces include, for example, cloud 
environments. The EU Commission may issue implementing provisions and request standard-developing organizations 
(e.g. CEN, CENELEC, ETSI) to define uniform standards in this area in order to achieve this interoperability. The 
providers will then implement these accordingly. 
Referring to Article 33 of the EU Data Act [i.2], the European Commission made available the Standardisation Request 
SReq [i.3]. The SReq requests CEN, CENELEC and ETSI to draft new European standards and European 
standardisation deliverables as listed in the Annexes of the SReq [i.3] in support of Article 33 of the EU Data Act [i.2]. 
For all deliverables requested by the SReq [i.3], CEN, CENELEC and ETSI are expected to co-operate in the Mode 4, 
which is specified in the Basic Co-operation Agreement between these three Standards Development Organizations 
(SDOs). According to this, one Party should take the lead of work and the other(s) may make written contributions 
during the progress of drafting the requested new European standards. This relation includes also full information 
sharing via nominated observers. 
 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 6
1 Scope 
The present document supports the preparation of the answer to C(2025)4135 - Standardisation Request M/614 [i.3] 
further on called "SReq" in the present document. 
The present document is based on the input from ETSI TR 104 409 [i.1]. 
Both reports (the present document and ETSI TR 104 409 [i.1]) will prepare the normative work to satisfy the  
SReq [i.3]. 
The present document is structured as follows: 
• Clauses 1 to 3 set the scene and provide references as well as definitions of terms, symbols and abbreviations,
which are used in the present document.
• Clause 4 provides a summary of the findings highlighted in ETSI TR 104 409 [i.1] about how oneM2M fulfils
the EU Data Act [i.2] with particular reference to Article 33 and the SReq [i.3]. It presents guidelines about
how oneM2M can be used to fulfil as much as possible the standardization requirements of these two
documents without the need for changes to oneM2M specifications.
Additionally, this clause lists potential Change Requests (CRs) that would enable oneM2M to fulfil some of
the aspects of these two documents (i.e. ETSI TR 104 409 [i.1] and the present document) that are currently
not covered. The content focuses on improvements that can be implemented in a reasonable manner according
with the timing available to make oneM2M compliant with the EU Data Act [i.2] with particular reference to
Article 33 and the SReq [i.3].
Some requirements of the two documents fall outside the scope of oneM2M specifications. Where possible,
this clause provides clarification of such boundaries together with additional guidelines that may help define a
clear positioning for oneM2M in the context of the two documents.
• Clause 5 provides a summary of the findings highlighted in ETSI TR 104 409 [i.1] about how SAREF fulfils
the EU Data Act [i.2] with particular reference to Article 33 and the SReq [i.3].
It lists feasible improvements that would enable SAREF [i.4] to fulfil the standardization requirements of these
two documents. The content focuses on improvements that can be implemented in a reasonable manner
according with the timing available to make SAREF compliant with the two documents.
Clause 5 provides possible additional guidelines for aligning SAREF with the EU Data Act [i.2] with
particular reference to Article 33 and the SReq [i.3].
• Clause 6 provides a summary of the findings highlighted in ETSI TR 104 409 [i.1] about how NGSI-LD
fulfils the EU Data Act [i.2] with particular reference to Article 33 and the SReq [i.3].
It provides guidelines about how NGSI-LD can be used to fulfil as much as possible the two documents
without carrying out changes within the NGSI-LD methodology.
Clause 6 lists feasible improvements that would enable NGSI-LD to fulfil the standardization requirements of
these two documents. The content focuses on improvements that can be implemented in a reasonable manner
according with the timing available to make NGSI-LD compliant with the EU Data Act [i.2] with particular
reference to Article 33 and the EU Standardisation Request, e.g. the definition of the mappings between
NGSI-LD and DCAT-AP provided in [i.7].
• Clause 7 provides insights about if the union of the three assets enables the fulfilment of the EU Data Act [i.2]
with particular reference to Article 33 and the SReq [i.3].
• Clause 8 provides a summary of conclusions from the standardization suggestions.
2 References 
2.1 Normative references 
Normative references are not applicable in the present document. 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 7 
2.2 Informative references 
References are either specific (identified by date of publication and/or edition number or version number) or 
non-specific. For specific references, only the cited version applies. For non-specific references, the latest version of the 
referenced document (including any amendments) applies. 
NOTE: While any hyperlinks included in this clause were valid at the time of publication, ETSI cannot guarantee 
their long-term validity. 
The following referenced documents may be useful in implementing an ETSI deliverable or add to the reader's 
understanding, but are not required for conformance to the present document. 
[i.1] ETSI TR 104 409: "Data Solutions (DATA); Data Act (art. 33) requirement and references 
analysis". 
[i.2]
 Regulation (EU) 2023/2854 of the European Parliament and of the Council of 13 December 2023 
on harmonised rules on fair access to and use of data and amending Regulation (EU) 2017/2394 
and Directive (EU) 2020/1828 (Data Act). 
[i.3] C(2025)4135 – Standardisation request M/614: "Commission Implementing Decision of 1.7.2025 
on a standardisation request to the European standardisation organisations as regards a European 
Trusted Data Framework in support of Regulation (EU) 2023/2854 of the European Parliament 
and of the Council". 
[i.4] ETSI SAREF portal. 
[i.5] ETSI EN 303 760: "SmartM2M; SAREF Guidelines for IoT Semantic Interoperability; Develop, 
apply and evolve Smart Applications ontologies". 
[i.6] ETSI GS CIM 006: "Context Information Management (CIM); NGSI-LD Information Model". 
[i.7] ETSI GR CIM 048: "Context Information Management (CIM); Handling of data catalogues and 
data services with NGSI-LD". 
[i.8] DCAT-AP 3.0.1 profile. 
[i.9] ETSI TS 104 414: "Data Solutions (DATA); Ontology Web Server - Functional Interfaces and 
Architectural Specification". 
[i.10] ETSI TS 104 415: "Data Solutions (DATA); IoT Ontology Web Server - User Interfaces and Use 
Cases". 
[i.11] ETSI TR 104 416: "Data Solutions (DATA); IoT Ontology Web Server - Security, Deployment, 
and Support". 
3 Definition of terms, symbols and abbreviations 
3.1 Terms 
For the purposes of the present document, the following terms apply: 
ACME CSE: open source CSE Middleware for Education 
connected product: item that obtains, generates or collects data concerning its use or environment and that is able to 
communicate product data via an electronic communications service, physical connection or on-device access, and 
whose primary function is not the storing, processing or transmission of data on behalf of any party other than the user  
data holder: natural or legal person that has the right or obligation, in accordance with the EU Data Act [i.2], 
applicable Union law or national legislation adopted in accordance with Union law, to use and make available data, 
including, where contractually agreed, product data or related service data which it has retrieved or generated during the 
provision of a related service 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 8 
data processing service: digital service that is provided to a customer and that enables ubiquitous and on-demand 
network access to a shared pool of configurable, scalable and elastic computing resources of a centralized, distributed or 
highly distributed nature that can be rapidly provisioned and released with minimal management effort or service 
provider interaction 
data recipient: natural or legal person, acting for purposes which are related to that person's trade, business, craft or 
profession, other than the user of a connected product or related service, to whom the data holder makes data available, 
including a third party following a request by the user to the data holder or in accordance with a legal obligation under 
Union law or national legislation adopted in accordance with Union law 
EU Data Act: Regulation (EU) 2023/2854 of the European Parliament and of the Council of 13 December 2023 on 
harmonised rules on fair access to and use of data and amending Regulation (EU) 2017/2394 and 
Directive (EU) 2020/1828 (Data Act) [i.2] 
GeoDCAT-AP: extension of DCAT-AP for the representation of geographic metadata 
public sector body: national, regional or local authorities of the Member States and bodies governed by public law of 
the Member States, or associations formed by one or more such authorities or one or more such bodies 
smart contract: computer program used for the automated execution of an agreement or part thereof, using a sequence 
of electronic data records and ensuring their integrity and the accuracy of their chronological ordering 
SReq: Standardisation Request to the European Committee for Standardization (CEN), the European Committee for 
Electrotechnical Standardization (CENELEC) and the European Telecommunications Standards Institute (ETSI) as 
regards to a European Trusted Data Framework [i.3] 
3.2 Symbols 
Void. 
3.3 Abbreviations 
For the purposes of the present document, the following abbreviations apply: 
AI Artificial Intelligence 
API Application Programming Interface 
CEN European Committee for Standardization 
CENELEC European Committee for Electrotechnical Standardization 
CR Change Request 
DCAT Data CATalogue vocabulary 
DCAT-AP Data CATalogue vocabulary Application Profile 
DSSC Data Spaces Support Centre 
ETSI European Telecommunications Standards Institute 
EU European Union 
GDPR General Data Protection Regulation 
HTTP HyperText Transfer Protocol 
IoT Internet of Things 
JSON JavaScript Object Notation 
KPI Key Performance Indicator 
LLM Large Language Model 
MCP Model Context Protocol 
MQTT Message Queuing Telemetry Transport 
NGSI-LD Next Generation Service Interface-Linked Data 
RDF Resource Description Framework 
SAREF Smart Applications REFerence ontology 
SReq Standardisation Request 
TR Technical Report 
W3C
® World Wide Web Consortium 
Web World Wide Web 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 9 
4 oneM2M 
4.1 Introduction 
The present clause gives a summary of the findings highlighted in ETSI TR 104 409 [i.1] about how oneM2M fulfils 
the EU Data Act [i.2] with particular reference to Article 33 and the EU Standardisation Request [i.3]. The summary 
guides the content of the remaining sub-clauses. 
4.2 Use as it is to fulfil the EU Data Act and the SReq 
oneM2M as it is does satisfy a substantial part of the SReq [i.3], especially in the following areas: 
• General Framework and Architecture: 
- oneM2M provides a comprehensive interoperability framework designed for seamless communication 
across various protocols and data models. 
- It supports a service layer that can be integrated into diverse hardware and software systems (this 
includes also access to devices, thanks to its legacy from IoT domain). 
• Terminology, Concepts, and Mechanisms: 
- oneM2M specifications clearly define:  
  Terminology (e.g. "Application Entity," "Common Services Entity").  
  Architectural concepts (e.g. hierarchical resource structure).  
  Mechanisms for data sharing, access control, and interoperability.  
  oneM2M supports data sharing by design. API queries are supported, both simple ones and 
semantic based, also in distributed contexts. 
  oneM2M by design supports distributed architectures.  
  Thanks to its legacy as an IoT Platform, access to devices is native. 
• Interoperability Requirements: 
- Data sharing & API access: Fully specifies protocols (HTTP, MQTT, etc.) and RESTful APIs for 
automatic data transmission.  
- oneM2M specifies interoperability mechanisms allowing data exchange with other oneM2M instances 
and non-oneM2M systems while preserving data security and access rights. 
- It supports API queries, both simple and semantic based, even in distributed contexts. 
- Distributed architectures: native support for IoT devices and cross-platform data exchange.  
• Implementation Framework for Semantic Assets: 
- has good support for semantics, including storage, management, and discovery of ontologies, 
(e.g. SAREF, and custom ones). 
- Machine-readable data: Resources are represented in JSON, enabling semantic annotation. 
- It offers capabilities to discover resources based on semantic descriptions and content. 
• Trustworthiness Requirements: 
- oneM2M provides advanced granular access control incorporating roles, tokens, identity verification, 
time-based restrictions, and location-based conditions. 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 10 
- It specifies sophisticated access control policies able to handle demanding scenarios. 
- Consent management support is available, considering GDPR and similar regulations in other parts of 
the world. 
- Data integrity: Versioning ("container instances") tracks changes.  
- License management: Explicitly specified for data sharing.  
As such, oneM2M can contribute to provide a solid framework for the implementation of "services" in the sense of the 
DSSC Blueprint, especially in the context of Technical Building Blocks. 
The Blueprint takes the stance that services can vary widely among Data Spaces, especially since specialized protocols 
may be in use according to individual vertical application. For that reason, the Blueprint cites examples but does not 
endorse one specific solution. 
oneM2M follows a different approach, i.e. that it assumes that most of the use cases can be tackled by using a single 
framework.  
Even in the cases where consolidated protocols/data layout are well established for a given vertical industry, a clear path 
for dealing with that (via the use of Application Entities) is outlined. This way, the effort needed to adapt to a new 
vertical is reduced to a minimum and clearly confined to easily identified sections of the software implementing the 
platform. 
Application Entities exchange data and information with the oneM2M core via messages, following to APIs that are 
well specified. This approach makes the code implementing the Application Entity to be disjoint from that of the 
oneM2M core: in this way, existing libraries for the existing/consolidated use cases can be leveraged, and there are no 
constraints regarding the programming language used. 
This is by design, with the intention of reusing as much as possible, avoiding reinventing the wheel each time. 
4.3 Potential improvements 
There are areas where oneM2M allows some room for potential improvements (work may be already being done to 
address some of said improvements): 
• Master Catalogue: 
- oneM2M does not provide a single master catalogue for listing available data. Considering the potential 
dimensions and the tremendous diversity of services, applications and of the related data sets, oneM2M 
provides advanced functionality to discover applications and related data, so that data catalogues can be 
easily built as oneM2M services. 
- Another work item, recently approved, calls for studying and specifying the interworking between 
oneM2M and Model Context Protocol (MCP). 
- This provides an alternative approach, in line with modern developments in LLMs and Agentic AI. 
There will be challenges as well, most notably about balancing the (typically greedy) access by AI 
against the granularity of access control allowed by the oneM2M specifications. 
• Data collection methodology, data quality, and uncertainty: 
- The oneM2M specifications only guarantee correct handling and transfer of data items between digital 
entities. 
- It is implicitly assumed that assessment of data quality is left either to human actors (who can have 
knowledge of the quality of data and related collection methodology) or to automated tools (that can, 
e.g. assess quality related information according to given KPIs). 
- A possible improvement, that can be considered by the oneM2M community, is to define a standardized 
way to convey information about quality of a given data item to participants of the Data Space. 
- Similar considerations might apply also to concepts like KPIs or reporting structure for Data Space 
maturity. 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 11 
• Auditability of data transactions: 
- oneM2M provides users with a mechanism for data versioning (so called "content instances" in oneM2M 
jargon of any resource are kept available and can be accessed by users, subject to access control 
policies). 
- A possible improvement to this scheme is to standardize the recording of aspects of the actors that caused 
such changes to occur. In this way it becomes possible to ensure full accountability of the actors that 
operate on a given Data Space. Such a feature could be graduated according to the required degree of 
accountability, from none to who caused data changes up to who just accessed any resource for the most 
demanding cases. 
4.4 Additional guidelines 
Clauses 6.1.1 and 6.1.2 of ETSI TR 104 409 [i.1] explain that oneM2M is more that the specification of an IoT 
platform, stating it is well suited to support Data Spaces. 
These capabilities, however, are not currently advertised on the oneM2M.org website. 
A possible improvement is to augment the website content to reflect these considerations. 
oneM2M specifications are technical in nature and describe APIs, mechanisms for managing information, etc. There are 
guidelines and best practices for implementation and usage of the specifications but, currently, they are oriented 
towards technical users. 
To better meet some of the requirements from the SReq [i.3], additional guidelines can be provided, articulated in 
practical, non-legal language that is accessible to all potential stakeholders.  
Such additional guidelines should cover not only the way oneM2M compliant frameworks can be 
implemented/deployed, but also explaining how oneM2M features map to requirements of the SReq [i.3], including 
coverage of the way to meet domain-specific (non-regulatory) requirements 
5 SAREF 
5.1 Introduction 
ETSI TR 104 409 [i.1] provides an analysis about how the SAREF methodology fulfils the EU Data Act [i.2], with 
particular reference to the Article 33 and the EU Standardisation Request [i.3]. There have been two main aspects 
making SAREF well positioned compared to the EU Data Act [i.2]. The first one is that the SAREF methodology is 
mentioned within the SReq [i.3] as a virtuous example of support to achieve data interoperability. This point paves the 
way to adopting the SAREF methodology to build data repositories and to making them compliant with the SReq [i.3]. 
The second one concerns the structure of the SAREF methodology, i.e. a set of Technical Specifications containing the 
description of each element and examples of concrete specifications. Their quality enables independent developers to 
develop conformant implementations. As part of the specifications, terminology, concepts and mechanisms used are 
clearly specified. 
Clause 5.2 provides a description about the impact of the SAREF methodology, concerning its current level of 
compliance with the EU Data Act [i.2], if it is used as it is. Instead, clause 5.3 describes a set of action that should be 
put in place to enhance the compliance level of the SAREF methodology to make it fully compliant with the 
EU Data Act [i.2] and EU SReq [i.3]. 
5.2 Use of SAREF to fulfil the EU Data Act and the SReq 
The content of the present clause refers to the version of SAREF published at the date in which the present document is 
written. Any subsequent updates of SAREF may affect the validity of the content provided below. 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 12 
The SAREF methodology is described in ETSI EN 303 760 [i.5] where there are provided the good practices about how 
the SAREF methodology can be used to grant semantic interoperability for IoT smart applications in a set of high-level 
outcome-focused provisions. Through the methodology described within ETSI EN 303 760 [i.5], it is possible to 
support all parties involved in the development and manufacturing of IoT smart applications and products with 
guidance on making them interoperable in compliance to the SAREF framework. The provisions give organizations and 
companies the flexibility to innovate and implement SAREF-compliant semantic interoperability solutions appropriate 
for their products and applications. Indeed, through the adoption of the described methodology, the datasets produced 
meets completely the following aspects of the SReq [i.3]: 
• Paragraph 1 (c) of the EU Data Act [i.2], Article 33; 
• Harmonised standards on Trusted Data Transactions - Part 1: Terminology, concepts and mechanisms; 
• Harmonised standards on Trusted Data Transactions - Part 2: Trustworthiness requirements; 
• Technical specification(s) on an implementation framework for semantic assets; 
• European standard on a quality framework for internal data governance; 
and partially: 
• Paragraph 1 (a) of the EU Data Act [i.2], Article 33; 
• Harmonised standards on Trusted Data Transactions - Part 3: Interoperability requirements. 
In particular, the SAREF methodology is fully compliant with the accessibility requirement. This enables the creation of 
datasets that, in turn, will be all compliant with the SReq [i.3]. Indeed, by adopting the SAREF methodology, datasets 
can be published by using the RDF Turtle language, a machine-readable format recommended by the W3C
®. This way, 
it is possible to understand the structure of the datasets built by using the SAREF methodology in a clear manner. 
The usage of the SAREF methodology in its current version leaves open some gaps before fulfilling completing the 
SReq [i.3]. Clause 5.3 provides a list of possible actions to improve the SAREF methodology. 
5.3 Potential improvements 
The present clause provides a set of actions that should be considered to improve the SAREF methodology, and a 
mention to possible assets that would make the SAREF ecosystem fully compliant with the EU Data Act [i.2] and the 
SReq [i.3]. Particularly, three feasible actions can be implemented to enhance the fulfilment of SReq [i.3]. 
The SReq [i.3] explicitly requires reliance on existing communities and well-established specifications, in particular 
DCAT-AP and some extensions. Therefore, DCAT-AP is intended to serve as the baseline methodology for dataset and 
catalogue metadata, while SAREF can provide domain-specific semantics enriching DCAT-AP descriptions. 
First, the SAREF methodology ensures the management of metadata catalogues describing the resource. The 
vocabulary recommended by the EU SReq is DCAT-AP [i.8] and some existing extensions. Through DCAT-AP, it is 
possible to generate a DCAT-AP extension or mapping for each dataset built by using the SAREF methodology. This 
new application profile allows to provide metadata describing such datasets to make them compliant with the 
SReq [i.3]. Indeed, currently, datasets built by using the SAREF methodology are, on the one hand, equipped with some 
descriptors coming from the RDF language. But, on the other hand, each dataset is not associated with a datasheet 
providing all the necessary information required by the SReq [i.3] (e.g. data quality descriptors). To satisfy this 
requirement, it is necessary to integrate the management of DCAT-AP extensions into the SAREF methodology. This 
way, the data structures, data formats, vocabularies, classification schemes, taxonomies and code lists, will be described 
in a publicly available and consistent manner with other Data Spaces to allowing the publication of SAREF-based 
datasets within the Common European Data Spaces catalogue and ensuring cross-domain interoperability. 
Second, to provide a SAREF-based query endpoint. The ontologies instantiating the SAREF methodology are available 
for download through the dedicated portal. However, it is still missing an endpoint to query datasets built by using the 
SAREF methodology (i.e. instantiating the SAREF ontologies) with the aim of extracting knowledge about their 
structures and contents. 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 13 
Third, to implement and deploy a SAREF-compliant web server. The SAREF ecosystem comes with a collection of 
synthetic examples showing how the ontologies instantiating the SAREF methodology can be used. However, the type 
of scenarios specified in the SReq [i.3] is not addressed since, currently, the SAREF methodology does not include an 
accompanying web server enabling the mentioned type of access. Currently, even SAREF is available for download 
through its website, it is not equipped with a facility allowing the access to the structured data produced by using 
SAREF. This issue is going to be addressed through the adoption of the ETSI IoT Ontology Web Server [i.9], [i.10], 
[i.11]. 
6 NGSI-LD 
6.1 Introduction 
ETSI TR 104 409 [i.1] provides an analysis about which components of NGSI-LD fulfils the EU Data Act [i.2], with 
particular reference to the Article 33 and the EU Standardisation Request [i.3]. NGSI-LD [i.6] is information model and 
API for publishing, querying and subscribing to context information. It enables structured information sharing across 
multiple domains like smart cities, smart industries, and digital twins. The NGSI-LD information model represents 
Context Information as entities that have properties and relationships to other entities. It is derived from property 
graphs, with semantics formally defined on the basis of RDF and the semantic web framework. 
There have been two main aspects making NGSI-LD aligned to the EU Data Act [i.2]. The first one is that with 
NGSI-LD it is possible to describes both data points and datasets with a set of metadata making this information 
accessible. The possibility of describing datasets put NGSI-LD at the same semantic level of DCAT by making 
NGSI-LD compliant with the SReq [i.3]. The second one is how the accessibility requirement is satisfied by the 
NGSI-LD standard. The specifications provide a complete documentation concerning the accessing mechanisms to all 
the data stored by using such a standard. NGSI-LD comes also with a set of open-source implementations of web 
service that can be used to access data collections stored by using the NGSI-LD format. 
Clause 6.2 provides a description about the impact of NGSI-LD, concerning its current level of compliance with the 
EU Data Act [i.2], if it is used as it is. Instead, clause 6.3 describes a set of action that should be put in place to enhance  
the compliance level of NGSI-LD to make it fully compliant with the EU Data Act [i.2] and EU SReq [i.3]. 
6.2 Use of NGSI-LD to fulfil the EU Data Act and the SReq 
The content of this clause refers to the version of NGSI-LD published at the date in which the present document is 
written. Any subsequent updates of NGSI-LD may affect the validity of the content provided below. 
The NGSI-LD specifications are described in [i.6] where there are provided the good practices about how NGSI-LD can 
be used to grant semantic interoperability for IoT smart applications in a set of high-level outcome-focused provisions. 
Through the specifications described in [i.6], it is possible to support all parties involved in the development and 
manufacturing of IoT smart applications and products with guidance on making them. The provisions give 
organizations and companies the flexibility to innovate and implement NGSI-LD compliant semantic interoperability 
solutions appropriate for their products and applications. Indeed, through the adoption of the described methodology, 
the datasets produced meets completely the following aspects of the SReq [i.3]: 
• Paragraph 1 (c) of the EU Data Act [i.2], Article 33; 
• Paragraph 3 and Paragraph 8 of the EU Data Act [i.2], Article 33; 
• Harmonised standards on Trusted Data Transactions - Part 2: Trustworthiness requirements; 
• Technical specification(s) on a data catalogue implementation framework; 
and partially: 
• Paragraph 1 (a) of the EU Data Act [i.2], Article 33; 
• Harmonised standards on Trusted Data Transactions - Part 1: Terminology, concepts and mechanisms; 
• Harmonised standards on Trusted Data Transactions - Part 3: Interoperability requirements; 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 14 
• Technical specification(s) on an implementation framework for semantic assets; 
• European standard on a quality framework for internal data governance. 
The usage of NGSI-LD in its current version leaves open same gaps before fulfilling completing the SReq [i.3]. 
Clause 6.3 provides a list of possible actions to improve NGSI-LD. 
A key development in this area is ETSI GR CIM 048 [i.7], which provides a detailed mapping between NGSI-LD and 
DCAT-AP. This mapping demonstrates how NGSI-LD annotations at the entity level can be systematically expressed in 
DCAT-AP compliant metadata records, thereby bridging dataset semantics with the catalogue-level requirements 
mandated by the SReq [i.3] ensuring discoverability. 
6.3 Potential improvements 
This Clause provides a set of actions that should be considered to improve NGSI-LD, and a mention to possible assets 
that would make NGSI-LD fully compliant with the EU Data Act [i.2] and the SReq [i.3]. 
In the previous clause, it has been mentioned that NGSI-LD satisfies the accessibility requirement by including 
information about its content, use restrictions, and licences in a machine-readable format, to allow the recipient to find, 
access and use the data. Concerning the aspects related to information about the data collection methodology, data 
quality and uncertainty, they are not applicable in the case of NGSI-LD since it is defined as a vocabulary to annotate 
data that have been previously collected. Hence, such a verification is demanded to the creator of the dataset annotated 
with the NGSI-LD vocabulary. 
The NGSI-LD information model consists of a specification. Their quality enables independent developers to develop 
conformant implementations. As part of the specifications, terminology, concepts and mechanisms used are clearly 
specified. These can be contributed to define the subset of the SReq [i.3] that can be covered by NGSI-LD. Concerning 
the specific requirement of terminology specification, the NGSI-LD specifications play the role of drivers to build 
assets being compliant with the SReq [i.3]. Hence, the appropriate adoption of NGSI-LD specifications would allow the 
fulfilment of all aspects mentioned by this requirement when constructing new data resources. 
Finally, also the requirement concerning the evaluation of the maturity and the interoperability of the NGSI-LD 
specifications cannot be fulfilled by NGSI-LD since the evaluation procedure within the Common European Data Space 
is still under development. 
7 oneM2M, SAREF and NGSI-LD cooperation to fulfil 
EU Data Act and SReq 
Previous clauses describe how each single asset fulfil the SReq [i.3]. The present clause provides insights and 
recommendations about how the interplay between them may mitigate current gaps. 
First, the interplay between oneM2M and SAREF can satisfy the requests regarding various aspects of semantics that 
come from the SReq [i.3]. In particular, the aspect of managing data tagging since SAREF provides the methodology to 
describe the semantic meaning of data, while oneM2M provides the actual data. This is slightly different than just 
stating that oneM2M allows (multiple) ontologies to be loaded and to perform tagging and queries. Indeed, in the case 
of such an interplay, this aspect becomes more concrete. 
Second, the interplay of oneM2M and NGSI-LD could equip oneM2M datasets with a light-semantic index facilitating 
the discoverability of data managed by oneM2M. 
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 15 
8 Conclusions 
The present document provides a set of guidelines that may drive future activities on oneM2M, SAREF and NGSI-LD 
in the context of their usage concerning the implementation of data spaces that intend to be compliant with the EU Data 
Act [i.2]. 
For each asset, there are reported which points of the SReq [i.3] are already fulfilled and which actions can be put in 
place to fill the current gaps. Of course, by considering the nature of each asset and their purpose, not all aspects of the 
SReq [i.3] can be achieved (e.g. to exploit the outcomes of the ongoing work of CEN/CENELEC on dataset quality 
aspects, to equip the SAREF methodology with such capability). 
Finally, the present document provides an analysis of how the interplay between oneM2M, SAREF and NGSI-LD can 
increase the fulfilment of SReq [i.3]. 
  
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 16 
Annex A: 
Change history 
Date Version Information about changes 
23.04.25 V0.0.1 Initial structure of Early Draft including all headlines and a description for each about the 
intended content of the clause 
24.04.25 V0.1.0 Early Draft provided to TC DATA for acceptance as basis for further drafting 
29.08.25 V0.2.0 Final Draft V0.2.0 provided for approval 
15.09.25 V0.2.1 Incorporation of comments received during the Remote Consensus Phase of V0.2.0 
06.10.25 V0.2.2 Incorporation of further comments received 
 
  
 
ETSI 
ETSI TR 104 410 V1.1.1 (2025-10) 17 
History 
Document history 
V1.1.1 October 2025 Publication""" ;
    onto:mentionsConcept onto:Basic_Co,
        onto:Change_Requests,
        onto:Commission_Implementing_Decision,
        onto:Data_Space,
        onto:Electrotechnical_Standardization,
        onto:European_Trusted_Data_Framework,
        onto:Linked_Data,
        onto:Trusted_Data_Transactions,
        onto:Trustworthiness_Requirements .

onto:European_Commission a onto:DomainConcept ;
    skos:prefLabel "European Commission" .

onto:Knowledge_Graphs a onto:DomainConcept ;
    skos:prefLabel "Knowledge Graphs" .

onto:Menu_Toggle a onto:DomainConcept ;
    skos:prefLabel "Menu Toggle" .

sources:Cloud_and_Edge_Computing__a_different_way_of_using_IT_Brochure___Shaping_Europes_digital_futurepdf_chunk_1 a onto:Chunk ;
    onto:chunkIndex 1 ;
    onto:chunkText """The European Alliance for industrial data,edge and cloud
With the objective of making Europe a frontrunner in ground breaking cloud and edge infrastructure
and services, the European Union decided on an ambitious investment approach. From 2021 to 2028,
co-investments are envisaged through different EU funding instruments, Member States and the private
sector (more information below).
These different investment streams need to be coordinated to ensure that they fit into a coherent and
ambitious industrial roadmap for cloud and edge in Europe and that they meet the specific needs of
demand sectors. This is the objective of the European Alliance for industrial data, edge and cloud.
The Alliance brings together businesses, Member States representatives and relevant experts. The
objective of the Alliance is to facilitate the emergence of a European offering of next generation,
trustworthy, energy efficient and competitive cloud and edge services. These new cloud and edge
capacities should be completely interoperable and offer open, multi-vendor cloud platforms and
services, based on European, international or open source standards.
To foster innovative ecosystems that are conducive to data sharing across businesses and public
organisations, the Alliance is linked to the development of Common European Dataspaces as
envisaged in the European Data Strategy. It will also aim at creating synergies between existing cloud
initiatives, such as Gaia-X and national cloud initiatives, to enhance and broaden their scale and
coverage.
Investing in cloud computing: boostinginnovation potential for businesses inEurope
In the Horizon 2020 funding programme, the EU has invested around €300 million in projects related to
cloud computing and software between 2014 and 2020.
Within the current financial programming period, which runs until 2027, the Commission is stepping up
its effort by funding multi-country projects in order to:
carry out state-of the art research in the area of cloud and edge computing;
fund cloud federation projects, e.g. by interconnecting existing national cloud capacities;
stimulate the deployment of EU cloud and edge services on the market, for example by means of
an EU online marketplace.
Funds will be drawn from the Horizon Europe programme, the Connecting Europe Facility 2, and the
Digital Europe programme.
These financial efforts, which should amount to at least €2bn over that period, will be complemented by
Member State and industry investments. Both will be able to tap into the Invest EU programme (to
facilitate the access to investments in cloud) and the Recovery and Resilience Facility (under the
NextGeneration EU programme) which will help the European Union to overcome the pandemic-
generated crisis.
Building an EU online marketplace for cloudservices
To ensure optimal access to new and innovative cloud and edge services offered in Europe, the
European Commission will support an EU online marketplace for cloud services providing easy
access to an online portal for businesses interested to use cloud services. All services offered on the EU
cloud marketplace will provide adequate reassurance on the compliance with the EU’s rules, norms and
standards in the area of cloud computing. This will provide a trusted gateway to cloud services offered
in Europe.
The EU Cloud Rulebook
To protect European businesses and public organisations, which increasingly depend on cloud
technologies, it is important that cloud and edge services offered in Europe fully comply with the
relevant (general and sectorial) laws, but also with key European self-regulatory norms and standards
regarding security, energy-efficiency, data protection, interoperability and fair competition.
Over the past years, industry stakeholders in Europe have worked together to develop such self-
regulatory norms and standards. The forthcoming EU Cloud Rulebook will provide a comprehensive
catalogue of such schemes and detail the mechanisms to demonstrate compliance with them.
Examples of the EU’s self-regulatory work in this area include:
An EU-wide Cloud cybersecurity certification scheme
Businesses need a certain level of trust from their cloud provider. A single European scheme for cloud
security certification will build trust in cloud computing and provide legal certainty in comparison with
the many different commercial schemes on the market. The EU cybersecurity agency, ENISA, is
finalising a cybersecurity certification scheme that should be ready for market adoption in the course of
2021.
SWIPO Codes of conduct on data portability in the cloud
Cloud users should be able to move easily their data and applications from one provider to another. As
mandated by the Free flow of non-personal data Regulation, cloud users and providers have jointly
worked on codes of conduct on data portability to avoid ‘vendor lock-in’ and facilitate cloud switching.
In accordance with the same Regulation, these ‘SWIPO’ codes of conduct will be evaluated by the
European Commission on the basis of their content and the level of market adoption.
Fair and balanced contractual arrangements
Contractual agreements between cloud service providers and their users determine the conditions
under which cloud and edge services operate. In this context, standard contractual clauses can be used
to even the negotiation power between cloud providers and cloud customers.. Standardisation
(processes) of contractual agreements already exist for Service Level Agreements, for cloud
agreements in the financial sector, for data protection and for general cloud agreements.
Code of Conduct on energy efficiency of data centres
This has shown to be effective when reducing the energy consumption of cloud providers. The
corresponding criteria have been translated into Green Public Procurement criteria to trigger a market-
push for green clouds.
Codes of Conduct on data protection in cloud computing
Data protection is a fundamental right for EU citizens. Several Codes of Conduct have been developed
by industry to ensure that cloud services on the European market can demonstrate compliance with the
GDPR.
Related topics
Cloud Computing Data policy
Print as PDF
Green cloud solutions
In 2018, in the EU, data centres accounted for 2.7% of the electricity demand, a figure expected to
reach 3.2% in 2030. Against this background, the Commission will put forward initiatives to make data
centres climate-neutral, highly energy efficient and sustainable by 2030. These initiatives will review
and complement existing measures such as:
The Energy Efficiency Directive
The Directive dealing with the Waste Electrical and Electronic Equipment
The Green Public Procurement criteria on data centres and cloud services
The Eco-design Directive on servers and data storage products
The Code of Conduct for energy efficiency in data centres
Last update
31 January 2023""" ;
    onto:mentionsConcept onto:Cloud_Computing_Data,
        onto:Cloud_Rulebook_To,
        onto:Common_European_Dataspaces,
        onto:Digital_Europe,
        onto:European_Commission,
        onto:European_Union,
        onto:Horizon_Europe,
        onto:Member_State,
        onto:Public_Procurement,
        onto:Service_Level_Agreements .

sources:Knowledge_Graphs__Redefining_Data_Management_for_the_Modern_Enterprisepdf_chunk_0 a onto:Chunk ;
    onto:chunkIndex 0 ;
    onto:chunkText """BLOG
Knowledge
Graphs:
Redefining Data
Management for
the Modern
Enterprise
November 20, 2024 Knowledge Graph
Reading Time: 9 min
Gergana Petkova
SENIOR CONTENT MANAGER AT GRAPHWISE
All Blog posts#
This post talks about some of the primary problems of
today’s enterprise data management and how
knowledge graphs can solve them
 
In the current data management landscape, enterprises have to deal
with diverse and dispersed data at unimaginable volumes. Among
this complexity of siloed data and content, valuable business insights
and opportunities get lost.
Not surprisingly, the last decade has witnessed a paradigm shift in
enterprise data management, leading to a rise in leveraging
knowledge graphs. Providing unified information access, flexible data
integration and automation of data management tasks, knowledge
graphs have a huge impact on many systems and processes across
various industries.
The value proposition of
knowledge graphs
One of the key advantages of knowledge graphs is their ability to
integrate and unify data from diverse sources. In this way, data is no
longer fragmented or potentially lost across different systems or
departments of an organization. Instead, it can be viewed, explored
and analyzed from a single access point.
Knowledge graphs can also act as a central hub that brings together
not only the actual data, but also metadata. This enables enterprises
to have a holistic view of all information and better understand the
relationships between its different pieces. This is a core component of
most data fabric based implementations.
Knowledge graphs also ensure that  data is always represented
consistently. Regardless of its original format or source, data is
transformed and unified in a way that provides all users with a
common framework for understanding and working with it.
Using semantic modeling techniques (such as ontologies and
controlled vocabularies) allows knowledge graphs to define precise
meanings and relationships between the data. This  solves
ambiguity issues that plague traditional data management systems.
Another unique ability of knowledge graphs is that they can enhance
their proprietary information  by leveraging global knowledge as
context for interpretation. This means that in addition to the data
contained within the graph, external knowledge sources can be
integrated to provide a richer and more comprehensive
understanding of the data.
Rising above the challenges
The value of data depends on our ability to use it effectively. The vast
amounts of data enterprises have today need to be processed,
understood and leveraged in real time. Traditional approaches to
data management are no longer sufficient to handle current
demands. More and more enterprises are realizing the importance of
managing their data differently to reduce costs, improve
maintenance and unlock potential revenue and gain competitive
advantage.
Knowledge graphs provide a viable solution to many data
management challenges. They are suitable for every organization,
regardless of its size, and can easily handle the diversity and lack of
centralized control inherent in modern data ecosystems.
Let’s have a look at some of the challenges enterprise data
management faces today and how knowledge graphs address them.
Multiplicity of data sources and
types
Traditionally, data representation is tightly coupled to specific
formats, which dictate how the data is organized and stored. As a
result, information and communication technology infrastructures are
required to support a wide range of data formats and types spread
across various systems. This also includes legacy systems that are
used in ways beyond their original purposes. 
Knowledge graphs address this problem by providing a higher-level
abstraction for representing data. This allows the format of the data
to be decoupled from its purpose or intended use. It’s a more flexible
approach towards data modeling, where concepts are represented
as nodes and relationships between concepts are represented as
edges. Since the graph structure is not tied to any specific format, it
becomes easier to integrate data from different sources and systems,
which enhances data interoperability. 
Also, as the purpose or use of data changes over time, the underlying
model can be modified without the need to restructure the data
completely. This flexibility enables enterprises to better respond to
changing business needs or data requirements.
Disconnect between data and the
real-world
Relational databases have significant limitations when it comes to
organizing and accessing information in an intuitive manner.
“Relational databases” are an oxymoron. Relationships are not first-
class citizens in such databases. Their rigid tabular structure fails to
capture the inherent complexities and rich interconnectedness of
real-life data, which often leads to compromises, simplifications and
impedance mismatch. 
As a result, traditional data management solutions often rely on
human efforts to organize real-world information in a way that
conforms to the available software. This requires extensive upfront
planning and schema design to determine how the data would be
stored, connected and queried.
In contrast, knowledge graphs organize information intuitively. By
enabling an expressive and flexible representation of data, graph
structures capture the relationships between different pieces of
information and provide richer context. This empowers enterprises to
work with data in a way that closely mirrors their understanding of the
domain. It also leads to better insights, decision-making and
utilization of data resources. 
According to McKinsey, data professionals in most organizations
spend 25-30% of their time finding and searching for relevant data.
Knowledge graphs help semantically discover, find and explore
relevant data,  using  Linked Data  principles. By leveraging shared
vocabularies and standards, data can be semantically linked across
different sources making it possible to traverse across the
connections to find the information they need.
Lack of meaning
Many enterprises fail to make proper use of their data because it’s
represented in a way that obscures its meaning and the underlying
modeling assumptions. This restricts the usability of the data to
systems where these assumptions are explicitly hardcoded. It also
makes it difficult to integrate data with other systems or leverage it in
different contexts.
The representation of data in a knowledge graph conforms to a
formal meaning that can be interpreted unambiguously by both
humans and machines. This enables a clear understanding of its
content. This formalism of semantics powers automated reasoning,
which leads to new data-driven insights as well as identifying hidden
patterns or relationships.
By leveraging the semantic richness of knowledge graphs, enterprises
can better perform important tasks such as answering complex
queries, making predictions or generating recommendations. They
can track data as it flows through the enterprise, monitor its quality,
discover errors, and trace them to the source, reducing bad data
quality and data duplication. Knowledge graphs provide high-quality
data based on enriched and linked metadata.
Rigid and brittle schemas
The traditional approach in data management calls for defining an
exhaustive data schema upfront, based on a presumed
understanding of all requirements. However, it’s next to impossible to
fully grasp the intricacies of a business case and to capture all
possible attributes and relationships in a single schema from the
outset.
In addition, the dynamic nature of businesses and evolving data
needs make it inconceivable to expect a single schema to remain
applicable and valid for long periods. The constantly changing
technologies, market trends and business requirements demand
adaptable data management approaches.
The good news is that knowledge graphs have the ability to model
data in a flexible and extensible manner. As new data requirements
arise, they allow adding or modifying schema elements, without a
complete overhaul of the existing structure. This enables enterprises
to keep pace with evolving business needs and future demands.
Data silos
Data silos are one of the biggest hurdles to using data efficiently and
enterprises often revert to using point-to-point data integration as a
quick workaround. However, each integration significantly increases
the development time, complexity, resources and effort, slowing down
crucial business processes that rely on timely and accurate
information.
Most importantly, this approach often fails to address the
fundamental problem. Data silos occur when data is isolated and
confined within specific systems or departments. Such integrations
only establish direct connections between selected systems, leading
to a fragmented integration landscape.
The interconnected nature of knowledge graphs, on the other hand,
allows enterprises to reuse their existing data assets more effectively
and efficiently as well as to easily incorporate external third-party
data sources. This empowers them to leverage their proprietary
knowledge into the context of global information and enhance
business analysis, decision-making and innovation.
In addition, the use of open standards when building knowledge
graphs not only ensures interoperability and facilitates the integration
of data from multiple domains, but also avoids proprietary formats
and vendor lock-in. They connect entities between records in the
different datasets to get a 360-degree view. Knowledge graphs excel
in providing an entity-centric view that encompasses data across
heterogeneous data sources
Expensive data management
As we already discussed, dealing with various data formats and
types, reliance on manual efforts, and never-ending data integration
projects puts a strain on the overall cost and timelines of enterprise
data management.
Knowledge graph approaches offer many cost-effective benefits. For
example, the ability to reuse data allows enterprises to better utilize
their existing data assets across different applications, projects and
teams. Bootstrapping systems with Linked Open Data reduces the
costs of data acquisition and maintenance. Flexible graph models
eliminate the need for exhaustive (and expensive!), future-proof
schema designs and redesigns. The list can go on and on.
Limited time and resources
For most enterprises across all industries, the majority of data
remains untapped, invisible, inaccessible and only a small fraction of
it is being actively used. This disparity between the vast amount of
data and the limited capacity to process it hinders their ability to
extract meaningful information and derive actionable insights.
By capturing the rich semantic relationships between concepts,
knowledge graphs enable inference capabilities, complex analysis
and discovery of hidden patterns. They form a robust backbone for
every artificial intelligence and analytics platform and empower users
to uncover insights locked in the data and do it in real time.
To wrap it up
The abundance of data requires a data model that is aligned with our
complex understanding of information, domain and context. To make
data smart, we need to abandon inflexible data schemas and choose
data models that can represent the real world with its rich and
intricate relationships. When this is done in a machine-readable
format with formal semantics, it enables automated reasoning, which
complements and facilitates human expertise and decision-making.
Semantic knowledge graphs fulfill these requirements and find
applications in many data and information-intensive services across
various industries. By adopting them as a foundational component of
their data management strategies, enterprises can navigate the
complexities of the modern data landscape and make their data and
decisioning smarter, faster and data-driven.
Want to move to the next level with a Graph Center of Excellence?
←  Previous Next →
Table of Contents
The value proposition of knowledge graphs
Rising above the challenges
Multiplicity of data sources and types
Disconnect between data and the real-world
Lack of meaning
Rigid and brittle schemas
Data silos
Expensive data management
Limited time and resources
To wrap it up
1.
2.
2.1.
2.2.
2.3.
2.4.
2.5.
2.6.
2.7.
3.""" ;
    onto:mentionsConcept onto:All_Blog,
        onto:Gergana_Petkova,
        onto:Graph_Center,
        onto:Knowledge_Graph,
        onto:Knowledge_Graphs,
        onto:Linked_Data,
        onto:Modern_Enterprise,
        onto:Previous_Next,
        onto:Reading_Time,
        onto:Redefining_Data_Management .

sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_2 a onto:Chunk ;
    onto:chunkIndex 2 ;
    onto:chunkText """[ Contact us ](https://www.ontotext.com/contact/)[Contact us](https://www.ontotext.com/contact/)

[![Ontotext](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20168%2048'%3E%3C/svg%3E)![Ontotext](https://www.ontotext.com/wp-content/uploads/2024/11/Ontotext-A-Graphwise-company.svg)](https://www.ontotext.com/)

[ Ontotext ](https://www.ontotext.com/)

Main Menu

* [ Products ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * [ Products Overview![mm-ast-icon-55](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-55](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg) ](https://www.ontotext.com/products/)Menu Toggle
      * [ ![mm-ast-icon-64032](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-64032](https://www.ontotext.com/wp-content/uploads/2024/09/icon-graphdb.svg)GraphDB ](https://www.ontotext.com/products/graphdb/)

Link diverse data, index it for semantic search and enrich it via text analysis to build big knowledge graphs

Menu Toggle
        * [ ![mm-ast-icon-57577](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-57577](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Release notes](https://graphdb.ontotext.com/documentation/11.0/)
        * [ ![mm-ast-icon-57578](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2018'%3E%3C/svg%3E)![mm-ast-icon-57578](https://www.ontotext.com/wp-content/uploads/2024/09/icon-inbox.svg)Quick start guide](https://graphdb.ontotext.com/documentation/11.0/how-to-install-graphdb.html?_gl=1*e0acjk*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNTkxOS4wLjAuMA..)
        * [ ![mm-ast-icon-57579](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-57579](https://www.ontotext.com/wp-content/uploads/2024/09/icon-book.svg)Documentation](https://graphdb.ontotext.com/documentation/11.0/?_gl=1*2lq5zz*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNjAwMy4wLjAuMA..)
      * [ ![mm-ast-icon-57505](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-57505](https://www.ontotext.com/wp-content/uploads/2024/09/icon-metadata-studiosvg.svg)Metadata Studio ](https://www.ontotext.com/products/ontotext-metadata-studio/)

Easily integrate and evaluate any text analysis service against your ground truth data

Menu Toggle
        * [ ![mm-ast-icon-57597](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-57597](https://www.ontotext.com/wp-content/uploads/2024/09/icon-settings.svg)Installation](https://platform.ontotext.com/omds/installation.html?_gl=1*1a55rrd*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
        * [ ![mm-ast-icon-57598](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-57598](https://www.ontotext.com/wp-content/uploads/2024/09/icon-monitor-alt.svg)Configuration](https://platform.ontotext.com/omds/configuration.html?_gl=1*1a55rrd*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
        * [ ![mm-ast-icon-57599](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-57599](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Release notes](https://platform.ontotext.com/omds/release-notes.html?_gl=1*2s09ev*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
      * [ ![mm-ast-icon-57589](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2022'%3E%3C/svg%3E)![mm-ast-icon-57589](https://www.ontotext.com/wp-content/uploads/2024/09/icon-semantic-objects.svg)Ontotext Semantic Objects ](https://www.ontotext.com/products/semantic-objects/)

Organize your information into enterprise knowledge graphs for synergistic data management and analytics

Menu Toggle
        * [ ![mm-ast-icon-57594](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-57594](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Release notes](https://platform.ontotext.com/semantic-objects/release-notes.html?_gl=1*173mruu*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNjk0MC4wLjAuMA..)
        * [ ![mm-ast-icon-57595](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2018'%3E%3C/svg%3E)![mm-ast-icon-57595](https://www.ontotext.com/wp-content/uploads/2024/09/icon-inbox.svg)Quick start guide](https://platform.ontotext.com/semantic-objects/installation/?_gl=1*173mruu*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNjk0MC4wLjAuMA..)
        * [ ![mm-ast-icon-57596](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2020'%3E%3C/svg%3E)![mm-ast-icon-57596](https://www.ontotext.com/wp-content/uploads/2024/09/icon-book.svg)Documentation](https://platform.ontotext.com/semantic-objects/)
      * [ ![mm-ast-icon-57506](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2018'%3E%3C/svg%3E)![mm-ast-icon-57506](https://www.ontotext.com/wp-content/uploads/2024/09/icon-refine.svg)Ontotext Refine ](https://www.ontotext.com/products/ontotext-refine/)

Automate converting messy string data into a knowledge graph with Ontotext’s free application

Menu Toggle
        * [ ![mm-ast-icon-57600](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-57600](https://www.ontotext.com/wp-content/uploads/2024/09/icon-settings.svg)Installation](https://platform.ontotext.com/ontorefine/install-migrate.html?_gl=1*2s09ev*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
        * [ ![mm-ast-icon-57601](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-57601](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Release notes](https://platform.ontotext.com/ontorefine/release-notes.html?_gl=1*ul01od*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
        * [ ![mm-ast-icon-57602](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2020'%3E%3C/svg%3E)![mm-ast-icon-57602](https://www.ontotext.com/wp-content/uploads/2024/09/icon-refresh.svg)Data loading](https://platform.ontotext.com/ontorefine/loading-data-using-ontorefine.html?_gl=1*ul01od*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
        * [ ![mm-ast-icon-57603](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2021%2022'%3E%3C/svg%3E)![mm-ast-icon-57603](https://www.ontotext.com/wp-content/uploads/2024/09/icon-data.svg)RDF-izing tabular data](https://platform.ontotext.com/ontorefine/rdfizing.html?_gl=1*ul01od*_ga*MTkyNDU5Nzc2MS4xNzI0OTM5MTYx*_ga_HGSKWBWCRK*MTcyNTMzNTg5My40LjEuMTcyNTMzNzQ3NS4wLjAuMA..)
    * [ Architecture patterns![mm-ast-icon-57580](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-57580](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg) ](https://www.ontotext.com/architecture-patterns/)Menu Toggle
      * [ ![mm-ast-icon-57583](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2012%2012'%3E%3C/svg%3E)![mm-ast-icon-57583](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-down.svg)Generative AI](https://www.ontotext.com/architecture-patterns/?p=generative-ai)
      * [ ![mm-ast-icon-57582](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2012%2012'%3E%3C/svg%3E)![mm-ast-icon-57582](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-down.svg)Domain Knowledge Graph](https://www.ontotext.com/architecture-patterns/?p=domain-knowledge-graph)
      * [ ![mm-ast-icon-57581](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2012%2012'%3E%3C/svg%3E)![mm-ast-icon-57581](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-down.svg)Data Fabric](https://www.ontotext.com/architecture-patterns/?p=data-fabric)
      * [ ![mm-ast-icon-57584](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2012%2012'%3E%3C/svg%3E)![mm-ast-icon-57584](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-down.svg)Graph Analytics](https://www.ontotext.com/architecture-patterns/?p=graph-analytics)
      * [ ![mm-ast-icon-57585](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2012%2012'%3E%3C/svg%3E)![mm-ast-icon-57585](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-down.svg)Semantic Content Hub](https://www.ontotext.com/architecture-patterns/?p=semantic-content-hub)
  * [ Solutions ](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#)Menu Toggle
    * [ Solutions Overview![mm-ast-icon-60484](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2014%2014'%3E%3C/svg%3E)![mm-ast-icon-60484](https://www.ontotext.com/wp-content/uploads/2024/09/icon-arrow-orange-right.svg)](https://www.ontotext.com/solutions/)
    * Life Sciences Accelerators Menu Toggle
      * [ ![mm-ast-icon-62732](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-62732](https://www.ontotext.com/wp-content/uploads/2024/09/icon-circles.svg)LinkedLifeData Inventory](https://www.ontotext.com/solutions/healthcare-and-life-sciences/linked-life-data-inventory/)

Get 200+ semantics ready biomedical datasets covering various life sciences domains

* [ ![mm-ast-icon-62733](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2022'%3E%3C/svg%3E)![mm-ast-icon-62733](https://www.ontotext.com/wp-content/uploads/2024/09/icon-rocket.svg)AI Powered Target Discovery](https://www.ontotext.com/solutions/ontotexts-target-discovery/)

Expedite discovering efficient drug candidates from scientific publications, patents, and clinical trials

* By Industry Menu Toggle
      * [ ![mm-ast-icon-57509](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2023%2020'%3E%3C/svg%3E)![mm-ast-icon-57509](https://www.ontotext.com/wp-content/uploads/2024/09/icon-activity.svg)Healthcare and Life Sciences](https://www.ontotext.com/solutions/healthcare-and-life-sciences/)

Discover new drug targets faster, enable drug safety analytics and regulatory intelligence with ease

* [ ![mm-ast-icon-57512](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2015%2018'%3E%3C/svg%3E)![mm-ast-icon-57512](https://www.ontotext.com/wp-content/uploads/2024/09/icon-bar-chart.svg)Financial Services](https://www.ontotext.com/solutions/financial-services/)

Enhance investment intelligence, inventory management, and regulatory compliance with better data insights

* [ ![mm-ast-icon-57510](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-57510](https://www.ontotext.com/wp-content/uploads/2024/09/icon-settings.svg)Manufacturing](https://www.ontotext.com/solutions/manufacturing/)

Optimize manufacturing processes with advanced data integration, analysis, and predictive insights

* [ ![mm-ast-icon-59015](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2023%2021'%3E%3C/svg%3E)![mm-ast-icon-59015](https://www.ontotext.com/wp-content/uploads/2024/09/icon-park-city.svg)AECO & Infrastructure](https://www.ontotext.com/solutions/aeco-infrastructure/)

Optimize your industrial processes and product development

* [ ![mm-ast-icon-57513](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2022%2023'%3E%3C/svg%3E)![mm-ast-icon-57513](https://www.ontotext.com/wp-content/uploads/2024/09/icon-megaphone.svg)Media & Publishing](https://www.ontotext.com/solutions/media-and-publishing/)

Improve engagement, discoverability, and personalized recommendations for media and publishing industries

* [ ![mm-ast-icon-57511](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2023%2020'%3E%3C/svg%3E)![mm-ast-icon-57511](https://www.ontotext.com/wp-content/uploads/2024/09/icon-folder.svg)Public Sector](https://www.ontotext.com/solutions/public-sector/)

Unlock intelligent public services and applications for government and defense

* By Application Menu Toggle
      * [ ![mm-ast-icon-60482](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2024%2024'%3E%3C/svg%3E)![mm-ast-icon-60482](https://www.ontotext.com/wp-content/uploads/2024/10/icon-cpu.svg)Knowledge Graph Applications](https://www.ontotext.com/knowledge-graph-applications/)

Enable unified data access across systems with the flexible, precise structure of a knowledge graph model

* [ ![mm-ast-icon-60483](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2018%2022'%3E%3C/svg%3E)![mm-ast-icon-60483](https://www.ontotext.com/wp-content/uploads/2024/09/icon-file-text.svg)Text Analysis for Content Management](https://www.ontotext.com/solutions/text-analysis-for-content-management/)

Interlink your organization’s data and content by using knowledge graph powered natural language processing""" ;
    onto:mentionsConcept onto:By_Application_Menu_Toggle,
        onto:Content_Management,
        onto:Knowledge_Graph_Applications,
        onto:Life_Sciences,
        onto:Life_Sciences_Accelerators_Menu,
        onto:Menu_Toggle,
        onto:Metadata_Studio,
        onto:Ontotext_Semantic_Objects,
        onto:Public_Sector,
        onto:Semantic_Content_Hub .

sources:LinkedInBlog_Posts_Set_1_of_3_EU_Data_Act_Linked_Data_chunk_2 a onto:Chunk ;
    onto:chunkIndex 2 ;
    onto:chunkText """1. **Technical Complexity (Silos and Swamps):** Cloud data lakes, using a **"schema-on-read"** strategy, often become **"data swamps"** because they lack descriptive metadata and robust governance. Data integration among heterogeneous sources relies on fragile, resource-intensive **N:M (many-to-many) conversions or extensive ETL processes**.
2. **Economic Complexity (Opaque Cost and Lock-in):** Expenditure on compute, storage, and data transfer is often opaque and difficult to optimize, leading to vendor dependency and the risk of **vendor lock-in** on proprietary formats and platforms.

These issues mean that while these platforms can store the volume of data generated, they are structurally ill-equipped to handle the *legal and semantic requirements* for compulsory data sharing and reusability.

**3. Linked Data: The Blueprint for Mandated Interoperability**

Linked Data (LOD) and Knowledge Graphs provide the structural solution required by the Data Act. The law directly supports principles the Linked Data community has championed for years:

* **Data Structure:** Data must be **structured, machine-readable, and reusable**. This moves data beyond raw storage into formats like **RDF**, which simplifies integration by facilitating **1:N relationships** using unique URLs as reference points.
* **Metadata:** Metadata must describe **meaning, not just format**. This semantic enrichment is essential for building digital trust and ensuring data context is maintained when data is shared across organizational boundaries.
* **Interconnection:** Systems must **interconnect through open standards rather than isolated APIs**. Utilizing standards like **RDF, OWL, SHACL, and DCAT-AP** makes this vision practical, turning the "Web of Data" into a single, massive data-space.

**4. Wistor: The Native Alternative to Cloud Middleware**

Wistor is designed specifically to address the failures of applying a semantic layer on top of traditional databases. Wistor is the **only native linked data platform** built from the ground up on LOD principles:""" ;
    onto:mentionsConcept onto:Cloud_Middleware,
        onto:Data_Act,
        onto:Data_Structure,
        onto:Economic_Complexity,
        onto:Knowledge_Graphs,
        onto:Linked_Data,
        onto:Mandated_Interoperability,
        onto:Opaque_Cost,
        onto:Technical_Complexity .

sources:RDF_Levels_the_Advantages_of_Labeled_Property_Graphs_Keeps_Three_Key_Benefits_Standards_Semantics_Interoperability_chunk_7 a onto:Chunk ;
    onto:chunkIndex 7 ;
    onto:chunkText """Ontotext USA, Inc.   
Select Office Suites Flatiron   
1115 Broadway, 16 Madison Square West  
Suite 1200, New York, NY 10010, USA   
[+1 929 239 0659](tel:+1 929 239 0659)

Join our newsletter to stay up to date on features and releases.

First name*

Last name*

Email*

* I confirm that I have read and agree to the terms of [Ontotext's Privacy Policy](https://www.ontotext.com/privacy-policy/) and consent to the processing of my personal data as described therein.

*

Products

Resources

* [GraphDB](https://www.ontotext.com/products/graphdb/)
  * [Metadata Studio](https://www.ontotext.com/products/ontotext-metadata-studio/)
  * [Semantic Objects](https://www.ontotext.com/products/semantic-objects/)
  * [Refine](https://www.ontotext.com/products/ontotext-refine/)

Architecture patterns

* [Generative AI](https://www.ontotext.com/architecture-patterns/?p=generative-ai)
  * [Domain Knowledge Graph](https://www.ontotext.com/architecture-patterns/?p=domain-knowledge-graph)
  * [Data Fabric](https://www.ontotext.com/architecture-patterns/?p=data-fabric)
  * [Graph Analytics](https://www.ontotext.com/architecture-patterns/?p=graph-analytics)
  * [Semantic Content Hub](https://www.ontotext.com/architecture-patterns/?p=semantic-content-hub)

[Blog](https://www.ontotext.com/blog/)

Solutions

* [Healthcare and Life Sciences](https://www.ontotext.com/solutions/healthcare-and-life-sciences/)
  * [Manufacturing](https://www.ontotext.com/solutions/manufacturing/)
  * [Media & Publishing](https://www.ontotext.com/solutions/media-and-publishing/)
  * [Financial Services](https://www.ontotext.com/solutions/financial-services/)
  * [AECO & Infrastructure](https://www.ontotext.com/solutions/aeco-infrastructure/)
  * [Public Sector](https://www.ontotext.com/solutions/public-sector/)

Services

* [Strategy and Technology Consulting](https://www.ontotext.com/services/semantic-technology-consulting/)
  * [Semantic Data Modelling](https://www.ontotext.com/services/semantic-data-modeling/)
  * [Text Analysis](https://www.ontotext.com/services/text-mining-and-text-analytics/)
  * [GraphDB Development Support](https://www.ontotext.com/services/graphdb-development-support/)
  * [GraphDB Managed Services](https://www.ontotext.com/services/graphdb-managed-services/)
  * [Trainings](https://www.ontotext.com/services/semantic-technology-trainings/)

Knowledge Hub

Resources

* [AI in Action](https://www.ontotext.com/ai-in-action/)
  * [Case studies](https://www.ontotext.com/knowledge-hub/case-studies/)
  * [White papers](https://www.ontotext.com/knowledge-hub/white_paper/)
  * [Fundamentals](https://www.ontotext.com/knowledge-hub/fundamentals/)
  * [Demo services](https://www.ontotext.com/knowledge-hub/demoservices/)
  * [Videos](https://www.ontotext.com/knowledge-hub/videos/)
  * [Publications](https://www.ontotext.com/knowledge-hub/publications/)
  * [GraphRAG](https://graphrag.info/)

News and webinars

* [News](https://www.ontotext.com/company/news/)
  * [Webinars](https://www.ontotext.com/knowledge-hub/webinars/)

Company

* [About us](https://www.ontotext.com/about-us/)
  * [Customers](https://www.ontotext.com/company/customers/)
  * [Careers](https://www.ontotext.com/company/careers/)
  * [Our team](https://www.ontotext.com/company/team/)
  * [Partners](https://www.ontotext.com/company/partners/)
  * [Research projects](https://www.ontotext.com/research-projects/)

[Blog](https://www.ontotext.com/blog/)

© Copyright 2025. All rights reserved

* [Privacy Policy](https://www.ontotext.com/privacy-policy/)
  * [Code of Ethics](https://www.ontotext.com/code-of-ethics/)
  * [Equal Opportunity Policy](https://www.ontotext.com/equal-opportunity-policy/)
  * [Corporate Social Responsibility Policy](https://www.ontotext.com/corporate-social-responsibility-policy/)
  * [Anti-slavery and Human Trafficking Policy](https://www.ontotext.com/anti-slavery-and-human-trafficking-policy/)

Scroll to Top

![](https://www.facebook.com/tr?id=277424705943253&ev=PageView
&noscript=1) ![](https://dc.ads.linkedin.com/collect/?pid=12844&fmt=gif) ![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/saved_resource)

![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/0)

Copy link

✓

Thanks for sharing!

Find any service

[AddToAny](https://www.addtoany.com/ "Share Buttons")

[More…](https://www.ontotext.com/knowledgehub/webinars/rdf-three-key-benefits/?utm_source=chatgpt.com#addtoany "Show all")

![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/adsct)![](./RDF Levels the Advantages of Labeled Property Graphs & Keeps Three Key Benefits_ Standards, Semantics & Interoperability _ Ontotext_files/adsct\\(1\\))""" ;
    onto:mentionsConcept onto:Corporate_Social_Responsibility_Policy,
        onto:Keeps_Three_Key,
        onto:Life_Sciences,
        onto:Managed_Services,
        onto:Metadata_Studio,
        onto:Privacy_Policy,
        onto:Public_Sector,
        onto:Semantic_Content_Hub,
        onto:Semantic_Data_Modelling,
        onto:Share_Buttons .

sources:node_12633_printable_pdfpdf_chunk_1 a onto:Chunk ;
    onto:chunkIndex 1 ;
    onto:chunkText """Issues addressed
Following the general provisions (Chapter I) which set out the scope of the regulation and deﬁne key terms, the Data Act is
structured into six main chapters: 
Chapter II on business-to-business and business-to-consumer data sharing in the context of IoT: users of IoT objects
can access, use and port data that they co-generate through their use of a connected product.
Chapter III on business-to-business data sharing: this clariﬁes the data-sharing conditions wherever a business is obliged
by law, including through the Data Act, to share data with another business.
Chapter IV on unfair contractual terms: these provisions protect all businesses, in particular SMEs, against unfair
contractual terms imposed on them.
Chapter V on business-to-government data sharing: public sector bodies will be able to make more evidence-based
decisions in certain situations of exceptional need through measures to access certain data held by the private sector.
Chapter VI on switching between data processing services: providers of cloud and edge computing services must meet
minimum requirements to facilitate interoperability and enable switching.
Chapter VII on unlawful third country government access to data: non-personal data stored in the EU is protected
against unlawful foreign government access requests.
Chapter VIII on interoperability: participants in data spaces must fulﬁl criteria to allow data to ﬂow within and between data
spaces. An EU repository will lay down relevant standards and speciﬁcations for cloud interoperability.
Chapter IX on enforcement: Member States must designate one or more competent authority(ies) to monitor and enforce the
Data Act. Where more than one authority is designated, a ‘data coordinator’ must be appointed to act as the single point of
contact at the national level.
Chapter II: Business-to-business and business-
to-consumer data sharing in the context of
the IoT market
Why?
A key objective of the Data Act is to create fairness in the data economy and empower users to reap value from the data
they generate using the connected products that they own, rent or lease.
The Data Act enables users of connected products (e.g. connected cars, medical and ﬁtness devices, industrial or agricultural
machinery) and related services (i.e. anything that would make a connected product behave in a speciﬁc manner, such as an
app to adjust the brightness of lights, or to regulate the temperature of a fridge) to access the data that they co-create by using
the connected products/ related services.
The availability of such data will signiﬁcantly impact the economy. For example, data generated by connected products and
related services can be used to boost aftermarket and ancillary services as well as to create entirely new services, beneﬁting
both businesses and consumers. 
Examples of connected products: consumer products (e.g. connected cars, health monitoring devices, smart-home devices),
other products (e.g. planes, robots, industrial machines).
Example of a related service: a user buys a washing machine and installs an application that allows them to measure the
environmental impact of the washing cycle based on the data from the diﬀerent sensors inside the machine and adjusts the
cycle accordingly. This application would be considered a related service.
Examples of aftermarket and ancillary services: repair and maintenance services, data-based insurance.
Types of data in scope
Chapter II of the Data Act on business-to-business and business-to-consumer data sharing applies to all raw and pre-
processed data generated from the use of a connected product or a related service that is readily available to the
data holder (e.g. manufacturer of a connected product/ provider of a related service), in other words data that can be easily
accessed without disproportionate eﬀort, going beyond a simple operation. This applies to both personal and non-personal data,
including relevant metadata.
Such data includes data collected from a single sensor or a connected group of sensors, such as temperature, pressure, ﬂow
rate, audio, pH value, liquid level, position, acceleration or speed.
Inferred or derived data and content (e.g. highly enriched data, audiovisual material) are out of scope. Furthermore, the Data
Act is without prejudice to the laws on the protection of intellectual property rights
(https://commission.europa.eu/business-economy-euro/doing-business-eu/intellectual-property-rights_en).
For example, if a user watches a ﬁlm on their connected TV, the ﬁlm itself is not within scope but data on the brightness of the
screen is within scope.
In practice
Chapter II of the Data Act allows users (i.e. any legal or natural person who owns, rents or leases a connected product) to
access the data that they generate through their use of the connected product or related service. If the user wishes to share this
data with another entity or individual (‘third party’), they can either do so directly or they can ask the data holder to share it
with a third party of their choice (excluding gatekeepers under the Digital Markets Act
(https://digital-markets-act.ec.europa.eu/legislation_en)). The data holder is typically the company that makes the connected
product or that provides a related service. A data holder must have a contract with the user (e.g. sales contract, rental contract,
related service contract, etc.) deﬁning the rights regarding the access, use and sharing of the data that is generated by the
connected product or related service. It is important to note that the data holder cannot use any non-personal data generated
by the product without the user’s agreement.
By way of example, and bearing in mind that the relevant contract determines the exact roles:
A company operates a bulldozer: the data holder would typically be the bulldozer manufacturer, and the user would be
the company that operates the bulldozer.  
If someone buys a connected fridge and downloads an app that helps them to regulate the optimal temperature for the
content of the fridge, there would potentially be two data holders, namely the entity that placed the fridge on the market
and the entity oﬀering the related service (the app), and only the one user (the owner of the fridge).
The Data Act incudes several mechanisms to make it easier for users to be able to make use of these provisions: data holders
must provide the user with information on the type of data that they will generate when using the connected product or related
service (including the volume, collection frequency, etc.); users should be able to request access to the data through a simple
process, and; data holders must make the data available to users for free.
Limitations on the use of the data
So as not to deter businesses from investing in data-generating products, the data obtained cannot be used to develop a
competing connected product. The Data Act does not prohibit competition in related or aftermarket services.
Furthermore, there is no obligation under the Data Act for a data holder to share data with third parties based outside the EU.
The Data Act is fully compliant with data protection rules, notably the GDPR. Where the user is not the data subject whose
data is being requested, personal data can only be made available if there is a valid legal basis (e.g. consent). This is an
important consideration as the co-generated data often contains both personal and non-personal data, which may be diﬃcult to
separate.  
It incentivises the development of connected products and services based on new ﬂows of data, which is of particular value to
smaller companies. In addition, micro and small companies, as manufacturers or providers of related services, are not
subject to the same obligations as larger companies.
To protect trade secrets without undermining the goal of the Data Act to make more data available, the data holder and the
user/ third party may agree on certain measures to preserve the conﬁdentiality of the trade secrets. Where these measures are
not respected, the data holder may withhold or suspend the data sharing. The data holder may only refuse to share data where
it can demonstrate that it is highly likely to suﬀer serious economic damage from the disclosure of trade secrets.
The data holder and user may agree to limit data sharing if there is a risk that the security requirements of the connected
product could be undermined, resulting in serious adverse eﬀects to the health, safety or security of people. Such
requirements must be laid down in EU or national law.
If the data holder suspends, withholds or refuses to share data on the grounds of trade secrets protection or security
requirements, it must notify the national competent authority. Users may challenge such a decision, either in front of the
competent court or tribunal of a Member State, via a complaint with the competent authority or upon agreement with the data
holder in front of a dispute settlement body.
Chapter III: Rules on mandatory business-to-
business data sharing
Why?
The Data Act introduces rules for situations where a business (‘data holder’) has a legal obligation under EU or national law to
make data available to another business (‘data recipient’), including in the context of IoT data. Notably, the data-sharing terms
and conditions must be fair, reasonable and non-discriminatory.
As an incentive to data sharing, data holders that are obliged to share data may request ‘reasonable compensation’ from the
data recipient.
Types of data in scope
Chapter III of the Data Act applies to all data (both personal and non-personal) held by a business, including situations covered
in Chapter II of the Data Act.
In practice
Data holders may request reasonable compensation for making the data available to a data recipient. This could include
costs incurred for making the data available as well as technical costs related to dissemination and storage. However, micro
companies, SMEs and non-proﬁt research organisations cannot be charged more than the costs incurred for making the data
available.
In order to protect data holders, the Data Act includes a non-exhaustive list of measures to remedy situations where a third
party or user has unlawfully accessed or used data. For example, a data holder could require that an infringing party stops
producing the product in question or destroys the data that it has unlawfully obtained, or it could seek compensation.
Any data-sharing obligations that precede the Data Act remain unaﬀected. Obligations in future (sectoral) legislation should
be aligned with the provisions of Chapter III of the Data Act.
Chapter IV: Unfair contractual terms
Why?
Contractual freedom is central to business-to-business relationships. However, the Data Act aims to protect all European
businesses seeking to acquire data, in particular SMEs, against unfair contractual terms through its measures to intervene in
situations where, for example, one of the businesses is in a stronger bargaining position (e.g. due to its market size) and
imposes a non-negotiable term (‘take-it-or-leave-it’) related to data access and use on the other.
Types of data in scope
These rules cover all data, both personal and non-personal, held by a private entity that is accessed and used based on a
contract between businesses.
In practice
Unilaterally imposed take-it-or-leave-it terms may, where they relate to making data available, be subject to an unfairness test.
The Data Act establishes a non-exhaustive list of terms that are always considered to be unfair (e.g. that would exclude or
limit the liability of the party that unilaterally imposed the term for intentional acts or gross negligence) and of terms that are
presumed to be unfair (e.g. that would inappropriately limit remedies in the case of non-performance of contractual
obligations or liability in the case of a breach of those obligations, or extend the liability of the enterprise upon whom the term
has been unilaterally imposed). If a term is considered to be unfair, it is no longer valid – where possible, it is simply severed
from the contract. If it is presumed to be unfair, the entity that imposed the term can try to demonstrate that the term is not
unfair.
Chapter V: Business-to-government data
sharing
Why?
Data held by private entities may be essential for a public sector body to undertake a task of public interest. Chapter V of the
Data Act allows public sector bodies to access such data, under certain terms and conditions, where there is an exceptional
need. The latter refers to a situation which is unforeseeable and limited in time, where the data held by a private entity are
necessary for the performance of the public interest task, notably to improve evidence-based decision making. Situations of
exceptional need include both public emergencies (such as major natural or human-induced disasters, pandemics and
cybersecurity incidents) and non-emergency situations (for example, aggregated and anonymised data from drivers’ GPS
systems could be used to help optimise traﬃc ﬂows).
The Data Act will ensure that public authorities have access to such data in a timely and reliable manner, without imposing an
undue administrative burden on businesses.
Types of data within scope
Under Chapter V, all data are in scope, with a focus on non-personal data.
Chapter V of the Data Act on business-to-government data sharing diﬀerentiates between two scenarios:
In order to respond to a public emergency, a public sector body should request non-personal data. However, if this is
insuﬃcient to respond to the situation, personal data may be requested. Where possible, this data should be anonymised
by the data holder.    
In non-emergency situations, public sector bodies may only request non-personal data.
Key stakeholders
The entities entitled to request data include public sector bodies of the Member States as well as certain EU Institutions, bodies
and agencies. These entities may also share the data with research-performing and -funding organisations under certain
conditions.
In the context of business-to-government requests, data holders are typically private entities, but may also include public
undertakings.
In practice
A public sector body may, under certain conditions, oblige a data holder to make available certain data without undue delay to
respond to a public emergency. The Data Act deﬁnes a public emergency; but its existence is determined according to national
or EU procedures or laws.
For exceptional needs which are not related to a public emergency, a public sector body may request non-personal data to fulﬁl
a speciﬁc task that is in the public interest and that has been provided by law, if the public sector body can prove that it has not
been able to access the data via other means.
In both cases (emergency and non-emergency), requests must respect a number of strict principles and conditions. For
example, requests must be speciﬁc, transparent and proportionate, trade secrets must be protected, and the data must be
deleted once it is no longer needed.
The table below summaries what businesses may request for providing data to a public sector body in this context.
 
Compensation for making data available under Chapter V of the Data Act
 Businesses other than micro and small
companies can ask for: Micro and small companies can ask for:
Public emergency
Businesses may ask for their data contribution to be
acknowledged and publicly recognised by the receiving
public sector body
Reasonable remuneration not exceeding
technical and organisational costs incurred +
public acknowledgement, upon request
Non-emergency
situation
Reasonable remuneration not exceeding technical and
organisational costs incurred (except for the
production of oﬃcial statistics)
N/A (exempt from the obligation to provide
data)
 
To minimise the burden on businesses, the same data cannot be requested more than once (‘once-only principle’) by more
than one public sector body. For this reason, all requests must be made publicly available by the data coordinator (unless there
is a security concern).
Chapter VI: Switching between data
processing services
Why?
In order to ensure a competitive market in the EU, customers of data processing services (including cloud and edge services)
should be able to switch seamlessly from one provider to another. However, customers currently face a number of barriers to
this, including high charges associated with, for example, data egress, lengthy procedures and a lack of interoperability between
providers that can result in a loss of data and applications.
The Data Act will make switching free, fast and ﬂuid. This will beneﬁt customers, who can freely choose the services that best
meet their needs, as well as providers, who will beneﬁt from a larger pool of customers.
Scope
Chapter VI of the Data Act applies to providers of data processing services (i.e. digital services enabling ubiquitous and on-
demand network access, such as networks, servers or other virtual or physical infrastructure and software). Data that is key for
switching comprises input and output data, including metadata, generated by the customer’s use of the service, excluding data
protected by intellectual property rights or constituting a trade secret of the service provider.  
In practice
To overcome the imbalance of power between providers and customers in the cloud market, the Data Act sets minimum
requirements for the content of cloud contracts. In particular, customers from the private and public sector will beneﬁt
from much greater contractual transparency.
The Data Act includes measures to ensure that customers can switch from one provider of data processing services (‘source
provider’) to another (‘destination’) provider quickly and smoothly, and without losing any data or the functionality of
applications. For example, providers of Platform and Software as a Service must make open interfaces available and, at a
minimum, export data in a commonly used and machine-readable format. Providers of Infrastructure as a Service must take
measures to facilitate that, where a customer switches to a service of the same type, the customer gets materially comparable
outcomes in response to the same input for features that both services share (‘functional equivalence’). As an example of such
a measure, the source provider may have to use tools for shifting computing workloads from one virtualization technology to
another. 
All providers are required to remove obstacles that their customers may face when they want to switch to another provider or
use several services at the same time.
The Data Act will also entirely remove switching charges, including charges for data egress (i.e. charges for data transit),
from 12 January 2027. This means that providers won’t be able to charge their customers for the operations that are necessary
to facilitate switching or for data egress. However, as a transitional measure during the ﬁrst 3 years after the Data Act’s entry
into force (from 11 January 2024 to 12 January 2027), providers may still charge their customers for the costs incurred in
relation to switching and data egress.
Chapter VII: Unlawful third country
government access
Why?
Sometimes, a decision or judgment issued by a country outside the EU (‘third country’) seeks to allow government access to and
transfer of non-personal data processed and stored within the EU. However, in certain instances, granting access to or transfer
of such data may actually be unlawful, in particular where the request conﬂicts with EU laws and guarantees on the protection
of the fundamental rights of individuals, national security interests or commercially sensitive data.
The Data Act follows the Data Governance Act with respect to the provisions aimed at preventing unlawful third-country
governmental access and transfer of non-personal data held in the EU. Such provisions have no impact on regular business-to-
business data sharing. They increase transparency and legal certainty regarding the process and conditions under which non-
personal data can be accessed by or transferred to non-EU government bodies.
Types of data in scope
Any non-personal data held in the EU by a provider of a data processing service.
In practice
The Data Act does not prohibit cross-border data ﬂows, but ensures that the protection aﬀorded to data in the EU travels
with any data transferred outside the EU.
In this context, the Data Act establishes rules and safeguards for access requests by a foreign public sector body to non-
personal data held in the Union. Legitimate international cooperation in relation to law enforcement is not aﬀected by these
provisions.
If there is no international agreement regulating access by a third country government to non-personal data located within the
EU, the data can only be transferred or accessed under speciﬁc conditions. These conditions refer to certain guarantees
safeguarding European rights that need to be met by the third country’s legal system, including a requirement to set out the
reasons and to assess the proportionality in the decision. The provider of data processing services addressed by such a decision
may contact the relevant national body to help assess whether the conditions set out in the Data Act are met. To help assess
whether these conditions have been met, the European Commission will develop guidelines together with the European Data
Innovation Board (an expert group established under the Data Governance Act
(https://digital-strategy.ec.europa.eu/en/policies/data-governance-act-explained) to facilitate the sharing of best practices and
prioritise cross-sectoral interoperability standards).
Providers of data processing services should take all reasonable measures (e.g. encryption, audits, adherence to certiﬁcation
schemes) to prevent access to the systems in which they store non-personal data. These measures should be published on their
websites. In addition, wherever possible, they should inform their customers before giving access to their data.
Chapter VIII: Interoperability
Why?
Standards and interoperability are key to ensuring that data from diﬀerent sources can be used within and between Common
European Data Spaces (https://digital-strategy.ec.europa.eu/en/policies/data-spaces) to foster research and develop new
products or services. To this end, the Data Act establishes some essential requirements with which participants in data spaces
must comply and which can be further speciﬁed by the European Commission by way of delegated acts
(https://commission.europa.eu/law/law-making-process/adopting-eu-law/implementing-and-delegated-acts_en).
It also aims to ensure interoperability between data processing services; this is essential if customers are to beneﬁt from easier
switching.
Key stakeholders
This chapter targets participants of data spaces that oﬀer data or data-based services to other participants and that facilitate or
engage in data sharing within the data spaces.
It also addresses vendors of smart contracts as well as data processing services providers.
In practice
Data space participants should comply with several essential requirements to allow data to ﬂow within and between
data spaces. For example, a description of the data structures, data formats and vocabularies, where available, should be
publicly accessible. In addition, means to ensure the interoperability of data-sharing agreements, such as smart contracts,
should be ensured.
The Data Act also prepares the ground for increasing the interoperability of data processing services through harmonised
standards and open interoperability speciﬁcations.
In addition, it lays out requirements for vendors of smart contracts for the automated execution of data-sharing agreements, for
example to ensure that they correctly carry out the provisions of the data-sharing agreement and withstand manipulation by
third parties.
The Commission will assess barriers to interoperability and prioritise standardisation needs, based on which it may ask European
standardisation organisation(s) to draft harmonised standards that comply with the abovementioned requirements.
If the request does not lead to a harmonised standard or if the standard is insuﬃcient to ensure conformity with the Data Act,
the Commission can adopt common speciﬁcations as a fall-back solution. These should be developed in an open and inclusive
way, considering feedback from the European Data Innovation Board.
Chapter IX: Enforcement and overarching
provisions
Member States will designate one or more (new or existing) competent authorities to ensure the eﬃcient implementation of
the Data Act. Wherever there are multiple competent authorities, Member States must designate one of them as ‘data
coordinator’. The data coordinator will act as a ‘one-stop shop’ for all issues related to the implementation of the Data Act at
the national level, facilitating is application both for businesses and public authorities. For example, if a business seeks redress
for the infringement of their rights under the Data Act, the data coordinator should (upon request) provide all the necessary
information to help them lodge their complaint to the appropriate competent authority. The data coordinator will also facilitate
collaboration in cross-border situations, such as when a competent authority from a given Member State does not know which
authority it should approach in the data coordinator’s Member State.
The Commission will maintain a public register of competent authorities and data coordinators.
The European Data Innovation Board (https://europa.eu/!f8xmhh) will facilitate discussions between competent authorities, for
example to coordinate and adopt recommendations on the setting of penalties for infringements of the Data Act. Penalties are
set by competent authorities, and according to the Data Act there should be eﬀective, proportionate and dissuasive penalties.
Member States may, if they wish, set up certiﬁed dispute settlement bodies to assist parties who cannot agree on fair,
reasonable and non-discriminatory terms for making data available. Parties are free to address any dispute settlement body –
either in the Member State in which they are established or in another.
Certiﬁed dispute settlement mechanisms and specialised competent authorities will make it easier for companies, particularly
small businesses, to enforce their rights under the Data Act as they oﬀer a simple, fast and low-cost solution to the parties
involved.
What’s next?
The European data strategy sets out the path for the EU to become a leader in the data economy. This will be achieved through
the creation of a European single market for data in which data can ﬂow between sectors and Member States in a safe and
trusted manner for the beneﬁt of the economy and society. By ensuring fairness in the allocation of the value of data amongst
stakeholders, the Data Act is a key element to achieving this vision.
The Data Act will become applicable on 12 September 2025.
To help businesses navigate these new rules, the Commission will recommend a set of model contractual terms to help
businesses conclude data-sharing contracts that are fair, reasonable and non-discriminatory (Chapters II and III of the Data Act).
These terms will also provide guidance on reasonable compensation and the protection of trade secrets. The Commission will
also recommend a set of non-binding standard contractual clauses for cloud computing contracts between cloud service users
and providers. An expert group has been set up to help the Commission draft such terms and clauses and it plans to
recommend them by autumn 2025.
Within 3 years of its entry into application, the Commission will carry out an evaluation of the impact of the Data Act. On this
basis, if necessary, the Commission may propose an amendment to the Act.  
Legal Notice
This document should not be considered as representative of the European Commission’s oﬃcial position.
PDF generated on 06/12/2025 from Data Act explained (https://digital-strategy.ec.europa.eu/en/factpages/data-act-explained)
© European Union, 2025 - Reuse of this document is allowed, provided appropriate credit is given and any changes are indicated (Creative Commons Attribution 4.0 International license).
For any use or reproduction of elements that are not owned by the EU, permission may need to be sought directly from the respective right holders.""" ;
    onto:mentionsConcept onto:Creative_Commons_Attribution,
        onto:Data_Act,
        onto:Data_Act_Businesses,
        onto:European_Commission,
        onto:European_Data_Innovation_Board,
        onto:Interoperability_Why,
        onto:Member_State,
        onto:Scope_Chapter,
        onto:Under_Chapter .

onto:Linked_Data a onto:DomainConcept ;
    skos:prefLabel "Linked Data" .

onto:Data_Act a onto:DomainConcept ;
    skos:prefLabel "Data Act" .

